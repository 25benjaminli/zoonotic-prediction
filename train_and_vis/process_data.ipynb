{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'project'):\n",
    "    %cd utils\n",
    "elif (os.path.abspath('').split('/')[-1] == 'train_and_vis'):\n",
    "    %cd ../utils\n",
    "\n",
    "import query_utils\n",
    "import model_utils\n",
    "import validation_utils\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'utils'):\n",
    "    %cd ..\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset1/human_infecting_virus', delimiter='\\t', header=None)\n",
    "df[['ID', 'DNA Sequence']] = df[0].str.split(expand=True)\n",
    "df = df.drop(0, axis=1)\n",
    "df['isZoonotic'] = 1\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('data/dataset1/Other_viruses', delimiter='\\t', header=None)\n",
    "df2[['ID', 'DNA Sequence']] = df2[0].str.split(expand=True)\n",
    "df2 = df2.drop(0, axis=1)\n",
    "df2['isZoonotic'] = 0\n",
    "\n",
    "\n",
    "nardus = pd.read_csv('data/dataset2/nardus_sequences.csv')\n",
    "nardus.reset_index(drop=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# inconsistency with tax IDS\n",
    "mergedDf = pd.concat([df, df2, nardus], axis=0, ignore_index=True)\n",
    "mergedDf = mergedDf.drop_duplicates(subset=['DNA Sequence'])\n",
    "mergedDf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mergedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resetkmerdict(permset)->OrderedDict:\n",
    "        kmerdict = OrderedDict()\n",
    "        for i in permset:\n",
    "            kmerdict[i]=0\n",
    "        return kmerdict\n",
    "\n",
    "def assign_kmers_to_dict(row, permset, kmer):\n",
    "    kmerdict=resetkmerdict(permset)\n",
    "    st = row[2] # tune for which column the sequence is in\n",
    "    for j in range(len(st)-kmer+1):\n",
    "        if not st[j:j+kmer] in permset: continue\n",
    "        kmerdict[st[j:j+kmer]]+=1\n",
    "    return kmerdict\n",
    "\n",
    "def getTrainParams(df, kmer, f=\"merged\", synthetic_pos=0, synthetic_neg=0, save_reg=False, save_new=False, save_merged=True):\n",
    "    s = product('acgt',repeat = kmer)\n",
    "    permset = set([\"\".join(x) for x in list(s)])\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for row in tqdm.tqdm(df.itertuples()):\n",
    "        l.append(assign_kmers_to_dict(row, permset, kmer))\n",
    "\n",
    "    finalkmerdict=pd.DataFrame(l)\n",
    "    \n",
    "    # shouldn't need to fill NAs\n",
    "    # mergedDf.fillna(0, inplace=True)\n",
    "\n",
    "    X = finalkmerdict\n",
    "    Y = df['isZoonotic']\n",
    "    # also test simple average\n",
    "\n",
    "    # sort X by alphabetical order of its columns\n",
    "    X = X.reindex(sorted(X.columns), axis=1)\n",
    "    print(X.columns)\n",
    "\n",
    "    # feature defs\n",
    "    vec = pd.concat([X, Y], axis=1)\n",
    "    \n",
    "    if save_reg:\n",
    "        vec.to_csv(f'data/{f}/kmers-{str(kmer)}.csv', index=False)\n",
    "    \n",
    "    X_norm = X.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=1)\n",
    "\n",
    "    place = pd.concat([X_norm, Y], axis=1)\n",
    "\n",
    "    if save_reg:\n",
    "        place.to_csv(f'data/{f}/normalized-{str(kmer)}.csv', index=False)\n",
    "\n",
    "    div = X.apply(lambda x: x/(len(x)-kmer+1), axis=1)\n",
    "    div = pd.concat([div, Y], axis=1)\n",
    "    if save_new:\n",
    "        div.to_csv(f'data/{f}/lengthdiv-{str(kmer)}.csv', index=False)\n",
    "\n",
    "    # generate based on normalized data\n",
    "    if (synthetic_neg != 0):\n",
    "        # # check if current model is better than pickled model\n",
    "        # posGanModel.save('models/curr_models/posGanModel.pkl')\n",
    "        notZoonotic = place.loc[place['isZoonotic']==0]\n",
    "        notZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "        # print(notZoonotic)\n",
    "        negGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "        negGanModel.fit(notZoonotic)\n",
    "\n",
    "        # negGanModel.save('models/curr_models/negGanModel.pkl')\n",
    "        # generate negative samples\n",
    "        print('Generating negative samples...')\n",
    "        negSamples = negGanModel.sample(synthetic_neg)\n",
    "        negSamples['isZoonotic'] = 0\n",
    "        print('Negative samples generated')\n",
    "        print(negSamples)\n",
    "        print(negSamples.shape)\n",
    "        place = pd.concat([place, negSamples], axis=0, ignore_index=True)\n",
    "        return train_test_split(place.drop('isZoonotic', axis=1), place['isZoonotic'], test_size=0.2, random_state=1)\n",
    "\n",
    "    # generate based on normalized data\n",
    "    if (synthetic_pos != 0):\n",
    "        isZoonotic = place.loc[place['isZoonotic']==1]\n",
    "        isZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "        # print(isZoonotic)\n",
    "\n",
    "        posGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "        posGanModel.fit(isZoonotic)\n",
    "\n",
    "        print('Generating negative samples...')\n",
    "        posSamples = posGanModel.sample(synthetic_neg)\n",
    "        posSamples['isZoonotic'] = 1\n",
    "        print('Negative samples generated')\n",
    "        print(posSamples)\n",
    "        print(posSamples.shape)\n",
    "        place = pd.concat([place, posSamples], axis=0, ignore_index=True)\n",
    "        return train_test_split(place.drop('isZoonotic', axis=1), place['isZoonotic'], test_size=0.2, random_state=1)\n",
    "\n",
    "        # negGanModel.save('models/curr_models/negGanModel.pkl')\n",
    "\n",
    "    return train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kmer in range(3, 7):\n",
    "    # based on literature\n",
    "    X_train, X_test, y_train, y_test = getTrainParams(mergedDf, kmer, f=\"merged\", save_reg=True, save_new=True)\n",
    "    zz = X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = getTrainParams(mergedDf, kmer=4, f=\"merged\", save_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 19 2022, 17:52:09) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
