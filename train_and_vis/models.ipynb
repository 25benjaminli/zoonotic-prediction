{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, balanced_accuracy_score, precision_recall_curve, roc_curve, roc_auc_score, f1_score, recall_score, precision_score, brier_score_loss, average_precision_score, classification_report, log_loss\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "from os import path\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "from torchviz import make_dot\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'project'):\n",
    "    %cd utils\n",
    "elif (os.path.abspath('').split('/')[-1] == 'train_and_vis'):\n",
    "    %cd ../utils\n",
    "\n",
    "import query_utils\n",
    "import model_utils\n",
    "import validation_utils\n",
    "import data_utils\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'utils'):\n",
    "    %cd ..\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingClassifier():\n",
    "    def __init__(self, classifiers, meta_classifier, n_folds=5, use_probas=True):\n",
    "        self.classifiers = classifiers\n",
    "        self.meta_classifier = meta_classifier\n",
    "        self.n_folds = n_folds\n",
    "        self.use_probas = use_probas\n",
    "\n",
    "    def fit_not_pretrained(self, X_train, y_train, cv=10, verbose=False):\n",
    "        print(f\"Training stacking with {len(self.classifiers)} base models\")\n",
    "        kfold = StratifiedKFold(n_splits=cv, random_state=42, shuffle=True)\n",
    "        out_of_fold_predictions = np.zeros((X_train.shape[0], len(self.classifiers)))\n",
    "        \n",
    "        for i, clf in enumerate(self.classifiers):\n",
    "            print(f\"Training base {i+1}/{len(self.classifiers)}\")\n",
    "            for fold, (train_index, holdout_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "                if type(clf).__name__ == 'XGBClassifier':\n",
    "                    X_train_xg, X_val, y_train_xg, y_val = train_test_split(\n",
    "                        X_train[train_index], y_train[train_index], test_size=0.15, random_state=1)\n",
    "                    self.classifiers[i] = clf.fit(X_train_xg, y_train_xg, eval_metric='aucpr', \n",
    "                                                eval_set=[(X_val, y_val)], early_stopping_rounds=20, verbose=False)\n",
    "                else:\n",
    "                    self.classifiers[i] = clf.fit(X_train[train_index], y_train[train_index])\n",
    "                \n",
    "                if self.use_probas:\n",
    "                    y_pred = clf.predict_proba(X_train[holdout_index])[:, 1]\n",
    "                else:\n",
    "                    y_pred = clf.predict(X_train[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "        \n",
    "        self.meta_classifier.fit(out_of_fold_predictions, y_train)\n",
    "        print(\"stacking training complete\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.use_probas:\n",
    "            meta_features = np.column_stack([clf.predict_proba(X)[:, 1] for clf in self.classifiers])\n",
    "        else:\n",
    "            meta_features = np.column_stack([clf.predict(X) for clf in self.classifiers])\n",
    "        return self.meta_classifier.predict(meta_features)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        meta_features = np.column_stack([clf.predict_proba(X)[:, 1] for clf in self.classifiers])\n",
    "        return self.meta_classifier.predict_proba(meta_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data testing\n",
    "With CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isZoonotic = df.loc[df['isZoonotic']==1][:1200]\n",
    "isZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(isZoonotic)\n",
    "\n",
    "posGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "posGanModel.fit(isZoonotic)\n",
    "posGanModel.save('models/curr_models/posGanModel.pkl')\n",
    "\n",
    "notZoonotic = df.loc[df['isZoonotic']==0][:3000]\n",
    "notZoonotic = notZoonotic.loc[:, notZoonotic.columns != 'isZoonotic']\n",
    "print(notZoonotic)\n",
    "\n",
    "negGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "negGanModel.fit(notZoonotic)\n",
    "negGanModel.save('models/curr_models/negGanModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_utils.retrieveMerged(dir='data/')\n",
    "print(f\"Available datasets: {list(dataset.keys())}\")\n",
    "print(f\"Dataset f2-4 shape: X={len(dataset['f2-4']['X'])}, y={len(dataset['f2-4']['y'])}\")\n",
    "print(f\"Positive samples: {sum(dataset['f2-4']['y'])}, Negative samples: {len(dataset['f2-4']['y'])-sum(dataset['f2-4']['y'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelScores = {}\n",
    "features = ['f1', 'f2', 'f3']\n",
    "scoring_metrics = ['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models across different feature sets and k-mer lengths\n",
    "model_configs = {\n",
    "    'knn': KNeighborsClassifier(n_neighbors=1, n_jobs=-1),\n",
    "    'rf': BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1),\n",
    "    'xgb': XGBClassifier(\n",
    "        learning_rate=0.1, n_estimators=300, max_depth=9, min_child_weight=1,\n",
    "        gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "        seed=42, n_jobs=-1, scale_pos_weight=6),\n",
    "    'mlp': MLPClassifier(\n",
    "        alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "        max_iter=550, random_state=42, solver='adam', activation='relu'),\n",
    "    'svm': SVC(\n",
    "        kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42, max_iter=500)\n",
    "}\n",
    "\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        print(f\"Training models for {feature}-{kmer}...\")\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "        X, y = ds['X'], ds['y']\n",
    "        \n",
    "        for model_name, model in model_configs.items():\n",
    "            name = f'{model_name}_{feature}_{kmer}'\n",
    "            if name not in modelScores:\n",
    "                print(f\"  Training {model_name}...\")\n",
    "                current_scoring = scoring_metrics if model_name != 'svm' else scoring_metrics[:-1]\n",
    "                try:\n",
    "                    x = cross_validate(model, X, y, cv=5, scoring=current_scoring)\n",
    "                    modelScores[name] = {k: v.mean() for k, v in x.items()}\n",
    "                    print(f\"    Completed {model_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "score_df = pd.DataFrame(modelScores).T\n",
    "print(f\"Total models trained: {len(score_df)}\")\n",
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = BalancedBaggingClassifier(estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "\n",
    "rf = BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "        learning_rate=0.1, n_estimators=200, max_depth=9, min_child_weight=1,\n",
    "        gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "        seed=42, n_jobs=-1, scale_pos_weight=6)\n",
    "\n",
    "em = StackingClassifier(\n",
    "    classifiers=[mlp, rf, xgb], \n",
    "    meta_classifier=LogisticRegression(C=1, random_state=42, solver='saga'), \n",
    "    use_probas=True\n",
    ")\n",
    "\n",
    "em.fit_not_pretrained(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_avg_roc_curve(model, name, X, y, multiple=False):\n",
    "    # done w/ the help of https://stats.stackexchange.com/questions/186337/average-roc-for-repeated-10-fold-cross-validation-with-probability-estimates\n",
    "    # plt.ylim(0.50, 1.01)\n",
    "    splits = 5\n",
    "    kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    avgauc = 0\n",
    "    \n",
    "    max_len_x = train_test_split(X, y, test_size=0.2, random_state=42)[0].shape[0]+1\n",
    "    max_len_y = train_test_split(X, y, test_size=0.2, random_state=42)[2].shape[0]+1\n",
    "\n",
    "    print(\"max len x: \" + str(max_len_x))\n",
    "    print(\"max len y: \" + str(max_len_y))\n",
    "\n",
    "    for train, test in kf.split(X, y):\n",
    "        # y_pred_proba = model.predict_proba(X.iloc[test])[::,1]\n",
    "        # fpr, tpr, _ = roc_curve(y[test], y_pred_proba)\n",
    "        # auc_thing = roc_auc_score(y[test], y_pred_proba)\n",
    "        # print(\"roc: \" + str(auc_thing))\n",
    "        # print(train)\n",
    "        # print(test)\n",
    "        print(len(train), len(test))\n",
    "        # if the length is greater than the max length, then chop off the excess\n",
    "        if len(train) > max_len_x:\n",
    "            train = train[:max_len_x]\n",
    "\n",
    "        if len(test) > max_len_y:\n",
    "            test = test[:max_len_y]\n",
    "\n",
    "        \n",
    "        model = model.fit(X.iloc[train], y[train])\n",
    "        print(\"fit done\")\n",
    "        y_score = model.predict_proba(X.iloc[test])\n",
    "        precision, recall, _ = precision_recall_curve(y[test], y_score[:, 1])\n",
    "        auc_thing = auc(recall, precision)\n",
    "        \n",
    "        # if not multiple:\n",
    "        #     # plot variance\n",
    "        #     plt.plot(recall, precision, alpha=0.15)\n",
    "\n",
    "        avgauc += auc_thing\n",
    "        print(\"auc split: \", auc_thing)\n",
    "\n",
    "        # pad with 0s\n",
    "        print(\"precision len: \", len(precision))\n",
    "        print(\"recall len: \", len(recall))\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        \n",
    "    \n",
    "    avgauc /= splits\n",
    "    # recall_scores\n",
    "\n",
    "    precision_scores = np.mean(precision_scores, axis=0)\n",
    "    recall_scores = np.mean(recall_scores, axis=0)\n",
    "\n",
    "\n",
    "    if name.lower() == \"ensemble\":\n",
    "        plt.plot(recall_scores, precision_scores, label=f\"{name}\", color=\"red\")\n",
    "    else:\n",
    "        plt.plot(recall_scores, precision_scores, label=f\"{name}\")\n",
    "    # fill in areas between\n",
    "    \n",
    "    return round(avgauc, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, em.predict(X_test)))\n",
    "print(recall_score(y_test, em.predict(X_test)))\n",
    "print(f1_score(y_test, em.predict(X_test)))\n",
    "# pickle.dump(em, open('models/curr_models/ensemble.pkl', 'wb'))\n",
    "asdf = pickle.load(open('models/curr_models/xgb1-test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = cross_val_score(model_configs[\"rf\"], X, y, cv=2, scoring='recall', verbose=1, n_jobs=-1)\n",
    "x2 = cross_val_score(em, X, y, cv=2, scoring='recall', verbose=1, n_jobs=-1)\n",
    "print(\"rf: \", x1)\n",
    "print(\"em: \", x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Ensemble\n",
    "precision, recall, _ = precision_recall_curve(y_test, em.predict_proba(X_test.values)[:,1])\n",
    "area = auc(recall, precision)\n",
    "plt.plot(recall, precision, marker='.', label=f'Ensemble (AUC={area:.3f})', linewidth=2, color='red')\n",
    "\n",
    "# Random Forest\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_configs[\"rf\"].predict_proba(X_test)[:, 1])\n",
    "area = auc(recall, precision)\n",
    "plt.plot(recall, precision, marker='.', label=f'Random Forest (AUC={area:.3f})', linewidth=2)\n",
    "\n",
    "# KNN (on f3-4 dataset as in original)\n",
    "ds_knn = dataset['f3-4']\n",
    "X_knn, y_knn = ds_knn['X'], ds_knn['y']\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_knn, y_knn, test_size=0.2, random_state=42)\n",
    "knn_f3 = BalancedBaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=1, n_jobs=-1), n_estimators=1, n_jobs=-1)\n",
    "knn_f3.fit(X_train_knn, y_train_knn)\n",
    "precision, recall, _ = precision_recall_curve(y_test_knn, knn_f3.predict_proba(X_test_knn)[:, 1])\n",
    "area = auc(recall, precision)\n",
    "plt.plot(recall, precision, marker='.', label=f'KNN (AUC={area:.3f})', linewidth=2)\n",
    "\n",
    "# No-skill line\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='gray', label='No Skill')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
