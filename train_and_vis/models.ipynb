{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/Documents/coding/scires/project/utils\n",
      "/Users/benjaminli/Documents/coding/scires/project\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, balanced_accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "from sklearn import svm\n",
    "if (os.path.abspath('').split('/')[-1] == 'project'):\n",
    "    %cd utils\n",
    "elif (os.path.abspath('').split('/')[-1] == 'train_and_vis'):\n",
    "    %cd ../utils\n",
    "\n",
    "import query_utils\n",
    "import model_utils\n",
    "import validation_utils\n",
    "import data_utils\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'utils'):\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          cctg      gtgt      acac      ccga      ttga      accg      ctca  \\\n",
      "0     0.297872  0.819149  0.446809  0.074468  0.265957  0.063830  0.106383   \n",
      "1     0.297872  0.819149  0.446809  0.074468  0.265957  0.063830  0.106383   \n",
      "2     0.297872  0.819149  0.446809  0.074468  0.265957  0.063830  0.106383   \n",
      "3     0.367347  0.857143  0.469388  0.040816  0.295918  0.081633  0.081633   \n",
      "4     0.483871  0.451613  0.580645  0.494624  0.311828  0.677419  0.129032   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1195  0.341772  0.265823  0.379747  0.101266  0.582278  0.126582  0.202532   \n",
      "1196  0.368421  0.394737  0.513158  0.052632  0.500000  0.092105  0.236842   \n",
      "1197  0.678571  0.797619  0.535714  0.071429  0.250000  0.166667  0.107143   \n",
      "1198  0.549451  0.791209  0.527473  0.153846  0.296703  0.098901  0.087912   \n",
      "1199  0.414634  0.292683  0.365854  0.060976  0.487805  0.158537  0.134146   \n",
      "\n",
      "          tgtt      agcc      cgtt  ...      tggg      aata      tatg  \\\n",
      "0     0.712766  0.095745  0.085106  ...  0.372340  0.702128  0.617021   \n",
      "1     0.712766  0.095745  0.085106  ...  0.372340  0.702128  0.617021   \n",
      "2     0.712766  0.095745  0.085106  ...  0.372340  0.702128  0.617021   \n",
      "3     0.806122  0.214286  0.102041  ...  0.285714  0.581633  0.744898   \n",
      "4     0.204301  0.365591  0.129032  ...  0.204301  0.161290  0.161290   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1195  0.594937  0.164557  0.088608  ...  0.202532  0.721519  0.493671   \n",
      "1196  0.697368  0.171053  0.118421  ...  0.342105  0.750000  0.500000   \n",
      "1197  0.559524  0.214286  0.154762  ...  0.583333  0.309524  0.571429   \n",
      "1198  0.560440  0.252747  0.120879  ...  0.450549  0.318681  0.637363   \n",
      "1199  0.475610  0.146341  0.085366  ...  0.304878  0.658537  0.329268   \n",
      "\n",
      "          gatc      ttac      ggga      ggtc      atac      atta      ccgc  \n",
      "0     0.095745  0.500000  0.202128  0.106383  0.500000  0.659574  0.021277  \n",
      "1     0.095745  0.500000  0.202128  0.106383  0.500000  0.659574  0.021277  \n",
      "2     0.095745  0.500000  0.202128  0.106383  0.500000  0.659574  0.021277  \n",
      "3     0.051020  0.551020  0.204082  0.122449  0.438776  0.704082  0.142857  \n",
      "4     0.311828  0.301075  0.290323  0.268817  0.376344  0.096774  0.462366  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1195  0.291139  0.354430  0.215190  0.164557  0.468354  0.670886  0.088608  \n",
      "1196  0.276316  0.513158  0.355263  0.276316  0.447368  0.776316  0.026316  \n",
      "1197  0.142857  0.250000  0.559524  0.095238  0.369048  0.392857  0.095238  \n",
      "1198  0.131868  0.285714  0.395604  0.186813  0.318681  0.340659  0.065934  \n",
      "1199  0.256098  0.329268  0.268293  0.365854  0.365854  0.585366  0.000000  \n",
      "\n",
      "[1200 rows x 256 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/models.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/models.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(isZoonotic)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/models.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m posGanModel \u001b[39m=\u001b[39m CTGANSynthesizer(batch_size\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/models.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m posGanModel\u001b[39m.\u001b[39;49mfit(isZoonotic)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/models.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# check if current model is better than pickled model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/models.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m posGanModel\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodels/curr_models/posGanModel.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/ctgan/synthesizers/base.py:50\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         \u001b[39mwith\u001b[39;00m set_random_states(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_random_state):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/ctgan/synthesizers/ctgan.py:306\u001b[0m, in \u001b[0;36mCTGANSynthesizer.fit\u001b[0;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    300\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39m`epochs` argument in `fit` method has been deprecated and will be removed \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    301\u001b[0m          \u001b[39m'\u001b[39m\u001b[39min a future version. Please pass `epochs` to the constructor instead\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    302\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer \u001b[39m=\u001b[39m DataTransformer()\n\u001b[0;32m--> 306\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformer\u001b[39m.\u001b[39;49mfit(train_data, discrete_columns)\n\u001b[1;32m    308\u001b[0m train_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39mtransform(train_data)\n\u001b[1;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_sampler \u001b[39m=\u001b[39m DataSampler(\n\u001b[1;32m    311\u001b[0m     train_data,\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer\u001b[39m.\u001b[39moutput_info_list,\n\u001b[1;32m    313\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_frequency)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/ctgan/data_transformer.py:104\u001b[0m, in \u001b[0;36mDataTransformer.fit\u001b[0;34m(self, raw_data, discrete_columns)\u001b[0m\n\u001b[1;32m    102\u001b[0m     column_transform_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_discrete(raw_data[[column_name]])\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     column_transform_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_continuous(raw_data[[column_name]])\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_info_list\u001b[39m.\u001b[39mappend(column_transform_info\u001b[39m.\u001b[39moutput_info)\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dimensions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m column_transform_info\u001b[39m.\u001b[39moutput_dimensions\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/ctgan/data_transformer.py:50\u001b[0m, in \u001b[0;36mDataTransformer._fit_continuous\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     48\u001b[0m column_name \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m gm \u001b[39m=\u001b[39m ClusterBasedNormalizer(model_missing_values\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_clusters\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(data), \u001b[39m10\u001b[39m))\n\u001b[0;32m---> 50\u001b[0m gm\u001b[39m.\u001b[39;49mfit(data, column_name)\n\u001b[1;32m     51\u001b[0m num_components \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(gm\u001b[39m.\u001b[39mvalid_component_indicator)\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m ColumnTransformInfo(\n\u001b[1;32m     54\u001b[0m     column_name\u001b[39m=\u001b[39mcolumn_name, column_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39mgm,\n\u001b[1;32m     55\u001b[0m     output_info\u001b[39m=\u001b[39m[SpanInfo(\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m), SpanInfo(num_components, \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)],\n\u001b[1;32m     56\u001b[0m     output_dimensions\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m num_components)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/rdt/transformers/base.py:240\u001b[0m, in \u001b[0;36mBaseTransformer.fit\u001b[0;34m(self, data, column)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_columns(column, data)\n\u001b[1;32m    239\u001b[0m columns_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_columns_data(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m--> 240\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(columns_data)\n\u001b[1;32m    242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_output_columns(data)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/rdt/transformers/numerical.py:469\u001b[0m, in \u001b[0;36mClusterBasedNormalizer._fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    468\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bgm_transformer\u001b[39m.\u001b[39;49mfit(data\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_component_indicator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bgm_transformer\u001b[39m.\u001b[39mweights_ \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_threshold\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/mixture/_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m     \u001b[39m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[39m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m        The fitted mixture.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[1;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/mixture/_base.py:266\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    264\u001b[0m log_prob_norm, log_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_e_step(X)\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_m_step(X, log_resp)\n\u001b[0;32m--> 266\u001b[0m lower_bound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_lower_bound(log_resp, log_prob_norm)\n\u001b[1;32m    268\u001b[0m change \u001b[39m=\u001b[39m lower_bound \u001b[39m-\u001b[39m prev_lower_bound\n\u001b[1;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_verbose_msg_iter_end(n_iter, change)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/mixture/_bayesian_mixture.py:846\u001b[0m, in \u001b[0;36mBayesianGaussianMixture._compute_lower_bound\u001b[0;34m(self, log_resp, log_prob_norm)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     log_norm_weight \u001b[39m=\u001b[39m _log_dirichlet_norm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_concentration_)\n\u001b[1;32m    845\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 846\u001b[0m     \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49mexp(log_resp) \u001b[39m*\u001b[39m log_resp)\n\u001b[1;32m    847\u001b[0m     \u001b[39m-\u001b[39m log_wishart\n\u001b[1;32m    848\u001b[0m     \u001b[39m-\u001b[39m log_norm_weight\n\u001b[1;32m    849\u001b[0m     \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m n_features \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_precision_))\n\u001b[1;32m    850\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "isZoonotic = df.loc[df['isZoonotic']==1][:1200]\n",
    "isZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(isZoonotic)\n",
    "\n",
    "posGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "posGanModel.fit(isZoonotic)\n",
    "\n",
    "# check if current model is better than pickled model\n",
    "posGanModel.save('models/curr_models/posGanModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tggc      ttcc      tatg  ...      cttg      ctat      tctt\n",
      "0     0.329787  0.297872  0.617021  ...  0.148936  0.393617  0.170213\n",
      "1     0.377551  0.255102  0.744898  ...  0.153061  0.367347  0.112245\n",
      "2     0.462366  0.279570  0.161290  ...  0.182796  0.193548  0.118280\n",
      "3     0.455446  0.188119  0.475248  ...  0.188119  0.386139  0.138614\n",
      "4     0.666667  0.333333  0.575758  ...  0.636364  0.515152  0.424242\n",
      "...        ...       ...       ...  ...       ...       ...       ...\n",
      "1195  0.404762  0.333333  0.571429  ...  0.261905  0.357143  0.202381\n",
      "1196  0.417582  0.252747  0.637363  ...  0.208791  0.274725  0.153846\n",
      "1197  0.341463  0.146341  0.329268  ...  0.207317  0.231707  0.231707\n",
      "1198  0.192308  0.153846  0.461538  ...  0.166667  0.320513  0.230769\n",
      "1199  0.226190  0.273810  0.428571  ...  0.166667  0.357143  0.285714\n",
      "\n",
      "[1200 rows x 256 columns]\n",
      "Epoch 1, Loss G:  1.8207,Loss D: -5.4888\n",
      "Epoch 2, Loss G: -1.7336,Loss D: -0.0555\n",
      "Epoch 3, Loss G: -1.9224,Loss D:  1.3800\n",
      "Epoch 4, Loss G: -0.3142,Loss D:  0.9002\n",
      "Epoch 5, Loss G:  0.2182,Loss D:  2.5544\n",
      "Epoch 6, Loss G:  0.4122,Loss D: -0.4554\n",
      "Epoch 7, Loss G: -1.5571,Loss D:  1.5836\n",
      "Epoch 8, Loss G:  0.5802,Loss D: -0.5996\n",
      "Epoch 9, Loss G:  0.9459,Loss D: -0.2177\n",
      "Epoch 10, Loss G: -0.0489,Loss D: -0.7818\n"
     ]
    }
   ],
   "source": [
    "notZoonotic = df.loc[df['isZoonotic']==0][:3000]\n",
    "notZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(notZoonotic)\n",
    "\n",
    "negGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "negGanModel.fit(notZoonotic)\n",
    "negGanModel.save('models/curr_models/negGanModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmer: 3\n",
      "kmer: 4\n",
      "kmer: 5\n",
      "kmer: 6\n"
     ]
    }
   ],
   "source": [
    "dataset1 = OrderedDict({})\n",
    "\n",
    "dataset2 = OrderedDict({})\n",
    "\n",
    "mergedDataset = OrderedDict({})\n",
    "\n",
    "\n",
    "# load datasets with different kmer values\n",
    "for kmer in range(3, 7):\n",
    "    df_1_reg = pd.read_csv(f'data/dataset1/kmers-{str(kmer)}.csv')\n",
    "    df_1_norm = pd.read_csv(f'data/dataset1/normalized-{str(kmer)}.csv')\n",
    "    df_2_reg = pd.read_csv(f'data/dataset2/kmers-{str(kmer)}.csv')\n",
    "    df_2_norm = pd.read_csv(f'data/dataset2/normalized-{str(kmer)}.csv')\n",
    "\n",
    "    print(\"kmer: \" + str(kmer))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_1_reg.loc[:, df_1_reg.columns != 'isZoonotic'], df_1_reg['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    # for col in df.columns:\n",
    "    #     col != 'isZoonotic' and X_train[col].isnull().sum() != 0 and print(X_train[col].isnull().sum())\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    dataset1[f'regular-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_1_norm.loc[:, df_1_norm.columns != 'isZoonotic'], df_1_norm['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    dataset1[f'normalized-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_2_reg.loc[:, df_2_reg.columns != 'isZoonotic'], df_2_reg['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    dataset2[f'regular-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_2_norm.loc[:, df_2_norm.columns != 'isZoonotic'], df_2_norm['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    dataset2[f'normalized-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "\n",
    "    # merge df_1 and df_2\n",
    "    df_reg = df_1_reg.append(df_2_reg)\n",
    "    df_norm = df_1_norm.append(df_2_norm)\n",
    "\n",
    "    df_reg.reset_index(drop=True, inplace=True)\n",
    "    df_norm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_reg.loc[:, df_reg.columns != 'isZoonotic'], df_reg['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    mergedDataset[f'regular-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_norm.loc[:, df_norm.columns != 'isZoonotic'], df_norm['isZoonotic'], test_size=0.2, random_state=1)\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    mergedDataset[f'normalized-{kmer}'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}\n",
    "\n",
    "datasets = {\"zhang\": dataset1, \"nardus\": dataset2, \"merged\": mergedDataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "model_utils.getOptimalModels(clf, datasets, kmer_range=[4, 6], onlyNormalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1829, fp: 53, fn: 157, tp: 197\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841 (0.004)\n",
      "tn: 1881, fp: 1, fn: 354, tp: 0\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1766, fp: 116, fn: 250, tp: 104\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841 (0.004)\n",
      "tn: 1836, fp: 46, fn: 320, tp: 34\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1825, fp: 57, fn: 159, tp: 195\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841 (0.004)\n",
      "tn: 1879, fp: 3, fn: 354, tp: 0\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896 (0.016)\n",
      "tn: 1829, fp: 53, fn: 121, tp: 233\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   55.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844 (0.010)\n",
      "tn: 1880, fp: 2, fn: 354, tp: 0\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lrmodel \u001b[39m=\u001b[39m LogisticRegression(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     multi_class\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmultinomial\u001b[39m\u001b[39m\"\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     fit_intercept\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, tol\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m lrmodel\u001b[39m.\u001b[39mfit(ds[\u001b[39m'\u001b[39m\u001b[39mX_train\u001b[39m\u001b[39m'\u001b[39m], ds[\u001b[39m'\u001b[39m\u001b[39my_train\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m acc \u001b[39m=\u001b[39m validation_utils\u001b[39m.\u001b[39;49mcross_validate(lrmodel, merged[\u001b[39m'\u001b[39;49m\u001b[39mX_test\u001b[39;49m\u001b[39m'\u001b[39;49m], merged[\u001b[39m'\u001b[39;49m\u001b[39my_test\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/coding/scires/project/utils/validation_utils.py:134\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m    131\u001b[0m X_test \u001b[39m=\u001b[39m transform_data(model, X_test)\n\u001b[1;32m    133\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m n_scores \u001b[39m=\u001b[39m cross_val_score(model, X_test, y_test, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, error_score\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mraise\u001b[39;49m\u001b[39m'\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    135\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (mean(n_scores), std(n_scores)))\n\u001b[1;32m    136\u001b[0m tn, fp, fn, tp \u001b[39m=\u001b[39m confusion_matrix(y_test, model\u001b[39m.\u001b[39mpredict(X_test))\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dsnames = ['zhang', 'nardus', 'merged']\n",
    "kmers = [4, 6]\n",
    "features = ['normalized', 'regular']\n",
    "\n",
    "for kmer in range(kmers[0], kmers[1]+1):\n",
    "    for dsname in dsnames:\n",
    "        for feature in features:\n",
    "            ds = datasets[dsname][f'{feature}-{kmer}']\n",
    "            merged = datasets['merged'][f'{feature}-{kmer}']\n",
    "            \n",
    "            lrmodel = LogisticRegression(\n",
    "                multi_class=\"multinomial\", max_iter=1000,\n",
    "                fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "            lrmodel.fit(ds['X_train'], ds['y_train'])\n",
    "            acc = validation_utils.cross_validate(lrmodel, merged['X_test'], merged['y_test'])\n",
    "            # predictions = lrmodel.predict(datasets['merged']['X_test'])\n",
    "            # picklething = pickle.load(open('models/curr_models/lrmodel.pkl', 'rb'))\n",
    "            # print(accuracy_score(merged['y_test'], predictions))\n",
    "            # print(accuracy_score(merged['y_test'], picklething.predict(merged['X_test'])))\n",
    "            model_utils.saveModel(lrmodel, \"lrmodel\", X_test, y_test, dir=f'models/curr_models/kmer{str(kmer)}')\n",
    "\n",
    "\n",
    "# model_utils.saveModel(lrmodel, \"lrmodel\", X_test, y_test, dir='models/misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1829, fp: 53, fn: 157, tp: 197\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1766, fp: 116, fn: 250, tp: 104\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1829, fp: 53, fn: 157, tp: 197\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1825, fp: 57, fn: 159, tp: 195\n",
      "LogisticRegression\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1825, fp: 57, fn: 159, tp: 195\n",
      "LogisticRegression\n",
      "LogisticRegression\n",
      "Accuracy: 0.889 (0.017)\n",
      "tn: 1825, fp: 57, fn: 159, tp: 195\n",
      "no update\n",
      "curr 0.889 pickle 0.889\n",
      "[1825   57  159  195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42, solver=&#x27;saga&#x27;,\n",
       "                   tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, random_state=42, solver=&#x27;saga&#x27;,\n",
       "                   tol=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(fit_intercept=False, max_iter=1000,\n",
       "                   multi_class='multinomial', random_state=42, solver='saga',\n",
       "                   tol=0.001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged = datasets['merged']['normalized-4']\n",
    "\n",
    "ds = datasets['zhang'][f'normalized-4']\n",
    "merged = datasets['merged'][f'normalized-4']\n",
    "\n",
    "# print(len(ds['X_train'])+len(ds['X_test']))\n",
    "\n",
    "lrmodel = LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "lrmodel.fit(ds['X_train'], ds['y_train'])\n",
    "acc = validation_utils.cross_validate(lrmodel, merged['X_test'], merged['y_test'])\n",
    "\n",
    "\n",
    "ds = datasets['nardus'][f'normalized-4']\n",
    "merged = datasets['merged'][f'normalized-4']\n",
    "\n",
    "# print(len(ds['X_train'])+len(ds['X_test']))\n",
    "\n",
    "lrmodel = LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "lrmodel.fit(ds['X_train'], ds['y_train'])\n",
    "acc = validation_utils.cross_validate(lrmodel, merged['X_test'], merged['y_test'])\n",
    "\n",
    "\n",
    "ds = datasets['zhang'][f'normalized-4']\n",
    "merged = datasets['merged'][f'normalized-4']\n",
    "\n",
    "# print(len(ds['X_train'])+len(ds['X_test']))\n",
    "\n",
    "lrmodel = LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "lrmodel.fit(ds['X_train'], ds['y_train'])\n",
    "acc = validation_utils.cross_validate(lrmodel, merged['X_test'], merged['y_test'])\n",
    "\n",
    "\n",
    "ds = datasets['merged'][f'normalized-4']\n",
    "merged = datasets['merged'][f'normalized-4']\n",
    "\n",
    "# print(len(ds['X_train'])+len(ds['X_test']))\n",
    "\n",
    "lrmodel = LogisticRegression(\n",
    "    multi_class=\"multinomial\", max_iter=1000,\n",
    "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
    "lrmodel.fit(ds['X_train'], ds['y_train'])\n",
    "acc = validation_utils.cross_validate(lrmodel, merged['X_test'], merged['y_test'])\n",
    "\n",
    "X_test, y_test = ds['X_test'], ds['y_test']\n",
    "model_utils.saveModel(lrmodel, \"lrmodel\", X_test, y_test, dir=\"models/curr_models/kmer4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedBaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819 (0.022)\n",
      "tn: 1637, fp: 245, fn: 52, tp: 302\n",
      "0.819\n",
      "BalancedBaggingClassifier\n",
      "BalancedBaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819 (0.025)\n",
      "tn: 1637, fp: 245, fn: 52, tp: 302\n",
      "BalancedBaggingClassifier\n",
      "BalancedBaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821 (0.024)\n",
      "tn: 1651, fp: 231, fn: 52, tp: 302\n",
      "no update\n",
      "curr 0.819 pickle 0.821\n",
      "[1651  231   52  302]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_jobs=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedBaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_jobs=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=1, n_neighbors=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=1, n_neighbors=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_jobs=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer = 5\n",
    "ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "knntest = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors = 1, n_jobs = 1), n_estimators = 10, n_jobs = 1)\n",
    "\n",
    "knntest.fit(X_train, y_train)\n",
    "# predictions = knntest.predict(X_test)\n",
    "print(validation_utils.cross_validate(knntest, X_test, y_test))\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_utils.saveModel(knntest, \"knn\", X_test, y_test, dir=f\"models/curr_models/kmer{kmer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193202146690519\n"
     ]
    }
   ],
   "source": [
    "merged = datasets['merged']['normalized-4']\n",
    "X_train, y_train, X_test, y_test = merged['X_train'], merged['y_train'], merged['X_test'], merged['y_test']\n",
    "\n",
    "predictions = knntest.predict(X_test)\n",
    "picklething = pickle.load(open('models/curr_models/knn.pkl', 'rb'))\n",
    "\n",
    "print(accuracy_score(y_test, predictions), accuracy_score(y_test, picklething.predict(X_test)))\n",
    "# saveModel(knntest, \"knn\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedBaggingClassifier\n",
      "BalancedBaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.873 (0.023)\n",
      "tn: 1749, fp: 133, fn: 75, tp: 279\n",
      "BalancedBaggingClassifier\n",
      "BalancedBaggingClassifier\n",
      "Accuracy: 0.866 (0.024)\n",
      "tn: 1743, fp: 139, fn: 82, tp: 272\n",
      "update!\n",
      "[1743  139   82  272]\n",
      "curr 0.873 pickle 0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedBaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features='sqrt'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer = 4\n",
    "ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"))\n",
    "\n",
    "randforest.fit(X_train, y_train)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_utils.saveModel(randforest, \"randforest\", X_test, y_test, dir=f\"models/curr_models/kmer{kmer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9294803817603393\n"
     ]
    }
   ],
   "source": [
    "probability_predictions = randforest.predict_proba(X_test)\n",
    "preds = randforest.predict(X_test)\n",
    "print(accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (validation): 0.957\n",
      "no update\n",
      "curr 0.9565217391304348 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.075\n",
      "Accuracy score (validation): 0.958\n",
      "no update\n",
      "curr 0.9581124072110286 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.1\n",
      "Accuracy score (validation): 0.956\n",
      "no update\n",
      "curr 0.9559915164369035 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.15\n",
      "Accuracy score (validation): 0.960\n",
      "no update\n",
      "curr 0.9602332979851538 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.2\n",
      "Accuracy score (validation): 0.963\n",
      "no update\n",
      "curr 0.9628844114528102 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.25\n",
      "Accuracy score (validation): 0.958\n",
      "no update\n",
      "curr 0.9575821845174973 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.3\n",
      "Accuracy score (validation): 0.958\n",
      "no update\n",
      "curr 0.9575821845174973 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.35\n",
      "Accuracy score (validation): 0.956\n",
      "no update\n",
      "curr 0.9559915164369035 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.4\n",
      "Accuracy score (validation): 0.951\n",
      "no update\n",
      "curr 0.9506892895015907 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.45\n",
      "Accuracy score (validation): 0.958\n",
      "no update\n",
      "curr 0.9581124072110286 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.5\n",
      "Accuracy score (validation): 0.956\n",
      "no update\n",
      "curr 0.9559915164369035 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.55\n",
      "Accuracy score (validation): 0.951\n",
      "no update\n",
      "curr 0.9506892895015907 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.6\n",
      "Accuracy score (validation): 0.949\n",
      "no update\n",
      "curr 0.9490986214209968 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.65\n",
      "Accuracy score (validation): 0.955\n",
      "no update\n",
      "curr 0.954931071049841 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.7\n",
      "Accuracy score (validation): 0.843\n",
      "no update\n",
      "curr 0.8430540827147401 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.75\n",
      "Accuracy score (validation): 0.748\n",
      "no update\n",
      "curr 0.7476139978791092 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.8\n",
      "Accuracy score (validation): 0.801\n",
      "no update\n",
      "curr 0.8011664899257688 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  0.85\n",
      "Accuracy score (validation): 0.870\n",
      "no update\n",
      "curr 0.8695652173913043 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n",
      "Learning rate:  1\n",
      "Accuracy score (validation): 0.860\n",
      "no update\n",
      "curr 0.8600212089077413 pickle 0.9883351007423118\n",
      "[1629    5   17  235]\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65,0.7, 0.75, 0.8, 0.85, 1]\n",
    "\n",
    "parameters={\n",
    "   'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 0, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "\n",
    "# careful with WARM START - only works after a lot of iterations\n",
    "for learning_rate in lr_list:\n",
    "    gradBoost = GradientBoostingClassifier(n_estimators=parameters['n_estimators'], \n",
    "    learning_rate=learning_rate, max_features=parameters['max_features'], \n",
    "    max_depth=parameters['max_depth'], random_state=parameters['random_state'], \n",
    "    min_samples_split=parameters['min_sample_split'], subsample=parameters['subsample']\n",
    "    )\n",
    "\n",
    "    parameters['learning_rate']=learning_rate\n",
    "    gradBoost.fit(X_train, y_train)\n",
    "\n",
    "    cols_when_model_builds = gradBoost.feature_names_in_\n",
    "    X_test=X_test[cols_when_model_builds]\n",
    "    \n",
    "    testingAcc = accuracy_score(y_test, gradBoost.predict(X_test))\n",
    "    trainingAcc = accuracy_score(y_train, gradBoost.predict(X_train))\n",
    "    \n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    # print(\"Accuracy score (training): {0:.3f}\".format(trainingAcc))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(testingAcc))\n",
    "    # print(f\"Feature importance {gradBoost.feature_importances_}\")\n",
    "\n",
    "    # pickle.dump(gradBoost, open('gradBoost.pkl', 'wb'))\n",
    "    saveModel(gradBoost, \"gradBoost\", X_test, y_test, parameters, gradBoost=True, dir=\"models/synthetic_data_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (validation): 0.960\n",
      "no update\n",
      "curr 0.9602332979851538 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.075\n",
      "Accuracy score (validation): 0.962\n",
      "no update\n",
      "curr 0.9623541887592789 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.1\n",
      "Accuracy score (validation): 0.962\n",
      "no update\n",
      "curr 0.9618239660657476 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.15\n",
      "Accuracy score (validation): 0.963\n",
      "no update\n",
      "curr 0.9634146341463414 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.2\n",
      "Accuracy score (validation): 0.966\n",
      "no update\n",
      "curr 0.9655355249204666 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.25\n",
      "Accuracy score (validation): 0.963\n",
      "no update\n",
      "curr 0.9634146341463414 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.3\n",
      "Accuracy score (validation): 0.961\n",
      "no update\n",
      "curr 0.9612937433722163 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.35\n",
      "Accuracy score (validation): 0.962\n",
      "no update\n",
      "curr 0.9623541887592789 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.4\n",
      "Accuracy score (validation): 0.959\n",
      "no update\n",
      "curr 0.9591728525980912 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.45\n",
      "Accuracy score (validation): 0.960\n",
      "no update\n",
      "curr 0.9602332979851538 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.5\n",
      "Accuracy score (validation): 0.960\n",
      "no update\n",
      "curr 0.9602332979851538 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.55\n",
      "Accuracy score (validation): 0.960\n",
      "no update\n",
      "curr 0.9602332979851538 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.6\n",
      "Accuracy score (validation): 0.962\n",
      "no update\n",
      "curr 0.9618239660657476 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.65\n",
      "Accuracy score (validation): 0.955\n",
      "no update\n",
      "curr 0.954931071049841 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.7\n",
      "Accuracy score (validation): 0.956\n",
      "no update\n",
      "curr 0.9559915164369035 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.75\n",
      "Accuracy score (validation): 0.953\n",
      "no update\n",
      "curr 0.953340402969247 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.8\n",
      "Accuracy score (validation): 0.959\n",
      "no update\n",
      "curr 0.95864262990456 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  0.85\n",
      "Accuracy score (validation): 0.951\n",
      "no update\n",
      "curr 0.9512195121951219 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n",
      "Learning rate:  1\n",
      "Accuracy score (validation): 0.956\n",
      "no update\n",
      "curr 0.9559915164369035 pickle 0.9904559915164369\n",
      "[1632    2   16  236]\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65,0.7, 0.75, 0.8, 0.85, 1]\n",
    "\n",
    "parameters={\n",
    "   \"n_estimators\":100, # 200 kind of overfits I think\n",
    "    \"max_features\":2,\n",
    "    \"max_depth\":6,\n",
    "    \"random_state\":0,\n",
    "    \"subsample\":0.8,\n",
    "    'lambda': 0.5, # regularization?\n",
    "    'alpha': 0.5\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    xgBoost = XGBClassifier(n_estimators=parameters['n_estimators'], \n",
    "    learning_rate=learning_rate, \n",
    "    max_depth=parameters['max_depth'], random_state=parameters['random_state'], \n",
    "    subsample=parameters['subsample'], \n",
    "    )\n",
    "\n",
    "    parameters['learning_rate']=learning_rate\n",
    "    xgBoost.fit(X_train, y_train)\n",
    "\n",
    "    # ALWAYS reset feature names\n",
    "    cols_when_model_builds = xgBoost.get_booster().feature_names\n",
    "    X_test=X_test[cols_when_model_builds]\n",
    "\n",
    "    testingAcc = accuracy_score(y_test, xgBoost.predict(X_test))\n",
    "    trainingAcc = accuracy_score(y_train, xgBoost.predict(X_train))\n",
    "    \n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    # print(\"Accuracy score (training): {0:.3f}\".format(trainingAcc))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(testingAcc))\n",
    "    # print(f\"Feature importance {gradBoost.feature_importances_}\")\n",
    "\n",
    "    # pickle.dump(gradBoost, open('gradBoost.pkl', 'wb'))\n",
    "    saveModel(xgBoost, \"xgBoost\", X_test, y_test, parameters, xgBoost=True, dir=\"models/synthetic_data_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 0, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3}\n",
    "\"\"\"\n",
    "kmer = 4\n",
    "ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "parameters={\n",
    "   'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 0, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "param_test1 = {'n_estimators':range(100,140,10), 'learning_rate':[0.1,0.15,0.2], 'subsample':[0.8,0.85,0.9], 'max_depth':range(6,9,1), 'min_samples_split':range(10,40,10), 'max_features':range(2, 5)}\n",
    "\n",
    "gradBoost = GridSearchCV(estimator = GradientBoostingClassifier(\n",
    "    n_estimators=parameters['n_estimators'], max_features=parameters['max_features'], random_state=parameters['random_state']), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=-1, cv=5, verbose=10)\n",
    "\n",
    "# parameters['learning_rate']=learning_rate\n",
    "gradBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.15, 'max_depth': 8, 'max_features': 3, 'min_samples_split': 30, 'n_estimators': 130, 'subsample': 0.8}\n",
      "GradientBoostingClassifier\n",
      "gradboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918 (0.015)\n",
      "tn: 1864, fp: 18, fn: 113, tp: 241\n",
      "0.918\n",
      "GradientBoostingClassifier\n",
      "gradboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.920 (0.014)\n",
      "tn: 1877, fp: 5, fn: 33, tp: 321\n",
      "0.92\n",
      "GradientBoostingClassifier\n",
      "gradboost\n",
      "precision recall: 0.9836942204649143\n",
      "roc: 0.9945394069297598\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00548521 0.00180334 0.00079118 ... 0.00184853 0.00543782 0.00500435]\n",
      "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.0010627 , 0.0010627 , 0.00159405, 0.00159405,\n",
      "       0.00265675, 0.00265675, 0.0031881 , 0.0031881 , 0.00371945,\n",
      "       0.0042508 , 0.0042508 , 0.0053135 , 0.0053135 , 0.00584485,\n",
      "       0.00584485, 0.0063762 , 0.0063762 , 0.00690755, 0.00690755,\n",
      "       0.00797024, 0.00797024, 0.00903294, 0.00903294, 0.00956429,\n",
      "       0.00956429, 0.01328374, 0.01328374, 0.01434644, 0.01540914,\n",
      "       0.01594049, 0.01594049, 0.01647184, 0.01647184, 0.02284803,\n",
      "       0.02284803, 0.03081828, 0.03081828, 0.03241233, 0.03347503,\n",
      "       0.03560043, 0.03560043, 0.03772582, 0.03772582, 0.03931987,\n",
      "       0.04038257, 0.04463337, 0.04463337, 0.04994687, 0.05100956,\n",
      "       0.05366631, 0.05472901, 0.05738576, 0.05738576, 0.09564293,\n",
      "       0.09564293, 0.09989373, 0.10095643, 0.10095643, 0.11583422,\n",
      "       0.11689692, 0.14399575, 0.14399575, 0.14612115, 0.14718385,\n",
      "       0.15090329, 0.15196599, 0.15515409, 0.15621679, 0.16365569,\n",
      "       0.16471838, 0.18331562, 0.18437832, 0.18597237, 0.18597237,\n",
      "       0.19978746, 0.20085016, 0.21466525, 0.21572795, 0.2162593 ,\n",
      "       0.2162593 , 0.22316684, 0.22316684, 0.22635494, 0.22741764,\n",
      "       0.24760893, 0.24867163, 0.35600425, 0.35706695, 0.39319872,\n",
      "       0.39426142, 0.48937301, 0.48937301, 0.57757705, 0.57863974,\n",
      "       0.86928799, 0.87035069, 0.87353879, 0.87513284, 0.88788523,\n",
      "       0.88894793, 0.90329437, 0.90435707, 0.97396387, 0.97502657,\n",
      "       1.        ]), array([0.        , 0.00282486, 0.31920904, 0.33050847, 0.39265537,\n",
      "       0.39830508, 0.5480226 , 0.55367232, 0.61016949, 0.61581921,\n",
      "       0.82485876, 0.82485876, 0.86440678, 0.86440678, 0.88983051,\n",
      "       0.88983051, 0.90677966, 0.90960452, 0.91525424, 0.9180791 ,\n",
      "       0.9180791 , 0.92090395, 0.92090395, 0.92372881, 0.92372881,\n",
      "       0.92937853, 0.92937853, 0.93220339, 0.93220339, 0.93785311,\n",
      "       0.93785311, 0.94067797, 0.94067797, 0.94350282, 0.94350282,\n",
      "       0.94632768, 0.94632768, 0.94915254, 0.94915254, 0.94915254,\n",
      "       0.94915254, 0.95480226, 0.95480226, 0.96045198, 0.96045198,\n",
      "       0.96327684, 0.96327684, 0.96610169, 0.96610169, 0.96610169,\n",
      "       0.96610169, 0.96892655, 0.96892655, 0.97175141, 0.97175141,\n",
      "       0.97175141, 0.97175141, 0.97740113, 0.97740113, 0.97740113,\n",
      "       0.97740113, 0.97740113, 0.97740113, 0.98022599, 0.98022599,\n",
      "       0.98305085, 0.98305085, 0.98305085, 0.98587571, 0.98587571,\n",
      "       0.98587571, 0.98587571, 0.98870056, 0.98870056, 0.98870056,\n",
      "       0.98870056, 0.98870056, 0.98870056, 0.98870056, 0.98870056,\n",
      "       0.98870056, 0.98870056, 0.98870056, 0.98870056, 0.99152542,\n",
      "       0.99152542, 0.99152542, 0.99152542, 0.99152542, 0.99152542,\n",
      "       0.99435028, 0.99435028, 0.99717514, 0.99717514, 0.99717514,\n",
      "       0.99717514, 0.99717514, 0.99717514, 0.99717514, 0.99717514,\n",
      "       0.99717514, 0.99717514, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        ]), 0.9945394069297598)\n",
      "GradientBoostingClassifier\n",
      "gradboost\n",
      "precision recall: 0.8814728508903781\n",
      "roc: 0.9599206277730747\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01436602 0.00302472 0.00117355 ... 0.00078883 0.02261897 0.0195416 ]\n",
      "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 5.31349628e-04, 5.31349628e-04, 5.31349628e-04,\n",
      "       5.31349628e-04, 1.06269926e-03, 1.06269926e-03, 1.59404888e-03,\n",
      "       1.59404888e-03, 2.12539851e-03, 2.12539851e-03, 2.65674814e-03,\n",
      "       2.65674814e-03, 3.18809777e-03, 3.18809777e-03, 3.71944740e-03,\n",
      "       3.71944740e-03, 4.25079702e-03, 4.25079702e-03, 4.78214665e-03,\n",
      "       4.78214665e-03, 6.37619554e-03, 6.37619554e-03, 6.90754516e-03,\n",
      "       6.90754516e-03, 7.97024442e-03, 7.97024442e-03, 9.03294368e-03,\n",
      "       9.03294368e-03, 9.03294368e-03, 9.03294368e-03, 9.03294368e-03,\n",
      "       9.03294368e-03, 9.56429330e-03, 9.56429330e-03, 9.56429330e-03,\n",
      "       9.56429330e-03, 9.56429330e-03, 1.06269926e-02, 1.06269926e-02,\n",
      "       1.16896918e-02, 1.16896918e-02, 1.22210414e-02, 1.22210414e-02,\n",
      "       1.32837407e-02, 1.32837407e-02, 1.43464400e-02, 1.54091392e-02,\n",
      "       1.59404888e-02, 1.59404888e-02, 1.64718385e-02, 1.64718385e-02,\n",
      "       1.75345377e-02, 1.91285866e-02, 1.91285866e-02, 2.12539851e-02,\n",
      "       2.12539851e-02, 2.55047821e-02, 2.55047821e-02, 2.60361318e-02,\n",
      "       2.60361318e-02, 2.65674814e-02, 2.76301807e-02, 2.86928799e-02,\n",
      "       2.86928799e-02, 2.92242295e-02, 2.92242295e-02, 3.08182784e-02,\n",
      "       3.08182784e-02, 3.29436769e-02, 3.29436769e-02, 3.34750266e-02,\n",
      "       3.34750266e-02, 3.40063762e-02, 3.40063762e-02, 3.50690755e-02,\n",
      "       3.50690755e-02, 3.66631243e-02, 3.66631243e-02, 3.71944740e-02,\n",
      "       3.71944740e-02, 3.82571732e-02, 3.82571732e-02, 3.87885228e-02,\n",
      "       3.87885228e-02, 4.03825717e-02, 4.03825717e-02, 4.19766206e-02,\n",
      "       4.19766206e-02, 4.25079702e-02, 4.25079702e-02, 4.67587673e-02,\n",
      "       4.67587673e-02, 4.88841658e-02, 4.88841658e-02, 4.94155154e-02,\n",
      "       4.94155154e-02, 5.04782147e-02, 5.41976621e-02, 5.41976621e-02,\n",
      "       5.52603613e-02, 5.52603613e-02, 5.79171095e-02, 5.79171095e-02,\n",
      "       5.89798087e-02, 5.89798087e-02, 6.16365569e-02, 6.16365569e-02,\n",
      "       6.37619554e-02, 6.37619554e-02, 6.42933050e-02, 6.42933050e-02,\n",
      "       6.48246546e-02, 6.58873539e-02, 6.80127524e-02, 6.80127524e-02,\n",
      "       7.33262487e-02, 7.33262487e-02, 7.43889479e-02, 7.49202976e-02,\n",
      "       7.59829968e-02, 7.70456961e-02, 7.70456961e-02, 8.18278427e-02,\n",
      "       8.18278427e-02, 8.39532412e-02, 8.39532412e-02, 8.82040383e-02,\n",
      "       8.82040383e-02, 8.87353879e-02, 8.87353879e-02, 9.45802338e-02,\n",
      "       9.45802338e-02, 9.56429330e-02, 9.56429330e-02, 9.88310308e-02,\n",
      "       9.98937301e-02, 1.00425080e-01, 1.00425080e-01, 1.09458023e-01,\n",
      "       1.09458023e-01, 1.16365569e-01, 1.16365569e-01, 1.19022317e-01,\n",
      "       1.20085016e-01, 1.21679065e-01, 1.21679065e-01, 1.22741764e-01,\n",
      "       1.23804463e-01, 1.28055260e-01, 1.28055260e-01, 1.29649309e-01,\n",
      "       1.29649309e-01, 1.30712009e-01, 1.30712009e-01, 1.32837407e-01,\n",
      "       1.33900106e-01, 1.36025505e-01, 1.37088204e-01, 1.39213603e-01,\n",
      "       1.39213603e-01, 1.40807651e-01, 1.40807651e-01, 1.51965994e-01,\n",
      "       1.51965994e-01, 1.57279490e-01, 1.57279490e-01, 1.68969182e-01,\n",
      "       1.68969182e-01, 1.72688629e-01, 1.72688629e-01, 1.74814028e-01,\n",
      "       1.74814028e-01, 1.81190223e-01, 1.81190223e-01, 1.91285866e-01,\n",
      "       1.91285866e-01, 1.99256111e-01, 1.99256111e-01, 2.14665250e-01,\n",
      "       2.14665250e-01, 2.19447396e-01, 2.19447396e-01, 2.22635494e-01,\n",
      "       2.22635494e-01, 2.23698193e-01, 2.24760893e-01, 2.25823592e-01,\n",
      "       2.25823592e-01, 2.26354942e-01, 2.26354942e-01, 2.27948990e-01,\n",
      "       2.28480340e-01, 2.43358130e-01, 2.43358130e-01, 2.46014878e-01,\n",
      "       2.47077577e-01, 2.49734325e-01, 2.49734325e-01, 2.63018066e-01,\n",
      "       2.64080765e-01, 2.74176408e-01, 2.74176408e-01, 2.84272051e-01,\n",
      "       2.84272051e-01, 2.93304995e-01, 2.93304995e-01, 3.17215728e-01,\n",
      "       3.17215728e-01, 3.20935175e-01, 3.20935175e-01, 3.23591923e-01,\n",
      "       3.23591923e-01, 3.25717322e-01, 3.25717322e-01, 3.29968119e-01,\n",
      "       3.29968119e-01, 3.74601488e-01, 3.74601488e-01, 3.80977683e-01,\n",
      "       3.80977683e-01, 3.95855473e-01, 3.95855473e-01, 4.04888417e-01,\n",
      "       4.04888417e-01, 4.09139214e-01, 4.09139214e-01, 4.13921360e-01,\n",
      "       4.14984060e-01, 4.22422954e-01, 4.23485654e-01, 6.74282678e-01,\n",
      "       6.75345377e-01, 8.17747078e-01, 8.20403826e-01, 8.23060574e-01,\n",
      "       8.24123273e-01, 8.41657811e-01, 8.41657811e-01, 8.42720510e-01,\n",
      "       8.88947928e-01, 8.88947928e-01, 9.33049947e-01, 9.34112646e-01,\n",
      "       9.92561105e-01, 9.93623804e-01, 1.00000000e+00]), array([0.        , 0.00282486, 0.11864407, 0.12429379, 0.27118644,\n",
      "       0.27118644, 0.31073446, 0.31638418, 0.4180791 , 0.4180791 ,\n",
      "       0.43220339, 0.43220339, 0.44350282, 0.44350282, 0.46892655,\n",
      "       0.46892655, 0.48022599, 0.48022599, 0.54237288, 0.54237288,\n",
      "       0.5480226 , 0.5480226 , 0.55932203, 0.55932203, 0.57344633,\n",
      "       0.57344633, 0.5819209 , 0.5819209 , 0.60451977, 0.60451977,\n",
      "       0.61864407, 0.61864407, 0.6299435 , 0.63559322, 0.65819209,\n",
      "       0.66384181, 0.66949153, 0.66949153, 0.67231638, 0.6779661 ,\n",
      "       0.68926554, 0.69491525, 0.69491525, 0.69774011, 0.69774011,\n",
      "       0.70338983, 0.70338983, 0.71186441, 0.71186441, 0.71468927,\n",
      "       0.71468927, 0.71468927, 0.71468927, 0.7259887 , 0.7259887 ,\n",
      "       0.72881356, 0.72881356, 0.72881356, 0.73163842, 0.73163842,\n",
      "       0.74293785, 0.74293785, 0.74576271, 0.74576271, 0.74858757,\n",
      "       0.74858757, 0.74858757, 0.74858757, 0.75423729, 0.75423729,\n",
      "       0.75706215, 0.75706215, 0.75988701, 0.75988701, 0.76271186,\n",
      "       0.76271186, 0.76836158, 0.77118644, 0.77683616, 0.77683616,\n",
      "       0.77966102, 0.77966102, 0.78531073, 0.78531073, 0.78813559,\n",
      "       0.78813559, 0.79096045, 0.79096045, 0.79378531, 0.79378531,\n",
      "       0.80225989, 0.80225989, 0.8079096 , 0.8079096 , 0.81073446,\n",
      "       0.81073446, 0.81355932, 0.81355932, 0.81638418, 0.81638418,\n",
      "       0.8220339 , 0.8220339 , 0.8220339 , 0.82485876, 0.82485876,\n",
      "       0.83615819, 0.83615819, 0.83898305, 0.83898305, 0.84180791,\n",
      "       0.84180791, 0.84463277, 0.84463277, 0.84745763, 0.84745763,\n",
      "       0.85028249, 0.85028249, 0.85028249, 0.85028249, 0.85310734,\n",
      "       0.85310734, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
      "       0.85875706, 0.86158192, 0.86158192, 0.86723164, 0.86723164,\n",
      "       0.8700565 , 0.8700565 , 0.87288136, 0.87288136, 0.87570621,\n",
      "       0.87570621, 0.87853107, 0.87853107, 0.88135593, 0.88135593,\n",
      "       0.88135593, 0.88135593, 0.88418079, 0.88418079, 0.88700565,\n",
      "       0.88700565, 0.88983051, 0.88983051, 0.88983051, 0.88983051,\n",
      "       0.89548023, 0.89548023, 0.89548023, 0.89548023, 0.89830508,\n",
      "       0.89830508, 0.90112994, 0.90112994, 0.9039548 , 0.9039548 ,\n",
      "       0.9039548 , 0.9039548 , 0.9039548 , 0.9039548 , 0.90677966,\n",
      "       0.90677966, 0.90960452, 0.90960452, 0.91242938, 0.91242938,\n",
      "       0.91525424, 0.91525424, 0.9180791 , 0.9180791 , 0.92090395,\n",
      "       0.92090395, 0.92372881, 0.92372881, 0.92655367, 0.92655367,\n",
      "       0.92937853, 0.92937853, 0.93220339, 0.93220339, 0.93785311,\n",
      "       0.93785311, 0.94067797, 0.94067797, 0.94350282, 0.94350282,\n",
      "       0.94350282, 0.94350282, 0.94632768, 0.94632768, 0.94915254,\n",
      "       0.94915254, 0.9519774 , 0.9519774 , 0.95480226, 0.95480226,\n",
      "       0.95480226, 0.95480226, 0.95762712, 0.95762712, 0.95762712,\n",
      "       0.95762712, 0.96045198, 0.96045198, 0.96327684, 0.96327684,\n",
      "       0.96610169, 0.96610169, 0.96892655, 0.96892655, 0.97175141,\n",
      "       0.97175141, 0.97457627, 0.97457627, 0.97740113, 0.97740113,\n",
      "       0.98022599, 0.98022599, 0.98305085, 0.98305085, 0.98587571,\n",
      "       0.98587571, 0.98870056, 0.98870056, 0.99152542, 0.99152542,\n",
      "       0.99435028, 0.99435028, 0.99435028, 0.99435028, 0.99435028,\n",
      "       0.99435028, 0.99435028, 0.99435028, 0.99435028, 0.99435028,\n",
      "       0.99435028, 0.99435028, 0.99717514, 0.99717514, 0.99717514,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        ]), 0.9599206277730747)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "{'learning_rate': 0.15, 'max_depth': 8, 'max_features': 3, 'min_samples_split': 30, 'n_estimators': 130, 'subsample': 0.8}\n",
    "\"\"\"\n",
    "print(gradBoost.best_params_)\n",
    "print(validation_utils.cross_validate(gradBoost.best_estimator_, X_test, y_test))\n",
    "pi = pickle.load(open('models/curr_models/nardus_gridsearch.pkl', 'rb'))\n",
    "print(validation_utils.cross_validate(pi.best_estimator_, X_test, y_test))\n",
    "print(validation_utils.draw_roc_curve(pi.best_estimator_, X_test, y_test))\n",
    "print(validation_utils.draw_roc_curve(gradBoost.best_estimator_, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "gradboost\n",
      "GradientBoostingClassifier\n",
      "gradboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918 (0.015)\n",
      "tn: 1864, fp: 18, fn: 113, tp: 241\n",
      "0.918\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'min_samples_split': 20, 'n_estimators': 140, 'subsample': 0.9}\n",
      "GradientBoostingClassifier\n",
      "gradboost\n",
      "Accuracy: 0.920 (0.014)\n",
      "tn: 1877, fp: 5, fn: 33, tp: 321\n",
      "0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(gradBoost, open('models/test/nardus_gridsearch.pkl', 'wb'))\n",
    "\n",
    "X_test = data_utils.transform_data(gradBoost.best_estimator_, X_test)\n",
    "print(validation_utils.cross_validate(gradBoost.best_estimator_, X_test, y_test))\n",
    "print(pi.best_params_)\n",
    "print(validation_utils.cross_validate(pi.best_estimator_, X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
