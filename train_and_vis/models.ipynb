{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/Documents/coding/scires/project/utils\n",
      "/Users/benjaminli/Documents/coding/scires/project\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, balanced_accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score, f1_score, recall_score, precision_score, brier_score_loss, average_precision_score, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "from os import path\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'project'):\n",
    "    %cd utils\n",
    "elif (os.path.abspath('').split('/')[-1] == 'train_and_vis'):\n",
    "    %cd ../utils\n",
    "\n",
    "import query_utils\n",
    "import model_utils\n",
    "import validation_utils\n",
    "import data_utils\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'utils'):\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data creation\n",
    "Performed with CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m isZoonotic \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39misZoonotic\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m][:\u001b[39m1200\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m isZoonotic \u001b[39m=\u001b[39m isZoonotic\u001b[39m.\u001b[39mloc[:, isZoonotic\u001b[39m.\u001b[39mcolumns \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39misZoonotic\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(isZoonotic)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "isZoonotic = df.loc[df['isZoonotic']==1][:1200]\n",
    "isZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(isZoonotic)\n",
    "\n",
    "posGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "posGanModel.fit(isZoonotic)\n",
    "\n",
    "# check if current model is better than pickled model\n",
    "posGanModel.save('models/curr_models/posGanModel.pkl')\n",
    "\n",
    "notZoonotic = df.loc[df['isZoonotic']==0][:3000]\n",
    "notZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(notZoonotic)\n",
    "\n",
    "negGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "negGanModel.fit(notZoonotic)\n",
    "negGanModel.save('models/curr_models/negGanModel.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset retrieval\n",
    "Workings of the function is packaged into data_utils (for readability). Data is generated within \"process_data.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: /Users/benjaminli/Documents/coding/scires/project\n"
     ]
    }
   ],
   "source": [
    "dataset = data_utils.retrieveMerged(dir='data/')\n",
    "# datasets = data_utils.retrieveAllDatasets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep track of scores of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelScores = {}\n",
    "import json\n",
    "modelScores = pickle.load(open('score_df.pkl', 'rb'))\n",
    "modelScores = modelScores.T.to_dict()\n",
    "modelScores\n",
    "\n",
    "score_df = pickle.load(open('score_df.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate & validate performance of KNN (baseline) on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['f1-3', 'f2-3', 'f3-3', 'f1-4', 'f2-4', 'f3-4', 'f1-5', 'f2-5', 'f3-5', 'f1-6', 'f2-6', 'f3-6'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.006434345245361328\n",
      "score_time 0.23126916885375975\n",
      "test_recall 0.8065397385785735\n",
      "test_f1 0.601296422615953\n",
      "test_accuracy 0.8332461512921254\n",
      "test_precision 0.48886637902036434\n",
      "test_roc_auc 0.8221471395149335\n",
      "test_neg_brier_score -0.1667538487078745\n",
      "fit_time 0.006704187393188477\n",
      "score_time 0.07589864730834961\n",
      "test_recall 0.8065502458706343\n",
      "test_f1 0.5710774429523003\n",
      "test_accuracy 0.8175344806596204\n",
      "test_precision 0.4473588072765174\n",
      "test_roc_auc 0.8129614190277772\n",
      "test_neg_brier_score -0.1824655193403796\n",
      "fit_time 0.006073999404907227\n",
      "score_time 0.03609743118286133\n",
      "test_recall 0.8169524650107174\n",
      "test_f1 0.6050472649993741\n",
      "test_accuracy 0.8296698577831887\n",
      "test_precision 0.4922435812769397\n",
      "test_roc_auc 0.8243815709753642\n",
      "test_neg_brier_score -0.17033014221681148\n",
      "fit_time 0.02127671241760254\n",
      "score_time 0.34290475845336915\n",
      "test_recall 0.8065292312865127\n",
      "test_f1 0.5827334292475597\n",
      "test_accuracy 0.820355265342261\n",
      "test_precision 0.4651860242243905\n",
      "test_roc_auc 0.8146019849332949\n",
      "test_neg_brier_score -0.17964473465773895\n",
      "fit_time 0.02101101875305176\n",
      "score_time 0.09459757804870605\n",
      "test_recall 0.843573740175682\n",
      "test_f1 0.6001263330822514\n",
      "test_accuracy 0.8280734436389796\n",
      "test_precision 0.47083773179337507\n",
      "test_roc_auc 0.8345001337091948\n",
      "test_neg_brier_score -0.17192655636102044\n",
      "fit_time 0.02068023681640625\n",
      "score_time 0.06336283683776855\n",
      "test_recall 0.8363930567814062\n",
      "test_f1 0.6029510913590906\n",
      "test_accuracy 0.8234594654418682\n",
      "test_precision 0.48454881636484626\n",
      "test_roc_auc 0.8288184326284576\n",
      "test_neg_brier_score -0.17654053455813182\n",
      "fit_time 0.10765976905822754\n",
      "score_time 0.6587644577026367\n",
      "test_recall 0.8286260664901441\n",
      "test_f1 0.5803285578110288\n",
      "test_accuracy 0.8070848541862652\n",
      "test_precision 0.4582952432916074\n",
      "test_roc_auc 0.8160191422159031\n",
      "test_neg_brier_score -0.1929151458137347\n",
      "fit_time 0.10547595024108887\n",
      "score_time 0.15437617301940917\n",
      "test_recall 0.793590551842979\n",
      "test_f1 0.5599588005008878\n",
      "test_accuracy 0.8161227159537381\n",
      "test_precision 0.4349396318273655\n",
      "test_roc_auc 0.8067567508802128\n",
      "test_neg_brier_score -0.18387728404626197\n",
      "fit_time 0.10336565971374512\n",
      "score_time 0.142830753326416\n",
      "test_recall 0.8337956541840036\n",
      "test_f1 0.5741466219933697\n",
      "test_accuracy 0.803982380609817\n",
      "test_precision 0.4512758228311407\n",
      "test_roc_auc 0.8163474693594758\n",
      "test_neg_brier_score -0.19601761939018317\n",
      "fit_time 0.5757604598999023\n",
      "score_time 1.9945283889770509\n",
      "test_recall 0.8682175429748245\n",
      "test_f1 0.5484528305880176\n",
      "test_accuracy 0.7672767196059986\n",
      "test_precision 0.4102172217413065\n",
      "test_roc_auc 0.809177566203978\n",
      "test_neg_brier_score -0.23272328039400145\n",
      "fit_time 0.5608635902404785\n",
      "score_time 0.49248366355895995\n",
      "test_recall 0.7313474551338629\n",
      "test_f1 0.4674971347574801\n",
      "test_accuracy 0.7533597033921753\n",
      "test_precision 0.34594140675944357\n",
      "test_roc_auc 0.7442097759984119\n",
      "test_neg_brier_score -0.24664029660782472\n",
      "fit_time 0.5713346481323243\n",
      "score_time 0.5241081714630127\n",
      "test_recall 0.8902912621359225\n",
      "test_f1 0.5476721418887871\n",
      "test_accuracy 0.758053500083006\n",
      "test_precision 0.40522346011513644\n",
      "test_roc_auc 0.8129497037151818\n",
      "test_neg_brier_score -0.2419464999169941\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        knntest = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors = 1, n_jobs = -1), n_estimators = 1, n_jobs = -1)\n",
    "\n",
    "        # knntest = KNeighborsClassifier(n_neighbors = 1, n_jobs = -1)\n",
    "        knntest.fit(X_train, y_train)\n",
    "        # print(knntest.score(X_test, y_test))\n",
    "        x = cross_validate(knntest, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "        \n",
    "        name = f'knn_{feature}_{kmer}'\n",
    "        \n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn_f1_4': {'fit_time': 0.556103515625, 'score_time': 2.1676071643829347, 'test_recall': 0.8967847686294288, 'test_f1': 0.5506206040204477, 'test_accuracy': 0.7598422223451939, 'test_precision': 0.4068609142945686, 'test_roc_auc': 0.8166917789212086, 'test_neg_brier_score': -0.24015777765480606}, 'knn_f2_4': {'fit_time': 0.5469307899475098, 'score_time': 0.5283036708831788, 'test_recall': 0.7209095112007733, 'test_f1': 0.49014203521664257, 'test_accuracy': 0.7846974710862709, 'test_precision': 0.37431163097253817, 'test_roc_auc': 0.7581982888970294, 'test_neg_brier_score': -0.2153025289137292}, 'knn_f3_4': {'fit_time': 0.5275906562805176, 'score_time': 0.5401241779327393, 'test_recall': 0.8695246501071743, 'test_f1': 0.5344595291629525, 'test_accuracy': 0.7597513806651541, 'test_precision': 0.39288153362735134, 'test_roc_auc': 0.8053181863634385, 'test_neg_brier_score': -0.24024861933484587}}\n"
     ]
    }
   ],
   "source": [
    "print(modelScores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate & validate performance of random forest (baseline) on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.673237657546997\n",
      "score_time 0.06305813789367676\n",
      "test_recall 0.8033287101248267\n",
      "test_f1 0.6376446981126623\n",
      "test_accuracy 0.8496201427701843\n",
      "test_precision 0.557841501561644\n",
      "test_roc_auc 0.9113908529679753\n",
      "test_neg_brier_score -0.1036142534713076\n",
      "fit_time 0.30217394828796384\n",
      "score_time 0.038896369934082034\n",
      "test_recall 0.7734417685873997\n",
      "test_f1 0.6213791860135606\n",
      "test_accuracy 0.8658125394278124\n",
      "test_precision 0.5325331554110591\n",
      "test_roc_auc 0.9063302693213835\n",
      "test_neg_brier_score -0.1044856117846273\n",
      "fit_time 0.28589487075805664\n",
      "score_time 0.03607010841369629\n",
      "test_recall 0.8026772580170638\n",
      "test_f1 0.635436790839013\n",
      "test_accuracy 0.8511267777101434\n",
      "test_precision 0.5558658633147152\n",
      "test_roc_auc 0.9113416202038491\n",
      "test_neg_brier_score -0.10388738292291518\n",
      "fit_time 0.3828004837036133\n",
      "score_time 0.04037809371948242\n",
      "test_recall 0.8247236582188038\n",
      "test_f1 0.6207048310771551\n",
      "test_accuracy 0.83861386752255\n",
      "test_precision 0.5229388200064958\n",
      "test_roc_auc 0.910494420772485\n",
      "test_neg_brier_score -0.10967277864423663\n",
      "fit_time 0.44559249877929685\n",
      "score_time 0.038927984237670896\n",
      "test_recall 0.7935485226747362\n",
      "test_f1 0.6095630801166361\n",
      "test_accuracy 0.8536746831940679\n",
      "test_precision 0.5078574652531154\n",
      "test_roc_auc 0.9124865212318658\n",
      "test_neg_brier_score -0.10795246804714738\n",
      "fit_time 0.36256895065307615\n",
      "score_time 0.03960065841674805\n",
      "test_recall 0.8104379439330897\n",
      "test_f1 0.6122819346017718\n",
      "test_accuracy 0.8375780421670079\n",
      "test_precision 0.517284226258682\n",
      "test_roc_auc 0.9098157387600138\n",
      "test_neg_brier_score -0.10799163270211942\n",
      "fit_time 0.6000373840332032\n",
      "score_time 0.04732570648193359\n",
      "test_recall 0.8156495607951919\n",
      "test_f1 0.5989438606391093\n",
      "test_accuracy 0.830617232029218\n",
      "test_precision 0.49094791592883613\n",
      "test_roc_auc 0.9037483385236003\n",
      "test_neg_brier_score -0.11737497661889215\n",
      "fit_time 0.6895964622497559\n",
      "score_time 0.04699277877807617\n",
      "test_recall 0.7864371874080611\n",
      "test_f1 0.5914793560904524\n",
      "test_accuracy 0.8407826904985889\n",
      "test_precision 0.4841031271214792\n",
      "test_roc_auc 0.9049874547443355\n",
      "test_neg_brier_score -0.11900806547949752\n",
      "fit_time 0.5398379325866699\n",
      "score_time 0.048029422760009766\n",
      "test_recall 0.8020089942420039\n",
      "test_f1 0.5919979110851005\n",
      "test_accuracy 0.8280752587017874\n",
      "test_precision 0.4869791095986976\n",
      "test_roc_auc 0.9015821871132556\n",
      "test_neg_brier_score -0.11647759820707211\n",
      "fit_time 1.7328995704650878\n",
      "score_time 0.07697968482971192\n",
      "test_recall 0.7864497961585339\n",
      "test_f1 0.5832211992936639\n",
      "test_accuracy 0.8308071938464945\n",
      "test_precision 0.47306123355413465\n",
      "test_roc_auc 0.8918330855185321\n",
      "test_neg_brier_score -0.12688660539427812\n",
      "fit_time 1.8176741123199462\n",
      "score_time 0.07468795776367188\n",
      "test_recall 0.7734480729626361\n",
      "test_f1 0.5789396932651698\n",
      "test_accuracy 0.8373941895855237\n",
      "test_precision 0.47011602095673055\n",
      "test_roc_auc 0.8879940037769811\n",
      "test_neg_brier_score -0.13097873010237399\n",
      "fit_time 1.489657735824585\n",
      "score_time 0.07536168098449707\n",
      "test_recall 0.8033118984575296\n",
      "test_f1 0.5930306595226671\n",
      "test_accuracy 0.8356999391289912\n",
      "test_precision 0.47858867704489666\n",
      "test_roc_auc 0.8958752523398182\n",
      "test_neg_brier_score -0.12601429025510485\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        randforest = BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(randforest, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "        name = f'rf_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 3.2481399536132813\n",
      "score_time 0.015207624435424805\n",
      "test_recall 0.8098222166183332\n",
      "test_f1 0.5993580116185406\n",
      "test_accuracy 0.8287332411045322\n",
      "test_precision 0.49247938747250075\n",
      "test_roc_auc 0.8983555937573016\n",
      "test_neg_brier_score -0.13648852807028594\n",
      "fit_time 3.682933235168457\n",
      "score_time 0.01545543670654297\n",
      "test_recall 0.7974509309460764\n",
      "test_f1 0.5985745962711088\n",
      "test_accuracy 0.8438875546455649\n",
      "test_precision 0.48785963453151826\n",
      "test_roc_auc 0.8971440087235623\n",
      "test_neg_brier_score -0.12304992852125171\n",
      "fit_time 3.7060344219207764\n",
      "score_time 0.014565849304199218\n",
      "test_recall 0.8137288278064977\n",
      "test_f1 0.6115900124135841\n",
      "test_accuracy 0.834283083393282\n",
      "test_precision 0.5106685846240002\n",
      "test_roc_auc 0.9068828343370023\n",
      "test_neg_brier_score -0.1307657871800653\n",
      "fit_time 3.781730365753174\n",
      "score_time 0.01956338882446289\n",
      "test_recall 0.8156201403774219\n",
      "test_f1 0.6104394394548548\n",
      "test_accuracy 0.8383293010901444\n",
      "test_precision 0.5084032815414197\n",
      "test_roc_auc 0.9124100464192155\n",
      "test_neg_brier_score -0.12665033904950382\n",
      "fit_time 4.854494190216064\n",
      "score_time 0.01835479736328125\n",
      "test_recall 0.7844765267095364\n",
      "test_f1 0.6006880549724263\n",
      "test_accuracy 0.8500970173205689\n",
      "test_precision 0.4947263503937707\n",
      "test_roc_auc 0.9064532988976353\n",
      "test_neg_brier_score -0.11687840443501238\n",
      "fit_time 3.8369383811950684\n",
      "score_time 0.018232250213623048\n",
      "test_recall 0.8091371411759761\n",
      "test_f1 0.5954835696761532\n",
      "test_accuracy 0.8257223617951415\n",
      "test_precision 0.4950999268794776\n",
      "test_roc_auc 0.9034605873383118\n",
      "test_neg_brier_score -0.1374745292269814\n",
      "fit_time 9.465924882888794\n",
      "score_time 0.034711790084838864\n",
      "test_recall 0.812377590047493\n",
      "test_f1 0.5957276641889511\n",
      "test_accuracy 0.8303351889768136\n",
      "test_precision 0.48868606627991606\n",
      "test_roc_auc 0.9061718723272761\n",
      "test_neg_brier_score -0.1282699816288476\n",
      "fit_time 8.804008769989014\n",
      "score_time 0.03093862533569336\n",
      "test_recall 0.7916025721850964\n",
      "test_f1 0.5993536834354649\n",
      "test_accuracy 0.8464271816722926\n",
      "test_precision 0.49043677764000504\n",
      "test_roc_auc 0.9004855606444698\n",
      "test_neg_brier_score -0.1197660981286734\n",
      "fit_time 7.592995834350586\n",
      "score_time 0.029067420959472658\n",
      "test_recall 0.833158912285126\n",
      "test_f1 0.5929275765570411\n",
      "test_accuracy 0.8235584527696309\n",
      "test_precision 0.4726514172596331\n",
      "test_roc_auc 0.9048827889306967\n",
      "test_neg_brier_score -0.1328818219277872\n",
      "fit_time 17.82449336051941\n",
      "score_time 0.11508121490478515\n",
      "test_recall 0.785810952801244\n",
      "test_f1 0.5774907223882504\n",
      "test_accuracy 0.8246897238669693\n",
      "test_precision 0.46652488051625063\n",
      "test_roc_auc 0.8916577906938631\n",
      "test_neg_brier_score -0.13109756176952062\n",
      "fit_time 20.36616539955139\n",
      "score_time 0.10566897392272949\n",
      "test_recall 0.7786344723237926\n",
      "test_f1 0.5987444155949405\n",
      "test_accuracy 0.8515098002324167\n",
      "test_precision 0.4932435177271969\n",
      "test_roc_auc 0.8988902599449696\n",
      "test_neg_brier_score -0.11388828005949392\n",
      "fit_time 17.45177388191223\n",
      "score_time 0.11109700202941894\n",
      "test_recall 0.7961648383978481\n",
      "test_f1 0.5917210656796733\n",
      "test_accuracy 0.8309933484588568\n",
      "test_precision 0.48462525924606464\n",
      "test_roc_auc 0.8970751434572094\n",
      "test_neg_brier_score -0.12559913663123567\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        xgb1 = BalancedBaggingClassifier(base_estimator=XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    "        ), n_estimators=1, n_jobs=-1)\n",
    "        xgb1.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(xgb1, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "        name = f'xgb_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rf_f1_3', 'rf_f2_3', 'rf_f3_3', 'rf_f1_4', 'rf_f2_4', 'rf_f3_4', 'rf_f1_5', 'rf_f2_5', 'rf_f3_5', 'rf_f1_6', 'rf_f2_6', 'rf_f3_6', 'xgb_f1_3', 'xgb_f2_3', 'xgb_f3_3', 'xgb_f1_4', 'xgb_f2_4', 'xgb_f3_4', 'xgb_f1_5', 'xgb_f2_5', 'xgb_f3_5', 'xgb_f1_6', 'xgb_f2_6', 'xgb_f3_6'])\n"
     ]
    }
   ],
   "source": [
    "print(modelScores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 5.641985559463501\n",
      "score_time 0.3429579257965088\n",
      "test_recall 0.7909805404951037\n",
      "test_f1 0.6129231538456255\n",
      "test_accuracy 0.8570628299485363\n",
      "test_precision 0.5071047997117664\n",
      "test_roc_auc 0.915887930020903\n",
      "test_neg_brier_score -0.10401978874103301\n",
      "fit_time 12.340601348876953\n",
      "score_time 0.29123740196228026\n",
      "test_recall 0.7689047198755936\n",
      "test_f1 0.6527537339157734\n",
      "test_accuracy 0.8850068728902662\n",
      "test_precision 0.5774773243160104\n",
      "test_roc_auc 0.9211042043255068\n",
      "test_neg_brier_score -0.08127809550056461\n",
      "fit_time 12.69257574081421\n",
      "score_time 0.34751105308532715\n",
      "test_recall 0.8383453116462825\n",
      "test_f1 0.6473697885556842\n",
      "test_accuracy 0.8494335011897516\n",
      "test_precision 0.5495825398084325\n",
      "test_roc_auc 0.9188979100863088\n",
      "test_neg_brier_score -0.10668787556757205\n",
      "fit_time 9.182259464263916\n",
      "score_time 0.38588614463806153\n",
      "test_recall 0.8072016979783971\n",
      "test_f1 0.6601338755726636\n",
      "test_accuracy 0.8749357534170772\n",
      "test_precision 0.5686347080784393\n",
      "test_roc_auc 0.9236435213170576\n",
      "test_neg_brier_score -0.09125115690858958\n",
      "fit_time 11.08979058265686\n",
      "score_time 0.36149845123291013\n",
      "test_recall 0.7766843189173287\n",
      "test_f1 0.6699328776782045\n",
      "test_accuracy 0.8882084223341267\n",
      "test_precision 0.6028925092633572\n",
      "test_roc_auc 0.9247547799273411\n",
      "test_neg_brier_score -0.08142440889216647\n",
      "fit_time 11.664755201339721\n",
      "score_time 0.34946379661560056\n",
      "test_recall 0.7987475307863657\n",
      "test_f1 0.6308952237003621\n",
      "test_accuracy 0.8528239499750981\n",
      "test_precision 0.5438019065901061\n",
      "test_roc_auc 0.9153417011857522\n",
      "test_neg_brier_score -0.10303714852755086\n",
      "fit_time 22.5436252117157\n",
      "score_time 0.44889016151428224\n",
      "test_recall 0.7987601395368386\n",
      "test_f1 0.6356739615485534\n",
      "test_accuracy 0.8646825078855626\n",
      "test_precision 0.5453670183852157\n",
      "test_roc_auc 0.9216410014637114\n",
      "test_neg_brier_score -0.09136863897767766\n",
      "fit_time 15.924036073684693\n",
      "score_time 0.42554874420166017\n",
      "test_recall 0.7721199512461647\n",
      "test_f1 0.6441999916940659\n",
      "test_accuracy 0.8779513253278735\n",
      "test_precision 0.576175876961647\n",
      "test_roc_auc 0.9258203558156538\n",
      "test_neg_brier_score -0.08975626613550972\n",
      "fit_time 14.193923425674438\n",
      "score_time 0.4031697750091553\n",
      "test_recall 0.8221136468709285\n",
      "test_f1 0.6271251773164528\n",
      "test_accuracy 0.8414355376016823\n",
      "test_precision 0.5334135592760462\n",
      "test_roc_auc 0.9152925071661814\n",
      "test_neg_brier_score -0.1088314663905234\n",
      "fit_time 51.713082265853885\n",
      "score_time 0.9758026123046875\n",
      "test_recall 0.8026457361408819\n",
      "test_f1 0.6361912305791717\n",
      "test_accuracy 0.8654382823308062\n",
      "test_precision 0.5374109465354621\n",
      "test_roc_auc 0.9224098264426661\n",
      "test_neg_brier_score -0.0945335057420684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 32.21785717010498\n",
      "score_time 0.711247444152832\n",
      "test_recall 0.7974656411549615\n",
      "test_f1 0.6316306377024214\n",
      "test_accuracy 0.8657188644789995\n",
      "test_precision 0.5371231872472746\n",
      "test_roc_auc 0.9202469133832045\n",
      "test_neg_brier_score -0.09866557396511037\n",
      "fit_time 24.688657188415526\n",
      "score_time 0.6551656723022461\n",
      "test_recall 0.8007102929433026\n",
      "test_f1 0.6163852010676341\n",
      "test_accuracy 0.84877941453157\n",
      "test_precision 0.5110844203436183\n",
      "test_roc_auc 0.9071307607457563\n",
      "test_neg_brier_score -0.11622677904897338\n"
     ]
    }
   ],
   "source": [
    "# ds = datasets['merged']['lengthdivdataset-4']\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        mlp = BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "        mlp.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(mlp, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision']])\n",
    "        name = f'mlp_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_time 71.89677076339721\n",
    "score_time 0.10850300788879394\n",
    "test_recall 0.8584950773558369\n",
    "test_f1 0.6911281484361098\n",
    "test_accuracy 0.8864734363076601\n",
    "test_precision 0.5796959595204415\n",
    "test_roc_auc 0.9540192015137766\n",
    "test_neg_brier_score -0.07964541647825815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(modelScores.keys()))\n",
    "# print(modelScores.keys())\n",
    "# print(modelScores['mlp_balanced_normalized_4'])\n",
    "# print(modelScores['mlp_balanced_normalized_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.9005918025970459\n",
      "score_time 1.832925271987915\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.510706523502875\n",
      "test_neg_brier_score -0.14527397592299335\n",
      "fit_time 1.0388792037963868\n",
      "score_time 1.184439754486084\n",
      "test_recall 0.7682637750598916\n",
      "test_f1 0.6470785392118301\n",
      "test_accuracy 0.8794546843008135\n",
      "test_precision 0.5694617314417644\n",
      "test_roc_auc 0.9059787336109665\n",
      "test_neg_brier_score -0.08563907097963931\n",
      "fit_time 1.820357084274292\n",
      "score_time 1.633793306350708\n",
      "test_recall 0.6223111839616695\n",
      "test_f1 0.6622677588722691\n",
      "test_accuracy 0.9047616623319129\n",
      "test_precision 0.7670728169863373\n",
      "test_roc_auc 0.8690880648935909\n",
      "test_neg_brier_score -0.07928686951563617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 6.530042266845703\n",
      "score_time 3.4427698135375975\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.5082480131965573\n",
      "test_neg_brier_score -0.1457355230836727\n",
      "fit_time 6.441674995422363\n",
      "score_time 3.110650157928467\n",
      "test_recall 0.7195666792754171\n",
      "test_f1 0.680627734884343\n",
      "test_accuracy 0.9109778982900781\n",
      "test_precision 0.6755043001874332\n",
      "test_roc_auc 0.9195314656792288\n",
      "test_neg_brier_score -0.06779188285595661\n",
      "fit_time 4.718837118148803\n",
      "score_time 2.7102776527404786\n",
      "test_recall 0.7358361703021898\n",
      "test_f1 0.6401249173404641\n",
      "test_accuracy 0.877006253112722\n",
      "test_precision 0.5891997818295154\n",
      "test_roc_auc 0.8913670041328989\n",
      "test_neg_brier_score -0.08740740861294846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 31.155922889709473\n",
      "score_time 12.689632606506347\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.5064696334864541\n",
      "test_neg_brier_score -0.14603576232779042\n",
      "fit_time 31.866920471191406\n",
      "score_time 12.23724298477173\n",
      "test_recall 0.3319232547387887\n",
      "test_f1 0.44129358607854174\n",
      "test_accuracy 0.8936664047368712\n",
      "test_precision 0.8403621359124871\n",
      "test_roc_auc 0.875871270787408\n",
      "test_neg_brier_score -0.0972674594534371\n",
      "fit_time 25.571607255935668\n",
      "score_time 10.544783449172973\n",
      "test_recall 0.7461669398562603\n",
      "test_f1 0.5291742991048717\n",
      "test_accuracy 0.8215867190526257\n",
      "test_precision 0.4163185110362675\n",
      "test_roc_auc 0.8431971153418008\n",
      "test_neg_brier_score -0.13201217769586973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 109.18032379150391\n",
      "score_time 53.78303756713867\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.50618518657562\n",
      "test_neg_brier_score -0.146554394177546\n",
      "fit_time 101.62899775505066\n",
      "score_time 47.86398730278015\n",
      "test_recall 0.1095553313999916\n",
      "test_f1 0.18371642419827017\n",
      "test_accuracy 0.8666605279176581\n",
      "test_precision 0.8303641312939307\n",
      "test_roc_auc 0.8119340753412974\n",
      "test_neg_brier_score -0.12238631828837598\n",
      "fit_time 109.11372156143189\n",
      "score_time 50.53300194740295\n",
      "test_recall 0.8898226369100156\n",
      "test_f1 0.3489018698900065\n",
      "test_accuracy 0.49279548447789273\n",
      "test_precision 0.21956569655117636\n",
      "test_roc_auc 0.7556959434635748\n",
      "test_neg_brier_score -0.2238242948240226\n"
     ]
    }
   ],
   "source": [
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42, max_iter=500), n_estimators=1, n_jobs=-1)\n",
    "        temp_svm.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(temp_svm, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        name = f'svm_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.61638\n",
      "[10]\tvalidation_0-aucpr:0.80782\n",
      "[20]\tvalidation_0-aucpr:0.82789\n",
      "[30]\tvalidation_0-aucpr:0.84020\n",
      "[40]\tvalidation_0-aucpr:0.84760\n",
      "[50]\tvalidation_0-aucpr:0.85234\n",
      "[60]\tvalidation_0-aucpr:0.85953\n",
      "[70]\tvalidation_0-aucpr:0.86429\n",
      "[80]\tvalidation_0-aucpr:0.86687\n",
      "[90]\tvalidation_0-aucpr:0.87223\n",
      "[100]\tvalidation_0-aucpr:0.87421\n",
      "[110]\tvalidation_0-aucpr:0.87528\n",
      "[120]\tvalidation_0-aucpr:0.87590\n",
      "[130]\tvalidation_0-aucpr:0.87729\n",
      "[140]\tvalidation_0-aucpr:0.87882\n",
      "[150]\tvalidation_0-aucpr:0.87985\n",
      "[160]\tvalidation_0-aucpr:0.88051\n",
      "[170]\tvalidation_0-aucpr:0.88118\n",
      "[180]\tvalidation_0-aucpr:0.88190\n",
      "[188]\tvalidation_0-aucpr:0.88187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=42, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "xgb1_test = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=200,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    ")\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "xgb1_test.fit(X_train, y_train, eval_metric='aucpr', eval_set=[(X_validation, y_validation)], early_stopping_rounds=10, verbose=10)\n",
    "# xgb1.fit(X_train, y_train)\n",
    "\n",
    "# x = cross_validate(xgb1, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "\n",
    "# for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "        # modelScores[name][k]=v.mean()\n",
    "\n",
    "# X_test = X_test[xgb1.get_booster().feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([10.12263608,  9.00429296,  9.30413198, 11.99384427, 11.84370995,\n",
      "       10.79316092, 10.00633025, 10.09028506, 11.25545502, 10.31688499]), 'score_time': array([0.01476312, 0.01359987, 0.01377797, 0.0210948 , 0.01741576,\n",
      "       0.0173142 , 0.01482892, 0.01795101, 0.01406169, 0.01382995]), 'test_recall': array([0.90967742, 0.79354839, 0.91558442, 0.92207792, 0.99350649,\n",
      "       0.64935065, 0.44805195, 0.48051948, 0.12987013, 0.15584416]), 'test_f1': array([0.84939759, 0.83959044, 0.8952381 , 0.91612903, 0.96226415,\n",
      "       0.72463768, 0.59227468, 0.63247863, 0.20512821, 0.21238938]), 'test_accuracy': array([0.95296331, 0.95578551, 0.96895579, 0.97554092, 0.98871119,\n",
      "       0.92850423, 0.91063029, 0.91902072, 0.85404896, 0.83239171]), 'test_precision': array([0.79661017, 0.89130435, 0.8757764 , 0.91025641, 0.93292683,\n",
      "       0.81967213, 0.87341772, 0.925     , 0.48780488, 0.33333333]), 'test_roc_auc': array([0.9871323 , 0.97677277, 0.97996943, 0.99192776, 0.99757833,\n",
      "       0.95170231, 0.95758862, 0.91271669, 0.81469192, 0.72614995]), 'test_neg_brier_score': array([-0.03589892, -0.0360074 , -0.02433944, -0.01803147, -0.0092197 ,\n",
      "       -0.0558726 , -0.06893053, -0.06892375, -0.11919112, -0.13314432]), 'test_average_precision': array([0.9453765 , 0.91703849, 0.94921174, 0.97452338, 0.99416307,\n",
      "       0.83817685, 0.8157934 , 0.77181219, 0.42549396, 0.2882046 ])}\n"
     ]
    }
   ],
   "source": [
    "x = cross_validate(xgb1, X, y, cv=10, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_estimators=1, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedBaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_estimators=1, n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=-1,\n",
       "                                                              n_neighbors=1),\n",
       "                          n_estimators=1, n_jobs=-1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train random forest\n",
    "randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "randforest.fit(X_train, y_train)\n",
    "\n",
    "# train svm\n",
    "temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42), n_estimators=1, n_jobs=-1)\n",
    "temp_svm.fit(X_train, y_train)\n",
    "\n",
    "# train knn\n",
    "knn = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=1, n_jobs=-1), n_estimators=1, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb1_test, open('models/curr_models/xgBoost-f2-4-2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randforest recall: \n",
      "0.7254901960784313\n",
      "randforest f1: \n",
      "0.5144843568945539\n",
      "randforest accuracy: \n",
      "0.8029162746942615\n",
      "randforest precision: \n",
      "0.3985637342908438\n",
      "randforest roc_auc: \n",
      "0.7707121310062487\n",
      "randforest brier_score: \n",
      "0.19708372530573848\n",
      "randforest confusion matrix: \n",
      "[1485  335   84  222]\n",
      "randforest classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88      1820\n",
      "           1       0.40      0.73      0.51       306\n",
      "\n",
      "    accuracy                           0.80      2126\n",
      "   macro avg       0.67      0.77      0.70      2126\n",
      "weighted avg       0.87      0.80      0.82      2126\n",
      "\n",
      "randforest roc_curve: \n",
      "(array([0.        , 0.18406593, 1.        ]), array([0.       , 0.7254902, 1.       ]), array([2., 1., 0.]))\n",
      "randforest precision_recall_curve: \n",
      "(array([0.14393227, 0.39856373, 1.        ]), array([1.       , 0.7254902, 0.       ]), array([0., 1.]))\n",
      "randforest average_precision_score: \n",
      "0.328664900178798\n",
      "svm recall: \n",
      "0.7810457516339869\n",
      "svm f1: \n",
      "0.7264437689969605\n",
      "svm accuracy: \n",
      "0.9153339604891816\n",
      "svm precision: \n",
      "0.6789772727272727\n",
      "svm roc_auc: \n",
      "0.9475274725274724\n",
      "svm brier_score: \n",
      "0.06287125543293742\n",
      "svm confusion matrix: \n",
      "[1707  113   67  239]\n",
      "svm classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1820\n",
      "           1       0.68      0.78      0.73       306\n",
      "\n",
      "    accuracy                           0.92      2126\n",
      "   macro avg       0.82      0.86      0.84      2126\n",
      "weighted avg       0.92      0.92      0.92      2126\n",
      "\n",
      "svm roc_curve: \n",
      "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.49450549e-04,\n",
      "       5.49450549e-04, 1.09890110e-03, 1.09890110e-03, 1.64835165e-03,\n",
      "       1.64835165e-03, 2.19780220e-03, 2.19780220e-03, 2.74725275e-03,\n",
      "       2.74725275e-03, 3.29670330e-03, 3.29670330e-03, 3.84615385e-03,\n",
      "       3.84615385e-03, 4.39560440e-03, 4.39560440e-03, 4.94505495e-03,\n",
      "       4.94505495e-03, 5.49450549e-03, 5.49450549e-03, 6.04395604e-03,\n",
      "       6.04395604e-03, 6.59340659e-03, 6.59340659e-03, 7.14285714e-03,\n",
      "       7.14285714e-03, 7.69230769e-03, 7.69230769e-03, 8.24175824e-03,\n",
      "       8.24175824e-03, 8.79120879e-03, 8.79120879e-03, 9.89010989e-03,\n",
      "       9.89010989e-03, 1.04395604e-02, 1.04395604e-02, 1.20879121e-02,\n",
      "       1.20879121e-02, 1.26373626e-02, 1.26373626e-02, 1.31868132e-02,\n",
      "       1.31868132e-02, 1.37362637e-02, 1.37362637e-02, 1.42857143e-02,\n",
      "       1.42857143e-02, 1.48351648e-02, 1.48351648e-02, 1.75824176e-02,\n",
      "       1.75824176e-02, 1.97802198e-02, 1.97802198e-02, 2.03296703e-02,\n",
      "       2.03296703e-02, 2.08791209e-02, 2.08791209e-02, 2.19780220e-02,\n",
      "       2.19780220e-02, 2.36263736e-02, 2.36263736e-02, 2.52747253e-02,\n",
      "       2.52747253e-02, 2.69230769e-02, 2.69230769e-02, 2.91208791e-02,\n",
      "       2.91208791e-02, 2.96703297e-02, 2.96703297e-02, 3.02197802e-02,\n",
      "       3.02197802e-02, 3.07692308e-02, 3.07692308e-02, 3.13186813e-02,\n",
      "       3.13186813e-02, 3.35164835e-02, 3.35164835e-02, 3.51648352e-02,\n",
      "       3.51648352e-02, 4.01098901e-02, 4.01098901e-02, 4.17582418e-02,\n",
      "       4.17582418e-02, 4.56043956e-02, 4.56043956e-02, 4.61538462e-02,\n",
      "       4.61538462e-02, 4.72527473e-02, 4.72527473e-02, 4.83516484e-02,\n",
      "       4.83516484e-02, 5.21978022e-02, 5.21978022e-02, 5.27472527e-02,\n",
      "       5.27472527e-02, 5.54945055e-02, 5.54945055e-02, 5.93406593e-02,\n",
      "       5.93406593e-02, 6.20879121e-02, 6.26373626e-02, 6.31868132e-02,\n",
      "       6.31868132e-02, 6.42857143e-02, 6.42857143e-02, 6.48351648e-02,\n",
      "       6.48351648e-02, 7.08791209e-02, 7.08791209e-02, 7.36263736e-02,\n",
      "       7.36263736e-02, 7.63736264e-02, 7.63736264e-02, 7.91208791e-02,\n",
      "       7.91208791e-02, 8.24175824e-02, 8.24175824e-02, 8.29670330e-02,\n",
      "       8.29670330e-02, 8.46153846e-02, 8.46153846e-02, 8.84615385e-02,\n",
      "       8.84615385e-02, 9.01098901e-02, 9.01098901e-02, 9.06593407e-02,\n",
      "       9.06593407e-02, 9.12087912e-02, 9.12087912e-02, 9.89010989e-02,\n",
      "       9.89010989e-02, 1.00549451e-01, 1.00549451e-01, 1.05494505e-01,\n",
      "       1.05494505e-01, 1.07142857e-01, 1.07142857e-01, 1.12637363e-01,\n",
      "       1.12637363e-01, 1.13186813e-01, 1.13186813e-01, 1.13736264e-01,\n",
      "       1.13736264e-01, 1.15934066e-01, 1.15934066e-01, 1.17032967e-01,\n",
      "       1.17032967e-01, 1.24175824e-01, 1.24175824e-01, 1.24725275e-01,\n",
      "       1.24725275e-01, 1.26923077e-01, 1.26923077e-01, 1.32417582e-01,\n",
      "       1.32417582e-01, 1.39010989e-01, 1.39010989e-01, 1.49450549e-01,\n",
      "       1.49450549e-01, 1.58791209e-01, 1.58791209e-01, 1.59890110e-01,\n",
      "       1.59890110e-01, 1.69230769e-01, 1.69230769e-01, 1.70329670e-01,\n",
      "       1.70329670e-01, 1.73076923e-01, 1.73076923e-01, 1.76923077e-01,\n",
      "       1.76923077e-01, 1.81318681e-01, 1.81318681e-01, 1.89010989e-01,\n",
      "       1.89010989e-01, 1.89560440e-01, 1.89560440e-01, 1.95054945e-01,\n",
      "       1.95054945e-01, 1.98901099e-01, 1.98901099e-01, 1.99450549e-01,\n",
      "       1.99450549e-01, 2.06593407e-01, 2.06593407e-01, 2.56043956e-01,\n",
      "       2.56043956e-01, 2.64285714e-01, 2.64285714e-01, 2.93956044e-01,\n",
      "       2.93956044e-01, 3.17032967e-01, 3.17032967e-01, 3.58241758e-01,\n",
      "       3.58241758e-01, 3.59890110e-01, 3.59890110e-01, 3.77472527e-01,\n",
      "       3.77472527e-01, 3.85164835e-01, 3.85164835e-01, 3.87362637e-01,\n",
      "       3.87362637e-01, 4.03846154e-01, 4.03846154e-01, 4.79120879e-01,\n",
      "       4.79120879e-01, 4.91758242e-01, 4.91758242e-01, 5.81318681e-01,\n",
      "       5.81318681e-01, 6.17582418e-01, 6.17582418e-01, 6.80219780e-01,\n",
      "       6.80219780e-01, 7.63186813e-01, 7.63186813e-01, 1.00000000e+00]), array([0.        , 0.00326797, 0.04575163, 0.04575163, 0.05555556,\n",
      "       0.05555556, 0.27777778, 0.27777778, 0.30065359, 0.30065359,\n",
      "       0.43464052, 0.43464052, 0.4379085 , 0.4379085 , 0.49019608,\n",
      "       0.49019608, 0.5       , 0.5       , 0.50653595, 0.50653595,\n",
      "       0.51960784, 0.51960784, 0.53921569, 0.53921569, 0.55228758,\n",
      "       0.55228758, 0.55882353, 0.55882353, 0.56535948, 0.56535948,\n",
      "       0.56862745, 0.56862745, 0.57189542, 0.57189542, 0.58823529,\n",
      "       0.58823529, 0.59150327, 0.59150327, 0.59477124, 0.59477124,\n",
      "       0.60457516, 0.60457516, 0.61437908, 0.61437908, 0.61764706,\n",
      "       0.61764706, 0.62745098, 0.62745098, 0.63071895, 0.63071895,\n",
      "       0.65686275, 0.65686275, 0.66339869, 0.66339869, 0.66666667,\n",
      "       0.66666667, 0.66993464, 0.66993464, 0.68300654, 0.68300654,\n",
      "       0.69607843, 0.69607843, 0.69934641, 0.69934641, 0.70588235,\n",
      "       0.70588235, 0.70915033, 0.70915033, 0.7124183 , 0.7124183 ,\n",
      "       0.7254902 , 0.7254902 , 0.72875817, 0.72875817, 0.73202614,\n",
      "       0.73202614, 0.73529412, 0.73529412, 0.73856209, 0.73856209,\n",
      "       0.74183007, 0.74183007, 0.74509804, 0.74509804, 0.74836601,\n",
      "       0.74836601, 0.75163399, 0.75163399, 0.75490196, 0.75490196,\n",
      "       0.76143791, 0.76143791, 0.76470588, 0.76470588, 0.77124183,\n",
      "       0.77124183, 0.7745098 , 0.7745098 , 0.77777778, 0.77777778,\n",
      "       0.78104575, 0.78104575, 0.7875817 , 0.7875817 , 0.79084967,\n",
      "       0.79084967, 0.79411765, 0.79411765, 0.80065359, 0.80065359,\n",
      "       0.80392157, 0.80392157, 0.80718954, 0.80718954, 0.81045752,\n",
      "       0.81045752, 0.81372549, 0.81372549, 0.81699346, 0.81699346,\n",
      "       0.82026144, 0.82026144, 0.82352941, 0.82352941, 0.83006536,\n",
      "       0.83006536, 0.83333333, 0.83333333, 0.83660131, 0.83660131,\n",
      "       0.83986928, 0.83986928, 0.84313725, 0.84313725, 0.84640523,\n",
      "       0.84640523, 0.8496732 , 0.8496732 , 0.85294118, 0.85294118,\n",
      "       0.85620915, 0.85620915, 0.85947712, 0.85947712, 0.86601307,\n",
      "       0.86601307, 0.86928105, 0.86928105, 0.87254902, 0.87254902,\n",
      "       0.87581699, 0.87581699, 0.87908497, 0.87908497, 0.88235294,\n",
      "       0.88235294, 0.88888889, 0.88888889, 0.89215686, 0.89215686,\n",
      "       0.89542484, 0.89542484, 0.89869281, 0.89869281, 0.90196078,\n",
      "       0.90196078, 0.90522876, 0.90522876, 0.91176471, 0.91176471,\n",
      "       0.91503268, 0.91503268, 0.91830065, 0.91830065, 0.92156863,\n",
      "       0.92156863, 0.9248366 , 0.9248366 , 0.92810458, 0.92810458,\n",
      "       0.93137255, 0.93137255, 0.93464052, 0.93464052, 0.9379085 ,\n",
      "       0.9379085 , 0.94117647, 0.94117647, 0.94444444, 0.94444444,\n",
      "       0.94771242, 0.94771242, 0.95098039, 0.95098039, 0.95424837,\n",
      "       0.95424837, 0.95751634, 0.95751634, 0.96078431, 0.96078431,\n",
      "       0.96405229, 0.96405229, 0.97058824, 0.97058824, 0.97385621,\n",
      "       0.97385621, 0.97712418, 0.97712418, 0.98039216, 0.98039216,\n",
      "       0.98366013, 0.98366013, 0.9869281 , 0.9869281 , 0.99019608,\n",
      "       0.99019608, 0.99346405, 0.99346405, 1.        , 1.        ]), array([1.99582312e+00, 9.95823120e-01, 9.94531415e-01, 9.94436592e-01,\n",
      "       9.94289932e-01, 9.94279015e-01, 9.86999381e-01, 9.86927181e-01,\n",
      "       9.86388431e-01, 9.86338828e-01, 9.76480240e-01, 9.76460467e-01,\n",
      "       9.76434010e-01, 9.76295980e-01, 9.71398806e-01, 9.70527899e-01,\n",
      "       9.68575907e-01, 9.68365838e-01, 9.67667216e-01, 9.66949185e-01,\n",
      "       9.63644033e-01, 9.63552600e-01, 9.59586262e-01, 9.57860502e-01,\n",
      "       9.52569555e-01, 9.52412006e-01, 9.51845003e-01, 9.50139883e-01,\n",
      "       9.47823126e-01, 9.47581718e-01, 9.46821414e-01, 9.44925375e-01,\n",
      "       9.44730798e-01, 9.44536261e-01, 9.38704129e-01, 9.35643267e-01,\n",
      "       9.35400708e-01, 9.35368719e-01, 9.34641462e-01, 9.27973308e-01,\n",
      "       9.25575905e-01, 9.25099460e-01, 9.23601206e-01, 9.23192166e-01,\n",
      "       9.22723321e-01, 9.22293220e-01, 9.20080760e-01, 9.19691919e-01,\n",
      "       9.19373656e-01, 9.17288315e-01, 9.05290489e-01, 8.97744386e-01,\n",
      "       8.93181571e-01, 8.73444993e-01, 8.70323635e-01, 8.66830507e-01,\n",
      "       8.64708832e-01, 8.64555638e-01, 8.59701865e-01, 8.51640442e-01,\n",
      "       8.48260866e-01, 8.34076621e-01, 8.32514114e-01, 8.23577746e-01,\n",
      "       8.16029302e-01, 8.09293950e-01, 8.04866686e-01, 7.99362062e-01,\n",
      "       7.98520153e-01, 7.97092054e-01, 7.73973588e-01, 7.73099925e-01,\n",
      "       7.68437925e-01, 7.66350012e-01, 7.59925249e-01, 7.54339775e-01,\n",
      "       7.48910017e-01, 7.38653148e-01, 7.24979040e-01, 7.20758611e-01,\n",
      "       7.20415198e-01, 6.89321705e-01, 6.83620299e-01, 6.76291290e-01,\n",
      "       6.75490850e-01, 6.49165009e-01, 6.48079849e-01, 6.43089909e-01,\n",
      "       6.35736324e-01, 6.34285020e-01, 6.23066296e-01, 6.18545742e-01,\n",
      "       6.15085503e-01, 5.77802982e-01, 5.71573326e-01, 5.69621323e-01,\n",
      "       5.69482727e-01, 5.50275827e-01, 5.46079791e-01, 5.33204149e-01,\n",
      "       5.27660822e-01, 5.05204125e-01, 5.00000000e-01, 4.94349575e-01,\n",
      "       4.89567766e-01, 4.82995021e-01, 4.76709270e-01, 4.69946678e-01,\n",
      "       4.66814976e-01, 4.27375973e-01, 4.27188328e-01, 4.13856446e-01,\n",
      "       4.10569313e-01, 3.94657292e-01, 3.93985171e-01, 3.82772041e-01,\n",
      "       3.80422967e-01, 3.68704513e-01, 3.64369802e-01, 3.62000090e-01,\n",
      "       3.52509760e-01, 3.38568728e-01, 3.37835404e-01, 3.12886112e-01,\n",
      "       3.08748176e-01, 2.97363464e-01, 2.96823797e-01, 2.94085154e-01,\n",
      "       2.89806925e-01, 2.86275491e-01, 2.84169615e-01, 2.47802302e-01,\n",
      "       2.47545704e-01, 2.44555110e-01, 2.42830677e-01, 2.34680621e-01,\n",
      "       2.32535204e-01, 2.24726715e-01, 2.23952352e-01, 2.16579249e-01,\n",
      "       2.16510250e-01, 2.15890902e-01, 2.12192665e-01, 2.10680030e-01,\n",
      "       2.10169095e-01, 2.04961099e-01, 2.04149558e-01, 1.99624353e-01,\n",
      "       1.95827073e-01, 1.80971983e-01, 1.80888791e-01, 1.80668919e-01,\n",
      "       1.80451454e-01, 1.75037952e-01, 1.74967724e-01, 1.61433142e-01,\n",
      "       1.60431508e-01, 1.53066865e-01, 1.52466003e-01, 1.34802727e-01,\n",
      "       1.34425705e-01, 1.28512881e-01, 1.28227691e-01, 1.26969801e-01,\n",
      "       1.25799082e-01, 1.22077176e-01, 1.21791587e-01, 1.21667367e-01,\n",
      "       1.21492424e-01, 1.20327696e-01, 1.20268783e-01, 1.17848221e-01,\n",
      "       1.17519447e-01, 1.15372921e-01, 1.15156474e-01, 1.11864146e-01,\n",
      "       1.11567076e-01, 1.11531981e-01, 1.11251789e-01, 1.10021583e-01,\n",
      "       1.09929142e-01, 1.08914770e-01, 1.08813156e-01, 1.08690360e-01,\n",
      "       1.08456044e-01, 1.07209951e-01, 1.07040489e-01, 1.00999703e-01,\n",
      "       1.00968946e-01, 9.95668699e-02, 9.94275592e-02, 9.42163941e-02,\n",
      "       9.41411438e-02, 9.04449526e-02, 9.03989700e-02, 8.10933225e-02,\n",
      "       8.08625859e-02, 8.06216331e-02, 8.05705569e-02, 7.79647231e-02,\n",
      "       7.79392322e-02, 7.63992469e-02, 7.63838891e-02, 7.55475701e-02,\n",
      "       7.54146783e-02, 7.19837907e-02, 7.19512772e-02, 5.77722073e-02,\n",
      "       5.76823989e-02, 5.43282597e-02, 5.42300390e-02, 3.61231269e-02,\n",
      "       3.60699737e-02, 2.99432787e-02, 2.98799872e-02, 2.15876675e-02,\n",
      "       2.15243955e-02, 1.49318172e-02, 1.48580002e-02, 1.01561322e-03]))\n",
      "svm precision_recall_curve: \n",
      "(array([0.14393227, 0.144     , 0.1440678 , ..., 1.        , 1.        ,\n",
      "       1.        ]), array([1.        , 1.        , 1.        , ..., 0.00653595, 0.00326797,\n",
      "       0.        ]), array([0.00101561, 0.00179131, 0.00186314, ..., 0.9955242 , 0.99557855,\n",
      "       0.99582312]))\n",
      "svm average_precision_score: \n",
      "0.8294958586921346\n",
      "knn recall: \n",
      "0.8562091503267973\n",
      "knn f1: \n",
      "0.6336154776299879\n",
      "knn accuracy: \n",
      "0.8574788334901223\n",
      "knn precision: \n",
      "0.5028790786948176\n",
      "knn roc_auc: \n",
      "0.8569507290095526\n",
      "knn brier_score: \n",
      "0.1425211665098777\n",
      "knn confusion matrix: \n",
      "[1561  259   44  262]\n",
      "knn classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      1820\n",
      "           1       0.50      0.86      0.63       306\n",
      "\n",
      "    accuracy                           0.86      2126\n",
      "   macro avg       0.74      0.86      0.77      2126\n",
      "weighted avg       0.90      0.86      0.87      2126\n",
      "\n",
      "knn roc_curve: \n",
      "(array([0.        , 0.14230769, 1.        ]), array([0.        , 0.85620915, 1.        ]), array([2., 1., 0.]))\n",
      "knn precision_recall_curve: \n",
      "(array([0.14393227, 0.50287908, 1.        ]), array([1.        , 0.85620915, 0.        ]), array([0., 1.]))\n",
      "knn average_precision_score: \n",
      "0.4512658116779458\n",
      "xgboost recall: \n",
      "0.6895424836601307\n",
      "xgboost f1: \n",
      "0.7617328519855596\n",
      "xgboost accuracy: \n",
      "0.9379115710253998\n",
      "xgboost precision: \n",
      "0.8508064516129032\n",
      "xgboost roc_auc: \n",
      "0.9577982475041299\n",
      "xgboost brier_score: \n",
      "0.049377249726187136\n",
      "xgboost confusion matrix: \n",
      "[1783   37   95  211]\n",
      "xgboost classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1820\n",
      "           1       0.85      0.69      0.76       306\n",
      "\n",
      "    accuracy                           0.94      2126\n",
      "   macro avg       0.90      0.83      0.86      2126\n",
      "weighted avg       0.94      0.94      0.94      2126\n",
      "\n",
      "xgboost roc_curve: \n",
      "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 5.49450549e-04, 5.49450549e-04, 1.09890110e-03,\n",
      "       1.09890110e-03, 1.64835165e-03, 1.64835165e-03, 2.19780220e-03,\n",
      "       2.19780220e-03, 2.74725275e-03, 2.74725275e-03, 3.29670330e-03,\n",
      "       3.29670330e-03, 3.84615385e-03, 3.84615385e-03, 4.39560440e-03,\n",
      "       4.39560440e-03, 4.94505495e-03, 4.94505495e-03, 5.49450549e-03,\n",
      "       5.49450549e-03, 6.04395604e-03, 6.04395604e-03, 6.59340659e-03,\n",
      "       6.59340659e-03, 7.69230769e-03, 7.69230769e-03, 8.24175824e-03,\n",
      "       8.24175824e-03, 9.89010989e-03, 9.89010989e-03, 1.04395604e-02,\n",
      "       1.04395604e-02, 1.09890110e-02, 1.09890110e-02, 1.20879121e-02,\n",
      "       1.20879121e-02, 1.26373626e-02, 1.26373626e-02, 1.37362637e-02,\n",
      "       1.37362637e-02, 1.42857143e-02, 1.42857143e-02, 1.81318681e-02,\n",
      "       1.81318681e-02, 1.92307692e-02, 1.92307692e-02, 2.03296703e-02,\n",
      "       2.03296703e-02, 2.30769231e-02, 2.30769231e-02, 2.36263736e-02,\n",
      "       2.36263736e-02, 2.52747253e-02, 2.52747253e-02, 2.69230769e-02,\n",
      "       2.69230769e-02, 2.74725275e-02, 2.74725275e-02, 2.80219780e-02,\n",
      "       2.80219780e-02, 2.91208791e-02, 2.91208791e-02, 3.35164835e-02,\n",
      "       3.35164835e-02, 3.62637363e-02, 3.62637363e-02, 3.68131868e-02,\n",
      "       3.68131868e-02, 3.79120879e-02, 3.79120879e-02, 3.84615385e-02,\n",
      "       3.84615385e-02, 3.90109890e-02, 3.90109890e-02, 3.95604396e-02,\n",
      "       3.95604396e-02, 4.06593407e-02, 4.06593407e-02, 4.17582418e-02,\n",
      "       4.17582418e-02, 4.34065934e-02, 4.34065934e-02, 4.50549451e-02,\n",
      "       4.50549451e-02, 4.67032967e-02, 4.67032967e-02, 4.78021978e-02,\n",
      "       4.78021978e-02, 5.00000000e-02, 5.00000000e-02, 5.16483516e-02,\n",
      "       5.16483516e-02, 5.49450549e-02, 5.49450549e-02, 5.60439560e-02,\n",
      "       5.60439560e-02, 5.71428571e-02, 5.71428571e-02, 6.42857143e-02,\n",
      "       6.42857143e-02, 6.75824176e-02, 6.75824176e-02, 6.92307692e-02,\n",
      "       6.92307692e-02, 7.03296703e-02, 7.03296703e-02, 7.08791209e-02,\n",
      "       7.08791209e-02, 7.25274725e-02, 7.25274725e-02, 7.41758242e-02,\n",
      "       7.41758242e-02, 7.47252747e-02, 7.47252747e-02, 7.69230769e-02,\n",
      "       7.69230769e-02, 8.24175824e-02, 8.24175824e-02, 8.68131868e-02,\n",
      "       8.68131868e-02, 8.73626374e-02, 8.73626374e-02, 8.79120879e-02,\n",
      "       8.79120879e-02, 8.84615385e-02, 8.84615385e-02, 9.28571429e-02,\n",
      "       9.28571429e-02, 9.50549451e-02, 9.50549451e-02, 1.06593407e-01,\n",
      "       1.06593407e-01, 1.20879121e-01, 1.20879121e-01, 1.21978022e-01,\n",
      "       1.21978022e-01, 1.22527473e-01, 1.22527473e-01, 1.24725275e-01,\n",
      "       1.24725275e-01, 1.26923077e-01, 1.26923077e-01, 1.33516484e-01,\n",
      "       1.33516484e-01, 1.34065934e-01, 1.34065934e-01, 1.42307692e-01,\n",
      "       1.42307692e-01, 1.42857143e-01, 1.42857143e-01, 1.45054945e-01,\n",
      "       1.45054945e-01, 1.55494505e-01, 1.55494505e-01, 1.58241758e-01,\n",
      "       1.58241758e-01, 1.59340659e-01, 1.59340659e-01, 1.60439560e-01,\n",
      "       1.60439560e-01, 1.62637363e-01, 1.62637363e-01, 1.78021978e-01,\n",
      "       1.78021978e-01, 1.80769231e-01, 1.80769231e-01, 1.83516484e-01,\n",
      "       1.83516484e-01, 1.88461538e-01, 1.88461538e-01, 1.95054945e-01,\n",
      "       1.95054945e-01, 1.95604396e-01, 1.95604396e-01, 2.00549451e-01,\n",
      "       2.00549451e-01, 2.17032967e-01, 2.17032967e-01, 2.25824176e-01,\n",
      "       2.25824176e-01, 2.26923077e-01, 2.26923077e-01, 2.27472527e-01,\n",
      "       2.27472527e-01, 2.30219780e-01, 2.30219780e-01, 2.30769231e-01,\n",
      "       2.30769231e-01, 2.33516484e-01, 2.33516484e-01, 2.35714286e-01,\n",
      "       2.35714286e-01, 2.36813187e-01, 2.36813187e-01, 2.74725275e-01,\n",
      "       2.74725275e-01, 3.24175824e-01, 3.24175824e-01, 3.27472527e-01,\n",
      "       3.27472527e-01, 3.59890110e-01, 3.59890110e-01, 4.01098901e-01,\n",
      "       4.01098901e-01, 4.21428571e-01, 4.21428571e-01, 4.32967033e-01,\n",
      "       4.32967033e-01, 5.18131868e-01, 5.18131868e-01, 6.95054945e-01,\n",
      "       6.96153846e-01, 7.23076923e-01, 7.23076923e-01, 8.43406593e-01,\n",
      "       8.44505495e-01, 8.84065934e-01, 8.85164835e-01, 1.00000000e+00]), array([0.        , 0.00326797, 0.05555556, 0.0620915 , 0.07843137,\n",
      "       0.08496732, 0.10457516, 0.11111111, 0.47058824, 0.47058824,\n",
      "       0.54901961, 0.54901961, 0.55882353, 0.55882353, 0.5620915 ,\n",
      "       0.5620915 , 0.56535948, 0.56535948, 0.56862745, 0.56862745,\n",
      "       0.57843137, 0.57843137, 0.58496732, 0.58496732, 0.59150327,\n",
      "       0.59150327, 0.59803922, 0.59803922, 0.60457516, 0.60457516,\n",
      "       0.61437908, 0.61437908, 0.61764706, 0.61764706, 0.62091503,\n",
      "       0.62091503, 0.62418301, 0.62418301, 0.63071895, 0.63071895,\n",
      "       0.64705882, 0.64705882, 0.65359477, 0.65359477, 0.66013072,\n",
      "       0.66013072, 0.66339869, 0.66339869, 0.66666667, 0.66666667,\n",
      "       0.67320261, 0.67320261, 0.68300654, 0.68300654, 0.68627451,\n",
      "       0.68627451, 0.69281046, 0.69281046, 0.69607843, 0.69607843,\n",
      "       0.69934641, 0.69934641, 0.70261438, 0.70261438, 0.70588235,\n",
      "       0.70588235, 0.70915033, 0.70915033, 0.7124183 , 0.7124183 ,\n",
      "       0.71895425, 0.71895425, 0.7254902 , 0.7254902 , 0.72875817,\n",
      "       0.72875817, 0.73529412, 0.73529412, 0.73856209, 0.73856209,\n",
      "       0.74183007, 0.74183007, 0.74836601, 0.74836601, 0.75163399,\n",
      "       0.75163399, 0.75490196, 0.75490196, 0.76143791, 0.76143791,\n",
      "       0.76470588, 0.76470588, 0.77124183, 0.77124183, 0.7745098 ,\n",
      "       0.7745098 , 0.78104575, 0.78104575, 0.78431373, 0.78431373,\n",
      "       0.7875817 , 0.7875817 , 0.79084967, 0.79084967, 0.79738562,\n",
      "       0.79738562, 0.80065359, 0.80065359, 0.80392157, 0.80392157,\n",
      "       0.80718954, 0.80718954, 0.81045752, 0.81045752, 0.81372549,\n",
      "       0.81372549, 0.81699346, 0.81699346, 0.82026144, 0.82026144,\n",
      "       0.82352941, 0.82352941, 0.82679739, 0.82679739, 0.83006536,\n",
      "       0.83006536, 0.83333333, 0.83333333, 0.83660131, 0.83660131,\n",
      "       0.83986928, 0.83986928, 0.84313725, 0.84313725, 0.84640523,\n",
      "       0.84640523, 0.85294118, 0.85294118, 0.85620915, 0.85620915,\n",
      "       0.85947712, 0.85947712, 0.8627451 , 0.8627451 , 0.86601307,\n",
      "       0.86601307, 0.86928105, 0.86928105, 0.87254902, 0.87254902,\n",
      "       0.87581699, 0.87581699, 0.87908497, 0.87908497, 0.88235294,\n",
      "       0.88235294, 0.88562092, 0.88562092, 0.89215686, 0.89215686,\n",
      "       0.89542484, 0.89542484, 0.89869281, 0.89869281, 0.90196078,\n",
      "       0.90196078, 0.90849673, 0.90849673, 0.91176471, 0.91176471,\n",
      "       0.91830065, 0.91830065, 0.92156863, 0.92156863, 0.9248366 ,\n",
      "       0.9248366 , 0.92810458, 0.92810458, 0.93137255, 0.93137255,\n",
      "       0.93464052, 0.93464052, 0.9379085 , 0.9379085 , 0.94117647,\n",
      "       0.94117647, 0.94444444, 0.94444444, 0.94771242, 0.94771242,\n",
      "       0.95098039, 0.95098039, 0.95424837, 0.95424837, 0.95751634,\n",
      "       0.95751634, 0.96078431, 0.96078431, 0.96405229, 0.96405229,\n",
      "       0.96732026, 0.96732026, 0.97058824, 0.97058824, 0.97385621,\n",
      "       0.97385621, 0.97712418, 0.97712418, 0.98039216, 0.98039216,\n",
      "       0.98366013, 0.98366013, 0.9869281 , 0.9869281 , 0.99019608,\n",
      "       0.99019608, 0.99346405, 0.99346405, 0.99673203, 0.99673203,\n",
      "       0.99673203, 0.99673203, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        ]), array([1.99995518e+00, 9.99955177e-01, 9.99901056e-01, 9.99900699e-01,\n",
      "       9.99894023e-01, 9.99892831e-01, 9.99872208e-01, 9.99868512e-01,\n",
      "       9.75771010e-01, 9.75375295e-01, 9.33048904e-01, 9.31433260e-01,\n",
      "       9.19197857e-01, 9.18071866e-01, 9.13621664e-01, 9.12403345e-01,\n",
      "       9.08115685e-01, 9.08113718e-01, 9.06068027e-01, 9.04123724e-01,\n",
      "       8.97935450e-01, 8.96491766e-01, 8.95103157e-01, 8.93398404e-01,\n",
      "       8.86002779e-01, 8.80785286e-01, 8.62678230e-01, 8.56565118e-01,\n",
      "       8.50498438e-01, 8.49503398e-01, 8.43458652e-01, 8.37255538e-01,\n",
      "       8.30664396e-01, 8.26792538e-01, 8.23721051e-01, 8.22539628e-01,\n",
      "       8.19996476e-01, 7.92744398e-01, 7.81169653e-01, 7.77441859e-01,\n",
      "       7.46394575e-01, 7.41848469e-01, 7.35528708e-01, 7.25640357e-01,\n",
      "       7.14175284e-01, 7.02209294e-01, 6.73504531e-01, 6.55156434e-01,\n",
      "       6.49313450e-01, 6.41338229e-01, 6.22351468e-01, 5.52501023e-01,\n",
      "       5.28011739e-01, 5.19189000e-01, 5.10582030e-01, 5.01575887e-01,\n",
      "       4.89021420e-01, 4.53467011e-01, 4.44116890e-01, 4.41901535e-01,\n",
      "       4.39654678e-01, 4.15969610e-01, 4.15695965e-01, 4.06619340e-01,\n",
      "       4.04933065e-01, 4.02912140e-01, 4.02242422e-01, 3.99296254e-01,\n",
      "       3.98493469e-01, 3.84824872e-01, 3.83300930e-01, 3.50563645e-01,\n",
      "       3.46651137e-01, 3.28982115e-01, 3.28803033e-01, 3.16762805e-01,\n",
      "       3.13432366e-01, 3.08537841e-01, 3.05790007e-01, 3.00395340e-01,\n",
      "       2.99343973e-01, 2.95068026e-01, 2.82953024e-01, 2.61809826e-01,\n",
      "       2.59956121e-01, 2.56453723e-01, 2.48419330e-01, 2.41597861e-01,\n",
      "       2.32151270e-01, 2.30238423e-01, 2.27434307e-01, 2.22424969e-01,\n",
      "       2.21559137e-01, 2.17786178e-01, 2.14114919e-01, 2.09982127e-01,\n",
      "       2.01554209e-01, 1.94817349e-01, 1.90616339e-01, 1.89080432e-01,\n",
      "       1.87827751e-01, 1.77912086e-01, 1.76535130e-01, 1.66856647e-01,\n",
      "       1.64980486e-01, 1.59725115e-01, 1.57754555e-01, 1.33628473e-01,\n",
      "       1.29514590e-01, 1.25818968e-01, 1.23204164e-01, 1.22607082e-01,\n",
      "       1.21642321e-01, 1.18210517e-01, 1.17111698e-01, 1.16239876e-01,\n",
      "       1.12156279e-01, 1.10502034e-01, 1.08409487e-01, 1.04680024e-01,\n",
      "       1.04504466e-01, 1.04063965e-01, 1.03316478e-01, 9.92655084e-02,\n",
      "       9.89277139e-02, 8.67596045e-02, 8.65013972e-02, 8.30781981e-02,\n",
      "       8.21382403e-02, 8.15949067e-02, 8.14641640e-02, 8.10495764e-02,\n",
      "       7.87080675e-02, 7.85219893e-02, 7.78837875e-02, 7.18274862e-02,\n",
      "       6.96575046e-02, 6.83483630e-02, 6.82614818e-02, 5.51294722e-02,\n",
      "       5.43486178e-02, 4.34650555e-02, 4.13422398e-02, 4.02682535e-02,\n",
      "       3.99594530e-02, 3.99324521e-02, 3.95884961e-02, 3.88529748e-02,\n",
      "       3.86522301e-02, 3.68753150e-02, 3.63940448e-02, 3.35421897e-02,\n",
      "       3.33738998e-02, 3.32026556e-02, 3.31071056e-02, 2.91524455e-02,\n",
      "       2.91312765e-02, 2.88896039e-02, 2.80566104e-02, 2.74548549e-02,\n",
      "       2.73438003e-02, 2.26066113e-02, 2.24950723e-02, 2.13266183e-02,\n",
      "       2.08068565e-02, 2.04814505e-02, 2.03951728e-02, 2.02435702e-02,\n",
      "       2.00762954e-02, 1.98294148e-02, 1.96005646e-02, 1.57924220e-02,\n",
      "       1.57516822e-02, 1.52089121e-02, 1.50344353e-02, 1.44645311e-02,\n",
      "       1.44121749e-02, 1.37824342e-02, 1.36984941e-02, 1.26835722e-02,\n",
      "       1.24894055e-02, 1.24279987e-02, 1.23840412e-02, 1.17627503e-02,\n",
      "       1.17187276e-02, 1.03133852e-02, 1.02890395e-02, 9.39613115e-03,\n",
      "       9.31713171e-03, 9.30413045e-03, 9.19148792e-03, 8.89976416e-03,\n",
      "       8.88190605e-03, 8.53205100e-03, 8.51064734e-03, 8.47948436e-03,\n",
      "       8.47734790e-03, 8.34015477e-03, 8.33178684e-03, 8.07159487e-03,\n",
      "       7.90233724e-03, 7.88063090e-03, 7.86608644e-03, 5.55219129e-03,\n",
      "       5.54236118e-03, 3.71215236e-03, 3.70131689e-03, 3.61640332e-03,\n",
      "       3.60070216e-03, 2.79218494e-03, 2.78145913e-03, 2.09531654e-03,\n",
      "       2.09046365e-03, 1.84128992e-03, 1.83567137e-03, 1.71725533e-03,\n",
      "       1.71684020e-03, 1.04611169e-03, 1.04558002e-03, 4.02057485e-04,\n",
      "       3.99213866e-04, 3.60075792e-04, 3.57595505e-04, 1.96319816e-04,\n",
      "       1.94105043e-04, 1.60656535e-04, 1.60572308e-04, 2.54400438e-05],\n",
      "      dtype=float32))\n",
      "xgboost precision_recall_curve: \n",
      "(array([0.14393227, 0.144     , 0.1440678 , ..., 1.        , 1.        ,\n",
      "       1.        ]), array([1.        , 1.        , 1.        , ..., 0.00653595, 0.00326797,\n",
      "       0.        ]), array([2.5440044e-05, 3.4523655e-05, 4.1282648e-05, ..., 9.9993610e-01,\n",
      "       9.9994624e-01, 9.9995518e-01], dtype=float32))\n",
      "xgboost average_precision_score: \n",
      "0.8628240575084943\n"
     ]
    }
   ],
   "source": [
    "# assess each model\n",
    "xgb1 = pickle.load(open('models/curr_models/xgBoost-f2-4-2.pkl', 'rb'))\n",
    "\n",
    "models = [randforest, temp_svm, knn, xgb1]\n",
    "modelNames = ['randforest', 'svm', 'knn', 'xgboost']\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    modelName = modelNames[i]\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    print(f'{modelName} recall: \\n{recall_score(y_test, y_pred)}')\n",
    "    print(f'{modelName} f1: \\n{f1_score(y_test, y_pred)}')\n",
    "    print(f'{modelName} accuracy: \\n{accuracy_score(y_test, y_pred)}')\n",
    "    print(f'{modelName} precision: \\n{precision_score(y_test, y_pred)}')\n",
    "    print(f'{modelName} roc_auc: \\n{roc_auc_score(y_test, y_pred_proba)}')\n",
    "    print(f'{modelName} brier_score: \\n{brier_score_loss(y_test, y_pred_proba)}')\n",
    "    print(f'{modelName} confusion matrix: \\n{confusion_matrix(y_test, y_pred).ravel()}')\n",
    "    print(f'{modelName} classification report: \\n{classification_report(y_test, y_pred)}')\n",
    "    print(f'{modelName} roc_curve: \\n{roc_curve(y_test, y_pred_proba)}')\n",
    "    print(f'{modelName} precision_recall_curve: \\n{precision_recall_curve(y_test, y_pred_proba)}')\n",
    "    print(f'{modelName} average_precision_score: \\n{average_precision_score(y_test, y_pred_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6,\n",
       "                                                       hidden_layer_sizes=(100,\n",
       "                                                                           180,\n",
       "                                                                           180,\n",
       "                                                                           200,\n",
       "                                                                           200),\n",
       "                                                       max_iter=550,\n",
       "                                                       random_state=42),\n",
       "                          n_estimators=5, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BalancedBaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6,\n",
       "                                                       hidden_layer_sizes=(100,\n",
       "                                                                           180,\n",
       "                                                                           180,\n",
       "                                                                           200,\n",
       "                                                                           200),\n",
       "                                                       max_iter=550,\n",
       "                                                       random_state=42),\n",
       "                          n_estimators=5, n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
       "              max_iter=550, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
       "              max_iter=550, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6,\n",
       "                                                       hidden_layer_sizes=(100,\n",
       "                                                                           180,\n",
       "                                                                           180,\n",
       "                                                                           200,\n",
       "                                                                           200),\n",
       "                                                       max_iter=550,\n",
       "                                                       random_state=42),\n",
       "                          n_estimators=5, n_jobs=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "mlp = BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# randforest.fit(X_train, y_train)\n",
    "x = cross_validate(mlp, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 12.1881685256958\n",
      "score_time 0.3574349880218506\n",
      "test_recall 0.7935716387172697\n",
      "test_f1 0.6657728990542772\n",
      "test_accuracy 0.8810549056499364\n",
      "test_precision 0.5883703167135279\n",
      "test_roc_auc 0.9227783079806313\n",
      "test_neg_brier_score -0.08561184605431278\n",
      "test_average_precision 0.7611865843305569\n"
     ]
    }
   ],
   "source": [
    "for k, v in x.items():\n",
    "        print(k, v.mean())\n",
    "        # modelScores[name][k]=v.mean()\n",
    "pickle.dump(mlp, open('models/curr_models/mlp-f2-4.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7617328519855596\n",
      "0.049377249726187136\n",
      "0.9577982475041299\n",
      "0.6895424836601307\n",
      "0.8626687296053343\n",
      "0.8628240575084943\n",
      "0.47541095284633406\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb1 = pickle.load(open('models/curr_models/xgBoost-f2-4-2.pkl', 'rb'))\n",
    "randforest = pickle.load(open('models/curr_models/randforest-test.pkl', 'rb'))\n",
    "# get brier score\n",
    "print(f1_score(y_test, xgb1.predict(X_test)))\n",
    "print(brier_score_loss(y_test, xgb1.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# get roc auc score\n",
    "print(roc_auc_score(y_test, xgb1.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "print(recall_score(y_test, xgb1.predict(X_test)))\n",
    "\n",
    "# get precision recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, xgb1.predict_proba(X_test)[:, 1])\n",
    "# plot the precision-recall curves\n",
    "print(auc(recall, precision))\n",
    "\n",
    "print(average_precision_score(y_test, xgb1.predict_proba(X_test)[:, 1]))\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='XGBoost')\n",
    "\n",
    "\n",
    "# plot precision recall for knn\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, randforest.predict_proba(X_test)[:, 1])\n",
    "print(auc(recall, precision))\n",
    "plt.plot(recall, precision, marker='.', label='rand forest')\n",
    "\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "print(type(xgb1).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ds \u001b[39m=\u001b[39m dataset[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf2-4\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m ds[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m], ds[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "ds = dataset[f'f2-4']\n",
    "\n",
    "X, y = ds['X'], ds['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "knn = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors = 1, n_jobs = -1), n_estimators = 1, n_jobs = -1)\n",
    "\n",
    "# randforest.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "area = auc(recall, precision)\n",
    "\n",
    "\n",
    "print('Area Under Curve: %.2f' % area)\n",
    "\n",
    "x = cross_validate(knn, X, y, cv=10, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "\n",
    "for k, v in x.items():\n",
    "    print(k, v.mean())\n",
    "        # modelScores[name][k]=v.mean()\n",
    "\n",
    "x = cross_validate(xgb1, X, y, cv=10, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "\n",
    "for k, v in x.items():\n",
    "    print(k, v.mean())\n",
    "# print(accuracy_score(knn.predict(X_test), y_test))\n",
    "# print(recall_score(knn.predict(X_test), y_test))\n",
    "\n",
    "\n",
    "# print(accuracy_score(xgb1.predict(X_test), y_test))\n",
    "# print(recall_score(xgb1.predict(X_test), y_test))\n",
    "# print(f1_score(xgb1.predict(X_test), y_test))\n",
    "# pickle.dump(xgb1, open('models/curr_models/xgBoost.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order models by performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(modelScores).T\n",
    "\n",
    "# select model with best overall scores, precision doesn't really matter, excluding accuracy just because\n",
    "score_df['total'] = score_df.apply(lambda x: x[['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score']].sum(), axis=1)\n",
    "score_df['name'] = score_df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "score_df['feature'] = score_df.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "score_df['kmer'] = score_df.apply(lambda x: x.name.split(\"_\")[2], axis=1)\n",
    "# sort based on total column\n",
    "score_df = score_df.sort_values(by='test_f1', ascending=False)\n",
    "# print(len(score_df))\n",
    "\n",
    "# for each k-mer value, create a plot with the AUC score of each model and each feature and put it into one graph\n",
    "\n",
    "\n",
    "# for kmer in modelKmers:\n",
    "#     for name in modelNames:\n",
    "#         for feature in modelFeatures:\n",
    "#             df = score_df[score_df.index.str.contains(f'{name}_{feature}_{kmer}')]\n",
    "#             df.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "#             plt.title(f'{name} {feature} {kmer}')\n",
    "#     plt.show()\n",
    "\n",
    "# retrieve all model names\n",
    "modelNames = score_df['name'].unique()\n",
    "\n",
    "for kmer in range(3, 7):\n",
    "    # for feature in features:\n",
    "\n",
    "    for modelName in modelNames:\n",
    "        # retrieve models that match the current name and k-mer\n",
    "        df = score_df[score_df['name'] == modelName]\n",
    "        df = df[df['kmer'] == str(kmer)]\n",
    "        # rename all indices to the name of the model\n",
    "        print(df)\n",
    "        df.index = df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "        \n",
    "        # plot the auc for \n",
    "        df.plot.bar(y=['test_roc_auc', 'test_accuracy'], figsize=(20, 10), rot=0, )\n",
    "        plt.title(f'kmer = {kmer}, feature = {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# xg_boost = score_df[score_df.index.str.contains(f'{name}_{feature}_{kmer}')]\n",
    "# # mlp = score_df[score_df.index.str.contains('mlp')]\n",
    "# # svm = score_df[score_df.index.str.contains('svm')]\n",
    "# xg_boost.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "\n",
    "# xg_boost.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "# pickle.dump(score_df, open('score_df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'test_f1'\n",
    "\n",
    "# Create a figure and subplots for each feature\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "# Loop through each k-mer length\n",
    "for length in range(3, 7):\n",
    "    # Loop through each feature\n",
    "    for i, feature in enumerate(['knn_f1', 'knn_f2', 'knn_f3']):\n",
    "        # Extract the data for the current length and feature\n",
    "        data = [modelScores[model][metric] for model in modelScores]\n",
    "        # print(data)\n",
    "        # Plot the data on the corresponding subplot\n",
    "        axs[i].plot(length, 'o-')\n",
    "        axs[i].set_xlabel('k-mer length')\n",
    "        axs[i].set_ylabel(metric)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump models into pickle - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Searched version of the Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "\"\"\"\n",
    "{'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 0, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3}\n",
    "\"\"\"\n",
    "\n",
    "parameters={\n",
    "   'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 42, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "param_test1 = {'n_estimators':range(100,140,10), 'learning_rate':[0.1,0.15,0.2], 'subsample':[0.8,0.85,0.9], 'max_depth':range(6,9,1), 'min_samples_split':range(10,40,10), 'max_features':range(2, 5)}\n",
    "\n",
    "gradBoost = GridSearchCV(estimator = GradientBoostingClassifier(\n",
    "    n_estimators=parameters['n_estimators'], max_features=parameters['max_features'], random_state=parameters['random_state']), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=-1, cv=5, verbose=10)\n",
    "\n",
    "# parameters['learning_rate']=learning_rate\n",
    "gradBoost.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "def hidden_layers_generator(hidden_layers, max_neurons):\n",
    "  hd_sizes = []\n",
    "  comb = combinations_with_replacement(np.arange(100,max_neurons+10,20), hidden_layers)\n",
    "  hd_sizes.append(list(comb))\n",
    "  return hd_sizes\n",
    "\n",
    "\n",
    "# ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "# X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = np.concatenate([ds['y_train'], ds['y_test']], axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(l)\n",
    "hlg = hidden_layers_generator(hidden_layers=5, max_neurons=200)\n",
    "print(hlg)\n",
    "\n",
    "mlp_gs = MLPClassifier(max_iter=350, random_state=42, solver='adam')\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': hlg[0],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.05, 0.1, 0.2],\n",
    "}\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5, verbose=10, scoring='recall')\n",
    "clf.fit(X_train, y_train) # X is train samples and y is the corresponding labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the ensemble model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp_f2_5</th>\n",
       "      <td>15.924036</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>0.772120</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.877951</td>\n",
       "      <td>0.576176</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>-0.089756</td>\n",
       "      <td>2.252384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_4</th>\n",
       "      <td>11.089791</td>\n",
       "      <td>0.361498</td>\n",
       "      <td>0.776684</td>\n",
       "      <td>0.669933</td>\n",
       "      <td>0.888208</td>\n",
       "      <td>0.602893</td>\n",
       "      <td>0.924755</td>\n",
       "      <td>-0.081424</td>\n",
       "      <td>2.289948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_4</th>\n",
       "      <td>9.182259</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>0.807202</td>\n",
       "      <td>0.660134</td>\n",
       "      <td>0.874936</td>\n",
       "      <td>0.568635</td>\n",
       "      <td>0.923644</td>\n",
       "      <td>-0.091251</td>\n",
       "      <td>2.299728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_6</th>\n",
       "      <td>51.713082</td>\n",
       "      <td>0.975803</td>\n",
       "      <td>0.802646</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.865438</td>\n",
       "      <td>0.537411</td>\n",
       "      <td>0.922410</td>\n",
       "      <td>-0.094534</td>\n",
       "      <td>2.266713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_5</th>\n",
       "      <td>22.543625</td>\n",
       "      <td>0.448890</td>\n",
       "      <td>0.798760</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>0.864683</td>\n",
       "      <td>0.545367</td>\n",
       "      <td>0.921641</td>\n",
       "      <td>-0.091369</td>\n",
       "      <td>2.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_3</th>\n",
       "      <td>12.340601</td>\n",
       "      <td>0.291237</td>\n",
       "      <td>0.768905</td>\n",
       "      <td>0.652754</td>\n",
       "      <td>0.885007</td>\n",
       "      <td>0.577477</td>\n",
       "      <td>0.921104</td>\n",
       "      <td>-0.081278</td>\n",
       "      <td>2.261485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_6</th>\n",
       "      <td>32.217857</td>\n",
       "      <td>0.711247</td>\n",
       "      <td>0.797466</td>\n",
       "      <td>0.631631</td>\n",
       "      <td>0.865719</td>\n",
       "      <td>0.537123</td>\n",
       "      <td>0.920247</td>\n",
       "      <td>-0.098666</td>\n",
       "      <td>2.250678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_4</th>\n",
       "      <td>6.441675</td>\n",
       "      <td>3.110650</td>\n",
       "      <td>0.719567</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.910978</td>\n",
       "      <td>0.675504</td>\n",
       "      <td>0.919531</td>\n",
       "      <td>-0.067792</td>\n",
       "      <td>2.251934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_3</th>\n",
       "      <td>12.692576</td>\n",
       "      <td>0.347511</td>\n",
       "      <td>0.838345</td>\n",
       "      <td>0.647370</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.549583</td>\n",
       "      <td>0.918898</td>\n",
       "      <td>-0.106688</td>\n",
       "      <td>2.297925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_3</th>\n",
       "      <td>5.641986</td>\n",
       "      <td>0.342958</td>\n",
       "      <td>0.790981</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>0.857063</td>\n",
       "      <td>0.507105</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>-0.104020</td>\n",
       "      <td>2.215772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_4</th>\n",
       "      <td>11.664755</td>\n",
       "      <td>0.349464</td>\n",
       "      <td>0.798748</td>\n",
       "      <td>0.630895</td>\n",
       "      <td>0.852824</td>\n",
       "      <td>0.543802</td>\n",
       "      <td>0.915342</td>\n",
       "      <td>-0.103037</td>\n",
       "      <td>2.241947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_5</th>\n",
       "      <td>14.193923</td>\n",
       "      <td>0.403170</td>\n",
       "      <td>0.822114</td>\n",
       "      <td>0.627125</td>\n",
       "      <td>0.841436</td>\n",
       "      <td>0.533414</td>\n",
       "      <td>0.915293</td>\n",
       "      <td>-0.108831</td>\n",
       "      <td>2.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_4</th>\n",
       "      <td>0.445592</td>\n",
       "      <td>0.038928</td>\n",
       "      <td>0.793549</td>\n",
       "      <td>0.609563</td>\n",
       "      <td>0.853675</td>\n",
       "      <td>0.507857</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>-0.107952</td>\n",
       "      <td>2.207646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_4</th>\n",
       "      <td>3.781730</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.610439</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>0.508403</td>\n",
       "      <td>0.912410</td>\n",
       "      <td>-0.126650</td>\n",
       "      <td>2.211819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_3</th>\n",
       "      <td>0.673238</td>\n",
       "      <td>0.063058</td>\n",
       "      <td>0.803329</td>\n",
       "      <td>0.637645</td>\n",
       "      <td>0.849620</td>\n",
       "      <td>0.557842</td>\n",
       "      <td>0.911391</td>\n",
       "      <td>-0.103614</td>\n",
       "      <td>2.248750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_3</th>\n",
       "      <td>0.285895</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.802677</td>\n",
       "      <td>0.635437</td>\n",
       "      <td>0.851127</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.911342</td>\n",
       "      <td>-0.103887</td>\n",
       "      <td>2.245568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_4</th>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.040378</td>\n",
       "      <td>0.824724</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.838614</td>\n",
       "      <td>0.522939</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>-0.109673</td>\n",
       "      <td>2.246250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_4</th>\n",
       "      <td>0.362569</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>0.810438</td>\n",
       "      <td>0.612282</td>\n",
       "      <td>0.837578</td>\n",
       "      <td>0.517284</td>\n",
       "      <td>0.909816</td>\n",
       "      <td>-0.107992</td>\n",
       "      <td>2.224544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_6</th>\n",
       "      <td>24.688657</td>\n",
       "      <td>0.655166</td>\n",
       "      <td>0.800710</td>\n",
       "      <td>0.616385</td>\n",
       "      <td>0.848779</td>\n",
       "      <td>0.511084</td>\n",
       "      <td>0.907131</td>\n",
       "      <td>-0.116227</td>\n",
       "      <td>2.207999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_3</th>\n",
       "      <td>3.706034</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.813729</td>\n",
       "      <td>0.611590</td>\n",
       "      <td>0.834283</td>\n",
       "      <td>0.510669</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>-0.130766</td>\n",
       "      <td>2.201436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_4</th>\n",
       "      <td>4.854494</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.784477</td>\n",
       "      <td>0.600688</td>\n",
       "      <td>0.850097</td>\n",
       "      <td>0.494726</td>\n",
       "      <td>0.906453</td>\n",
       "      <td>-0.116878</td>\n",
       "      <td>2.174739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_3</th>\n",
       "      <td>0.302174</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.773442</td>\n",
       "      <td>0.621379</td>\n",
       "      <td>0.865813</td>\n",
       "      <td>0.532533</td>\n",
       "      <td>0.906330</td>\n",
       "      <td>-0.104486</td>\n",
       "      <td>2.196666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_5</th>\n",
       "      <td>9.465925</td>\n",
       "      <td>0.034712</td>\n",
       "      <td>0.812378</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>0.830335</td>\n",
       "      <td>0.488686</td>\n",
       "      <td>0.906172</td>\n",
       "      <td>-0.128270</td>\n",
       "      <td>2.186007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_3</th>\n",
       "      <td>1.038879</td>\n",
       "      <td>1.184440</td>\n",
       "      <td>0.768264</td>\n",
       "      <td>0.647079</td>\n",
       "      <td>0.879455</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>0.905979</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>2.235682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_5</th>\n",
       "      <td>0.689596</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.591479</td>\n",
       "      <td>0.840783</td>\n",
       "      <td>0.484103</td>\n",
       "      <td>0.904987</td>\n",
       "      <td>-0.119008</td>\n",
       "      <td>2.163896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_5</th>\n",
       "      <td>7.592996</td>\n",
       "      <td>0.029067</td>\n",
       "      <td>0.833159</td>\n",
       "      <td>0.592928</td>\n",
       "      <td>0.823558</td>\n",
       "      <td>0.472651</td>\n",
       "      <td>0.904883</td>\n",
       "      <td>-0.132882</td>\n",
       "      <td>2.198087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_5</th>\n",
       "      <td>0.600037</td>\n",
       "      <td>0.047326</td>\n",
       "      <td>0.815650</td>\n",
       "      <td>0.598944</td>\n",
       "      <td>0.830617</td>\n",
       "      <td>0.490948</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>-0.117375</td>\n",
       "      <td>2.200967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_4</th>\n",
       "      <td>3.836938</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.809137</td>\n",
       "      <td>0.595484</td>\n",
       "      <td>0.825722</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.903461</td>\n",
       "      <td>-0.137475</td>\n",
       "      <td>2.170607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_5</th>\n",
       "      <td>0.539838</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.591998</td>\n",
       "      <td>0.828075</td>\n",
       "      <td>0.486979</td>\n",
       "      <td>0.901582</td>\n",
       "      <td>-0.116478</td>\n",
       "      <td>2.179111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_5</th>\n",
       "      <td>8.804009</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>0.791603</td>\n",
       "      <td>0.599354</td>\n",
       "      <td>0.846427</td>\n",
       "      <td>0.490437</td>\n",
       "      <td>0.900486</td>\n",
       "      <td>-0.119766</td>\n",
       "      <td>2.171676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_6</th>\n",
       "      <td>20.366165</td>\n",
       "      <td>0.105669</td>\n",
       "      <td>0.778634</td>\n",
       "      <td>0.598744</td>\n",
       "      <td>0.851510</td>\n",
       "      <td>0.493244</td>\n",
       "      <td>0.898890</td>\n",
       "      <td>-0.113888</td>\n",
       "      <td>2.162381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_3</th>\n",
       "      <td>3.248140</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.599358</td>\n",
       "      <td>0.828733</td>\n",
       "      <td>0.492479</td>\n",
       "      <td>0.898356</td>\n",
       "      <td>-0.136489</td>\n",
       "      <td>2.171047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_3</th>\n",
       "      <td>3.682933</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.598575</td>\n",
       "      <td>0.843888</td>\n",
       "      <td>0.487860</td>\n",
       "      <td>0.897144</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>2.170120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_6</th>\n",
       "      <td>17.451774</td>\n",
       "      <td>0.111097</td>\n",
       "      <td>0.796165</td>\n",
       "      <td>0.591721</td>\n",
       "      <td>0.830993</td>\n",
       "      <td>0.484625</td>\n",
       "      <td>0.897075</td>\n",
       "      <td>-0.125599</td>\n",
       "      <td>2.159362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_6</th>\n",
       "      <td>1.489658</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.803312</td>\n",
       "      <td>0.593031</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.478589</td>\n",
       "      <td>0.895875</td>\n",
       "      <td>-0.126014</td>\n",
       "      <td>2.166204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_6</th>\n",
       "      <td>1.732900</td>\n",
       "      <td>0.076980</td>\n",
       "      <td>0.786450</td>\n",
       "      <td>0.583221</td>\n",
       "      <td>0.830807</td>\n",
       "      <td>0.473061</td>\n",
       "      <td>0.891833</td>\n",
       "      <td>-0.126887</td>\n",
       "      <td>2.134617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_6</th>\n",
       "      <td>17.824493</td>\n",
       "      <td>0.115081</td>\n",
       "      <td>0.785811</td>\n",
       "      <td>0.577491</td>\n",
       "      <td>0.824690</td>\n",
       "      <td>0.466525</td>\n",
       "      <td>0.891658</td>\n",
       "      <td>-0.131098</td>\n",
       "      <td>2.123862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_4</th>\n",
       "      <td>4.718837</td>\n",
       "      <td>2.710278</td>\n",
       "      <td>0.735836</td>\n",
       "      <td>0.640125</td>\n",
       "      <td>0.877006</td>\n",
       "      <td>0.589200</td>\n",
       "      <td>0.891367</td>\n",
       "      <td>-0.087407</td>\n",
       "      <td>2.179921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_6</th>\n",
       "      <td>1.817674</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>0.773448</td>\n",
       "      <td>0.578940</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>0.470116</td>\n",
       "      <td>0.887994</td>\n",
       "      <td>-0.130979</td>\n",
       "      <td>2.109403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_5</th>\n",
       "      <td>31.866920</td>\n",
       "      <td>12.237243</td>\n",
       "      <td>0.331923</td>\n",
       "      <td>0.441294</td>\n",
       "      <td>0.893666</td>\n",
       "      <td>0.840362</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>-0.097267</td>\n",
       "      <td>1.551821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_3</th>\n",
       "      <td>1.820357</td>\n",
       "      <td>1.633793</td>\n",
       "      <td>0.622311</td>\n",
       "      <td>0.662268</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.767073</td>\n",
       "      <td>0.869088</td>\n",
       "      <td>-0.079287</td>\n",
       "      <td>2.074380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_5</th>\n",
       "      <td>25.571607</td>\n",
       "      <td>10.544783</td>\n",
       "      <td>0.746167</td>\n",
       "      <td>0.529174</td>\n",
       "      <td>0.821587</td>\n",
       "      <td>0.416319</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>-0.132012</td>\n",
       "      <td>1.986526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_4</th>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.094598</td>\n",
       "      <td>0.843574</td>\n",
       "      <td>0.600126</td>\n",
       "      <td>0.828073</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>-0.171927</td>\n",
       "      <td>2.106274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_4</th>\n",
       "      <td>0.020680</td>\n",
       "      <td>0.063363</td>\n",
       "      <td>0.836393</td>\n",
       "      <td>0.602951</td>\n",
       "      <td>0.823459</td>\n",
       "      <td>0.484549</td>\n",
       "      <td>0.828818</td>\n",
       "      <td>-0.176541</td>\n",
       "      <td>2.091622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_3</th>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>0.816952</td>\n",
       "      <td>0.605047</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.492244</td>\n",
       "      <td>0.824382</td>\n",
       "      <td>-0.170330</td>\n",
       "      <td>2.076051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_3</th>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.231269</td>\n",
       "      <td>0.806540</td>\n",
       "      <td>0.601296</td>\n",
       "      <td>0.833246</td>\n",
       "      <td>0.488866</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>-0.166754</td>\n",
       "      <td>2.063229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_5</th>\n",
       "      <td>0.103366</td>\n",
       "      <td>0.142831</td>\n",
       "      <td>0.833796</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>0.803982</td>\n",
       "      <td>0.451276</td>\n",
       "      <td>0.816347</td>\n",
       "      <td>-0.196018</td>\n",
       "      <td>2.028272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_5</th>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.658764</td>\n",
       "      <td>0.828626</td>\n",
       "      <td>0.580329</td>\n",
       "      <td>0.807085</td>\n",
       "      <td>0.458295</td>\n",
       "      <td>0.816019</td>\n",
       "      <td>-0.192915</td>\n",
       "      <td>2.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_4</th>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.342905</td>\n",
       "      <td>0.806529</td>\n",
       "      <td>0.582733</td>\n",
       "      <td>0.820355</td>\n",
       "      <td>0.465186</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>-0.179645</td>\n",
       "      <td>2.024220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_3</th>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.075899</td>\n",
       "      <td>0.806550</td>\n",
       "      <td>0.571077</td>\n",
       "      <td>0.817534</td>\n",
       "      <td>0.447359</td>\n",
       "      <td>0.812961</td>\n",
       "      <td>-0.182466</td>\n",
       "      <td>2.008124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_6</th>\n",
       "      <td>0.571335</td>\n",
       "      <td>0.524108</td>\n",
       "      <td>0.890291</td>\n",
       "      <td>0.547672</td>\n",
       "      <td>0.758054</td>\n",
       "      <td>0.405223</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>-0.241946</td>\n",
       "      <td>2.008967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_6</th>\n",
       "      <td>101.628998</td>\n",
       "      <td>47.863987</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.183716</td>\n",
       "      <td>0.866661</td>\n",
       "      <td>0.830364</td>\n",
       "      <td>0.811934</td>\n",
       "      <td>-0.122386</td>\n",
       "      <td>0.982820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_6</th>\n",
       "      <td>0.575760</td>\n",
       "      <td>1.994528</td>\n",
       "      <td>0.868218</td>\n",
       "      <td>0.548453</td>\n",
       "      <td>0.767277</td>\n",
       "      <td>0.410217</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>-0.232723</td>\n",
       "      <td>1.993125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_5</th>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.154376</td>\n",
       "      <td>0.793591</td>\n",
       "      <td>0.559959</td>\n",
       "      <td>0.816123</td>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.806757</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>1.976429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_6</th>\n",
       "      <td>109.113722</td>\n",
       "      <td>50.533002</td>\n",
       "      <td>0.889823</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>0.492795</td>\n",
       "      <td>0.219566</td>\n",
       "      <td>0.755696</td>\n",
       "      <td>-0.223824</td>\n",
       "      <td>1.770596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_6</th>\n",
       "      <td>0.560864</td>\n",
       "      <td>0.492484</td>\n",
       "      <td>0.731347</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>0.753360</td>\n",
       "      <td>0.345941</td>\n",
       "      <td>0.744210</td>\n",
       "      <td>-0.246640</td>\n",
       "      <td>1.696414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_3</th>\n",
       "      <td>1.900592</td>\n",
       "      <td>1.832925</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.510707</td>\n",
       "      <td>-0.145274</td>\n",
       "      <td>0.369314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_4</th>\n",
       "      <td>6.530042</td>\n",
       "      <td>3.442770</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>-0.145736</td>\n",
       "      <td>0.366394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_5</th>\n",
       "      <td>31.155923</td>\n",
       "      <td>12.689633</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506470</td>\n",
       "      <td>-0.146036</td>\n",
       "      <td>0.364315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_6</th>\n",
       "      <td>109.180324</td>\n",
       "      <td>53.783038</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>-0.146554</td>\n",
       "      <td>0.363512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fit_time  score_time  test_recall   test_f1  test_accuracy  \\\n",
       "mlp_f2_5   15.924036    0.425549     0.772120  0.644200       0.877951   \n",
       "mlp_f2_4   11.089791    0.361498     0.776684  0.669933       0.888208   \n",
       "mlp_f1_4    9.182259    0.385886     0.807202  0.660134       0.874936   \n",
       "mlp_f1_6   51.713082    0.975803     0.802646  0.636191       0.865438   \n",
       "mlp_f1_5   22.543625    0.448890     0.798760  0.635674       0.864683   \n",
       "mlp_f2_3   12.340601    0.291237     0.768905  0.652754       0.885007   \n",
       "mlp_f2_6   32.217857    0.711247     0.797466  0.631631       0.865719   \n",
       "svm_f2_4    6.441675    3.110650     0.719567  0.680628       0.910978   \n",
       "mlp_f3_3   12.692576    0.347511     0.838345  0.647370       0.849434   \n",
       "mlp_f1_3    5.641986    0.342958     0.790981  0.612923       0.857063   \n",
       "mlp_f3_4   11.664755    0.349464     0.798748  0.630895       0.852824   \n",
       "mlp_f3_5   14.193923    0.403170     0.822114  0.627125       0.841436   \n",
       "rf_f2_4     0.445592    0.038928     0.793549  0.609563       0.853675   \n",
       "xgb_f1_4    3.781730    0.019563     0.815620  0.610439       0.838329   \n",
       "rf_f1_3     0.673238    0.063058     0.803329  0.637645       0.849620   \n",
       "rf_f3_3     0.285895    0.036070     0.802677  0.635437       0.851127   \n",
       "rf_f1_4     0.382800    0.040378     0.824724  0.620705       0.838614   \n",
       "rf_f3_4     0.362569    0.039601     0.810438  0.612282       0.837578   \n",
       "mlp_f3_6   24.688657    0.655166     0.800710  0.616385       0.848779   \n",
       "xgb_f3_3    3.706034    0.014566     0.813729  0.611590       0.834283   \n",
       "xgb_f2_4    4.854494    0.018355     0.784477  0.600688       0.850097   \n",
       "rf_f2_3     0.302174    0.038896     0.773442  0.621379       0.865813   \n",
       "xgb_f1_5    9.465925    0.034712     0.812378  0.595728       0.830335   \n",
       "svm_f2_3    1.038879    1.184440     0.768264  0.647079       0.879455   \n",
       "rf_f2_5     0.689596    0.046993     0.786437  0.591479       0.840783   \n",
       "xgb_f3_5    7.592996    0.029067     0.833159  0.592928       0.823558   \n",
       "rf_f1_5     0.600037    0.047326     0.815650  0.598944       0.830617   \n",
       "xgb_f3_4    3.836938    0.018232     0.809137  0.595484       0.825722   \n",
       "rf_f3_5     0.539838    0.048029     0.802009  0.591998       0.828075   \n",
       "xgb_f2_5    8.804009    0.030939     0.791603  0.599354       0.846427   \n",
       "xgb_f2_6   20.366165    0.105669     0.778634  0.598744       0.851510   \n",
       "xgb_f1_3    3.248140    0.015208     0.809822  0.599358       0.828733   \n",
       "xgb_f2_3    3.682933    0.015455     0.797451  0.598575       0.843888   \n",
       "xgb_f3_6   17.451774    0.111097     0.796165  0.591721       0.830993   \n",
       "rf_f3_6     1.489658    0.075362     0.803312  0.593031       0.835700   \n",
       "rf_f1_6     1.732900    0.076980     0.786450  0.583221       0.830807   \n",
       "xgb_f1_6   17.824493    0.115081     0.785811  0.577491       0.824690   \n",
       "svm_f3_4    4.718837    2.710278     0.735836  0.640125       0.877006   \n",
       "rf_f2_6     1.817674    0.074688     0.773448  0.578940       0.837394   \n",
       "svm_f2_5   31.866920   12.237243     0.331923  0.441294       0.893666   \n",
       "svm_f3_3    1.820357    1.633793     0.622311  0.662268       0.904762   \n",
       "svm_f3_5   25.571607   10.544783     0.746167  0.529174       0.821587   \n",
       "knn_f2_4    0.021011    0.094598     0.843574  0.600126       0.828073   \n",
       "knn_f3_4    0.020680    0.063363     0.836393  0.602951       0.823459   \n",
       "knn_f3_3    0.006074    0.036097     0.816952  0.605047       0.829670   \n",
       "knn_f1_3    0.006434    0.231269     0.806540  0.601296       0.833246   \n",
       "knn_f3_5    0.103366    0.142831     0.833796  0.574147       0.803982   \n",
       "knn_f1_5    0.107660    0.658764     0.828626  0.580329       0.807085   \n",
       "knn_f1_4    0.021277    0.342905     0.806529  0.582733       0.820355   \n",
       "knn_f2_3    0.006704    0.075899     0.806550  0.571077       0.817534   \n",
       "knn_f3_6    0.571335    0.524108     0.890291  0.547672       0.758054   \n",
       "svm_f2_6  101.628998   47.863987     0.109555  0.183716       0.866661   \n",
       "knn_f1_6    0.575760    1.994528     0.868218  0.548453       0.767277   \n",
       "knn_f2_5    0.105476    0.154376     0.793591  0.559959       0.816123   \n",
       "svm_f3_6  109.113722   50.533002     0.889823  0.348902       0.492795   \n",
       "knn_f2_6    0.560864    0.492484     0.731347  0.467497       0.753360   \n",
       "svm_f1_3    1.900592    1.832925     0.001297  0.002585       0.855086   \n",
       "svm_f1_4    6.530042    3.442770     0.001297  0.002585       0.855086   \n",
       "svm_f1_5   31.155923   12.689633     0.001297  0.002585       0.855086   \n",
       "svm_f1_6  109.180324   53.783038     0.001297  0.002585       0.855086   \n",
       "\n",
       "          test_precision  test_roc_auc  test_neg_brier_score     total  \n",
       "mlp_f2_5        0.576176      0.925820             -0.089756  2.252384  \n",
       "mlp_f2_4        0.602893      0.924755             -0.081424  2.289948  \n",
       "mlp_f1_4        0.568635      0.923644             -0.091251  2.299728  \n",
       "mlp_f1_6        0.537411      0.922410             -0.094534  2.266713  \n",
       "mlp_f1_5        0.545367      0.921641             -0.091369  2.264706  \n",
       "mlp_f2_3        0.577477      0.921104             -0.081278  2.261485  \n",
       "mlp_f2_6        0.537123      0.920247             -0.098666  2.250678  \n",
       "svm_f2_4        0.675504      0.919531             -0.067792  2.251934  \n",
       "mlp_f3_3        0.549583      0.918898             -0.106688  2.297925  \n",
       "mlp_f1_3        0.507105      0.915888             -0.104020  2.215772  \n",
       "mlp_f3_4        0.543802      0.915342             -0.103037  2.241947  \n",
       "mlp_f3_5        0.533414      0.915293             -0.108831  2.255700  \n",
       "rf_f2_4         0.507857      0.912487             -0.107952  2.207646  \n",
       "xgb_f1_4        0.508403      0.912410             -0.126650  2.211819  \n",
       "rf_f1_3         0.557842      0.911391             -0.103614  2.248750  \n",
       "rf_f3_3         0.555866      0.911342             -0.103887  2.245568  \n",
       "rf_f1_4         0.522939      0.910494             -0.109673  2.246250  \n",
       "rf_f3_4         0.517284      0.909816             -0.107992  2.224544  \n",
       "mlp_f3_6        0.511084      0.907131             -0.116227  2.207999  \n",
       "xgb_f3_3        0.510669      0.906883             -0.130766  2.201436  \n",
       "xgb_f2_4        0.494726      0.906453             -0.116878  2.174739  \n",
       "rf_f2_3         0.532533      0.906330             -0.104486  2.196666  \n",
       "xgb_f1_5        0.488686      0.906172             -0.128270  2.186007  \n",
       "svm_f2_3        0.569462      0.905979             -0.085639  2.235682  \n",
       "rf_f2_5         0.484103      0.904987             -0.119008  2.163896  \n",
       "xgb_f3_5        0.472651      0.904883             -0.132882  2.198087  \n",
       "rf_f1_5         0.490948      0.903748             -0.117375  2.200967  \n",
       "xgb_f3_4        0.495100      0.903461             -0.137475  2.170607  \n",
       "rf_f3_5         0.486979      0.901582             -0.116478  2.179111  \n",
       "xgb_f2_5        0.490437      0.900486             -0.119766  2.171676  \n",
       "xgb_f2_6        0.493244      0.898890             -0.113888  2.162381  \n",
       "xgb_f1_3        0.492479      0.898356             -0.136489  2.171047  \n",
       "xgb_f2_3        0.487860      0.897144             -0.123050  2.170120  \n",
       "xgb_f3_6        0.484625      0.897075             -0.125599  2.159362  \n",
       "rf_f3_6         0.478589      0.895875             -0.126014  2.166204  \n",
       "rf_f1_6         0.473061      0.891833             -0.126887  2.134617  \n",
       "xgb_f1_6        0.466525      0.891658             -0.131098  2.123862  \n",
       "svm_f3_4        0.589200      0.891367             -0.087407  2.179921  \n",
       "rf_f2_6         0.470116      0.887994             -0.130979  2.109403  \n",
       "svm_f2_5        0.840362      0.875871             -0.097267  1.551821  \n",
       "svm_f3_3        0.767073      0.869088             -0.079287  2.074380  \n",
       "svm_f3_5        0.416319      0.843197             -0.132012  1.986526  \n",
       "knn_f2_4        0.470838      0.834500             -0.171927  2.106274  \n",
       "knn_f3_4        0.484549      0.828818             -0.176541  2.091622  \n",
       "knn_f3_3        0.492244      0.824382             -0.170330  2.076051  \n",
       "knn_f1_3        0.488866      0.822147             -0.166754  2.063229  \n",
       "knn_f3_5        0.451276      0.816347             -0.196018  2.028272  \n",
       "knn_f1_5        0.458295      0.816019             -0.192915  2.032059  \n",
       "knn_f1_4        0.465186      0.814602             -0.179645  2.024220  \n",
       "knn_f2_3        0.447359      0.812961             -0.182466  2.008124  \n",
       "knn_f3_6        0.405223      0.812950             -0.241946  2.008967  \n",
       "svm_f2_6        0.830364      0.811934             -0.122386  0.982820  \n",
       "knn_f1_6        0.410217      0.809178             -0.232723  1.993125  \n",
       "knn_f2_5        0.434940      0.806757             -0.183877  1.976429  \n",
       "svm_f3_6        0.219566      0.755696             -0.223824  1.770596  \n",
       "knn_f2_6        0.345941      0.744210             -0.246640  1.696414  \n",
       "svm_f1_3        0.400000      0.510707             -0.145274  0.369314  \n",
       "svm_f1_4        0.400000      0.508248             -0.145736  0.366394  \n",
       "svm_f1_5        0.400000      0.506470             -0.146036  0.364315  \n",
       "svm_f1_6        0.400000      0.506185             -0.146554  0.363512  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "score_df = score_df.sort_values(by=['test'], ascending=False)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.61638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.80782\n",
      "[20]\tvalidation_0-aucpr:0.82789\n",
      "[30]\tvalidation_0-aucpr:0.84020\n",
      "[40]\tvalidation_0-aucpr:0.84760\n",
      "[50]\tvalidation_0-aucpr:0.85234\n",
      "[60]\tvalidation_0-aucpr:0.85953\n",
      "[70]\tvalidation_0-aucpr:0.86429\n",
      "[80]\tvalidation_0-aucpr:0.86687\n",
      "[90]\tvalidation_0-aucpr:0.87223\n",
      "[100]\tvalidation_0-aucpr:0.87421\n",
      "[110]\tvalidation_0-aucpr:0.87528\n",
      "[120]\tvalidation_0-aucpr:0.87590\n",
      "[130]\tvalidation_0-aucpr:0.87729\n",
      "[140]\tvalidation_0-aucpr:0.87882\n",
      "[150]\tvalidation_0-aucpr:0.87985\n",
      "[160]\tvalidation_0-aucpr:0.88051\n",
      "[170]\tvalidation_0-aucpr:0.88118\n",
      "[180]\tvalidation_0-aucpr:0.88190\n",
      "[188]\tvalidation_0-aucpr:0.88187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=42, ...)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained models\n",
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP: f2_4\n",
    "mlp = BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# knn\n",
    "knn = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=1, n_jobs=-1), n_estimators=1, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# SVM: f2_4\n",
    "# temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42), n_estimators=10, n_jobs=-1)\n",
    "\n",
    "# temp_svm.fit(X_train, y_train)\n",
    "\n",
    "# RF: f2_4\n",
    "randforest = BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1)\n",
    "\n",
    "randforest.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost: f2_4\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=200,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    ")\n",
    "X_train_xg, X_validation, y_train_xg, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "xgb1.fit(X_train_xg.values, y_train_xg, eval_metric='aucpr', eval_set=[(X_validation.values, y_validation)], early_stopping_rounds=10, verbose=10)\n",
    "# print(\"cross validating stacking classifier\")\n",
    "# print(em.cross_validate(X, y, cv=5))\n",
    "# xgb1 = pickle.load(open('models/curr_models/xgb1-test.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# xgb1.fit(X_train, y_train)\n",
    "\n",
    "# em = StackingCVClassifier(classifiers = [mlp, randforest, xgb1],\n",
    "#                             # shuffle = True,\n",
    "#                             use_probas = True,\n",
    "#                             cv = 5,\n",
    "#                             use_features_in_secondary=True,\n",
    "#                             meta_classifier = LogisticRegression(C = 1, random_state=42, solver='saga'), n_jobs=-1, random_state=42, verbose=1, store_train_meta_features=True)\n",
    "# x = cross_validate(em, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'], verbose=1, n_jobs=-1)\n",
    "# name = 'ensemble_lengthdiv_4'\n",
    "# if (name not in modelScores):\n",
    "#     modelScores[name] = {}\n",
    "#     for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "#         modelScores[name][k]=v.mean()\n",
    "# else:\n",
    "#     print('already in modelScores')\n",
    "# em.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingClassifier():\n",
    "    def __init__(self, classifiers, meta_classifier, n_folds=5, use_probas=True):\n",
    "        self.classifiers = classifiers # assume pretrained\n",
    "        self.meta_classifier = meta_classifier # logistic regression\n",
    "        self.n_folds = n_folds\n",
    "        self.X_train_new=None\n",
    "        self.X_test_new=None\n",
    "        self.y_train_new=None\n",
    "        self.use_probas = use_probas\n",
    "        self.feature_names_in = None\n",
    "\n",
    "    def fit_pretrained(self, X_train, y_train):\n",
    "        self.X_train_new = np.zeros((X_train.shape[0], len(self.classifiers)))\n",
    "        self.y_train_new = y_train\n",
    "        print(X_train.shape[0], len(y_train))\n",
    "        \n",
    "        for i, clf in enumerate(self.classifiers):\n",
    "            if self.use_probas:\n",
    "                self.X_train_new[:, i] = model.predict_proba(X_train)[:,1]\n",
    "            else:\n",
    "                self.X_train_new[:, i] = model.predict(X_train)\n",
    "\n",
    "        print(len(self.X_train_new))\n",
    "        \n",
    "        self.meta_classifier = self.meta_classifier.fit(self.X_train_new, self.y_train_new)\n",
    "\n",
    "    def fit_not_pretrained(self, X_train, y_train): # assume NOT pretrained\n",
    "        print(X_train.shape[0], len(y_train))\n",
    "        # X_train = X_train.values\n",
    "        for index, clf in enumerate(self.classifiers):\n",
    "            print(type(clf).__name__)\n",
    "            if type(clf).__name__ != 'XGBClassifier':\n",
    "                self.classifiers[index] = clf.fit(X_train, y_train)\n",
    "            else:\n",
    "                print(\"xgboost detected\")\n",
    "                X_train_temp, X_validation, y_train_temp, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "                self.classifiers[index] = clf.fit(X_train_temp, y_train_temp, eval_metric='aucpr', eval_set=[(X_validation, y_validation)], early_stopping_rounds=15, verbose=10)\n",
    "                self.feature_names_in = clf.get_booster().feature_names\n",
    "        \n",
    "        self.fit_pretrained(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # make \n",
    "        meta_features = np.column_stack([\n",
    "            clf.predict(X) for clf in self.classifiers\n",
    "        ])\n",
    "        return self.meta_classifier.predict(meta_features)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            clf.predict_proba(X)[:,1] for clf in self.classifiers\n",
    "        ])\n",
    "        return self.meta_classifier.predict_proba(meta_features)\n",
    "\n",
    "    def cross_validate(self, X, y, scoring=['precision', 'recall', 'f1', 'average_precision'], cv=5):\n",
    "        kfold = KFold(n_splits=cv)\n",
    "        scores = {s: [] for s in scoring}\n",
    "        metrics = {\n",
    "            'recall': recall_score,\n",
    "            'f1': f1_score,\n",
    "            'accuracy': accuracy_score,\n",
    "            'precision': precision_score,\n",
    "            'roc_auc': roc_auc_score,\n",
    "            'neg_brier_score': brier_score_loss,\n",
    "            'average_precision': average_precision_score\n",
    "        }\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "            self.fit_not_pretrained(X_train, y_train)\n",
    "            if self.use_probas:\n",
    "                y_pred = self.predict_proba(X_test)[:,1]\n",
    "\n",
    "                print(y_pred.sum())\n",
    "\n",
    "                for s in scoring:\n",
    "                    # if s == 'accuracy' or s == 'precision' or s == 'recall':\n",
    "                    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "                    scores[s].append(metrics[s](y_test, y_pred))\n",
    "            else:\n",
    "                print(\"not use probas\")\n",
    "                y_pred = self.predict(X_test)\n",
    "\n",
    "                print(y_pred.sum())\n",
    "\n",
    "                for s in scoring:\n",
    "                    met = metrics[s](y_test, y_pred)\n",
    "                    print(s, met)\n",
    "                    scores[s].append(met)\n",
    "\n",
    "        return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8501 8501\n",
      "8501\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression(C = 1, random_state=42, solver='saga')\n",
    "\n",
    "em = StackingClassifier(classifiers = [mlp, randforest, xgb1], use_probas = False, meta_classifier = BalancedBaggingClassifier(base_estimator=LogisticRegression(C = 1, random_state=42, solver='saga'), n_estimators=1, random_state=42))\n",
    "\n",
    "em.fit_pretrained(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7650, 256) (851, 256) (7650,) (851,)\n",
      "7650 7650\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.57826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.79737\n",
      "[20]\tvalidation_0-aucpr:0.82178\n",
      "[30]\tvalidation_0-aucpr:0.83245\n",
      "[40]\tvalidation_0-aucpr:0.84122\n",
      "[50]\tvalidation_0-aucpr:0.84429\n",
      "[60]\tvalidation_0-aucpr:0.84665\n",
      "[70]\tvalidation_0-aucpr:0.85003\n",
      "[80]\tvalidation_0-aucpr:0.85263\n",
      "[90]\tvalidation_0-aucpr:0.85503\n",
      "[100]\tvalidation_0-aucpr:0.85709\n",
      "[110]\tvalidation_0-aucpr:0.85670\n",
      "[115]\tvalidation_0-aucpr:0.85743\n",
      "7650 7650\n",
      "7650\n",
      "not use probas\n",
      "267\n",
      "precision 0.4419475655430712\n",
      "recall 0.9007633587786259\n",
      "f1 0.592964824120603\n",
      "average_precision 0.41336631925354206\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.57924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.78251\n",
      "[20]\tvalidation_0-aucpr:0.81473\n",
      "[30]\tvalidation_0-aucpr:0.83312\n",
      "[40]\tvalidation_0-aucpr:0.84199\n",
      "[50]\tvalidation_0-aucpr:0.84812\n",
      "[60]\tvalidation_0-aucpr:0.85464\n",
      "[70]\tvalidation_0-aucpr:0.85723\n",
      "[80]\tvalidation_0-aucpr:0.85970\n",
      "[90]\tvalidation_0-aucpr:0.86153\n",
      "[100]\tvalidation_0-aucpr:0.86134\n",
      "[106]\tvalidation_0-aucpr:0.86016\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "248\n",
      "precision 0.5\n",
      "recall 0.9117647058823529\n",
      "f1 0.6458333333333334\n",
      "average_precision 0.47\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.57173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.80586\n",
      "[20]\tvalidation_0-aucpr:0.82899\n",
      "[30]\tvalidation_0-aucpr:0.83683\n",
      "[40]\tvalidation_0-aucpr:0.84727\n",
      "[50]\tvalidation_0-aucpr:0.85352\n",
      "[60]\tvalidation_0-aucpr:0.85655\n",
      "[70]\tvalidation_0-aucpr:0.86106\n",
      "[80]\tvalidation_0-aucpr:0.86460\n",
      "[90]\tvalidation_0-aucpr:0.86730\n",
      "[100]\tvalidation_0-aucpr:0.87070\n",
      "[110]\tvalidation_0-aucpr:0.87167\n",
      "[120]\tvalidation_0-aucpr:0.87292\n",
      "[130]\tvalidation_0-aucpr:0.87333\n",
      "[140]\tvalidation_0-aucpr:0.87410\n",
      "[150]\tvalidation_0-aucpr:0.87441\n",
      "[160]\tvalidation_0-aucpr:0.87573\n",
      "[170]\tvalidation_0-aucpr:0.87506\n",
      "[174]\tvalidation_0-aucpr:0.87541\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "165\n",
      "precision 0.6303030303030303\n",
      "recall 0.8\n",
      "f1 0.705084745762712\n",
      "average_precision 0.534830659536542\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.57999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.79102\n",
      "[20]\tvalidation_0-aucpr:0.82076\n",
      "[30]\tvalidation_0-aucpr:0.83326\n",
      "[40]\tvalidation_0-aucpr:0.84633\n",
      "[50]\tvalidation_0-aucpr:0.85295\n",
      "[60]\tvalidation_0-aucpr:0.85920\n",
      "[70]\tvalidation_0-aucpr:0.86269\n",
      "[80]\tvalidation_0-aucpr:0.86484\n",
      "[90]\tvalidation_0-aucpr:0.86499\n",
      "[100]\tvalidation_0-aucpr:0.86708\n",
      "[110]\tvalidation_0-aucpr:0.86845\n",
      "[120]\tvalidation_0-aucpr:0.86996\n",
      "[130]\tvalidation_0-aucpr:0.87070\n",
      "[140]\tvalidation_0-aucpr:0.87113\n",
      "[150]\tvalidation_0-aucpr:0.87165\n",
      "[160]\tvalidation_0-aucpr:0.87279\n",
      "[170]\tvalidation_0-aucpr:0.87385\n",
      "[180]\tvalidation_0-aucpr:0.87463\n",
      "[190]\tvalidation_0-aucpr:0.87524\n",
      "[199]\tvalidation_0-aucpr:0.87585\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "156\n",
      "precision 0.6602564102564102\n",
      "recall 0.8110236220472441\n",
      "f1 0.7279151943462897\n",
      "average_precision 0.563718839443712\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.59553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.82148\n",
      "[20]\tvalidation_0-aucpr:0.84845\n",
      "[30]\tvalidation_0-aucpr:0.86014\n",
      "[40]\tvalidation_0-aucpr:0.86481\n",
      "[50]\tvalidation_0-aucpr:0.87199\n",
      "[60]\tvalidation_0-aucpr:0.87447\n",
      "[70]\tvalidation_0-aucpr:0.87831\n",
      "[80]\tvalidation_0-aucpr:0.87949\n",
      "[90]\tvalidation_0-aucpr:0.88014\n",
      "[100]\tvalidation_0-aucpr:0.88320\n",
      "[110]\tvalidation_0-aucpr:0.88595\n",
      "[120]\tvalidation_0-aucpr:0.88724\n",
      "[130]\tvalidation_0-aucpr:0.88838\n",
      "[140]\tvalidation_0-aucpr:0.88931\n",
      "[150]\tvalidation_0-aucpr:0.89115\n",
      "[160]\tvalidation_0-aucpr:0.89148\n",
      "[170]\tvalidation_0-aucpr:0.89253\n",
      "[180]\tvalidation_0-aucpr:0.89339\n",
      "[190]\tvalidation_0-aucpr:0.89406\n",
      "[197]\tvalidation_0-aucpr:0.89383\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "148\n",
      "precision 0.6486486486486487\n",
      "recall 0.8067226890756303\n",
      "f1 0.7191011235955056\n",
      "average_precision 0.5503384056325233\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.59305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.78311\n",
      "[20]\tvalidation_0-aucpr:0.81986\n",
      "[30]\tvalidation_0-aucpr:0.83291\n",
      "[40]\tvalidation_0-aucpr:0.84270\n",
      "[50]\tvalidation_0-aucpr:0.84931\n",
      "[60]\tvalidation_0-aucpr:0.85232\n",
      "[70]\tvalidation_0-aucpr:0.85589\n",
      "[80]\tvalidation_0-aucpr:0.85814\n",
      "[90]\tvalidation_0-aucpr:0.86202\n",
      "[100]\tvalidation_0-aucpr:0.86326\n",
      "[110]\tvalidation_0-aucpr:0.86483\n",
      "[120]\tvalidation_0-aucpr:0.86632\n",
      "[130]\tvalidation_0-aucpr:0.86885\n",
      "[140]\tvalidation_0-aucpr:0.86997\n",
      "[150]\tvalidation_0-aucpr:0.87072\n",
      "[160]\tvalidation_0-aucpr:0.87225\n",
      "[170]\tvalidation_0-aucpr:0.87309\n",
      "[180]\tvalidation_0-aucpr:0.87384\n",
      "[190]\tvalidation_0-aucpr:0.87429\n",
      "[199]\tvalidation_0-aucpr:0.87511\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "154\n",
      "precision 0.564935064935065\n",
      "recall 0.8055555555555556\n",
      "f1 0.6641221374045801\n",
      "average_precision 0.4797924624395213\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.52654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.78228\n",
      "[20]\tvalidation_0-aucpr:0.80811\n",
      "[30]\tvalidation_0-aucpr:0.82969\n",
      "[40]\tvalidation_0-aucpr:0.84069\n",
      "[50]\tvalidation_0-aucpr:0.85011\n",
      "[60]\tvalidation_0-aucpr:0.85526\n",
      "[70]\tvalidation_0-aucpr:0.85873\n",
      "[80]\tvalidation_0-aucpr:0.86342\n",
      "[90]\tvalidation_0-aucpr:0.86592\n",
      "[100]\tvalidation_0-aucpr:0.86753\n",
      "[110]\tvalidation_0-aucpr:0.86797\n",
      "[120]\tvalidation_0-aucpr:0.86811\n",
      "[130]\tvalidation_0-aucpr:0.86843\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "149\n",
      "precision 0.5771812080536913\n",
      "recall 0.7889908256880734\n",
      "f1 0.6666666666666667\n",
      "average_precision 0.4824495014433334\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.62197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.79223\n",
      "[20]\tvalidation_0-aucpr:0.81957\n",
      "[30]\tvalidation_0-aucpr:0.83991\n",
      "[40]\tvalidation_0-aucpr:0.84644\n",
      "[50]\tvalidation_0-aucpr:0.85436\n",
      "[60]\tvalidation_0-aucpr:0.85828\n",
      "[70]\tvalidation_0-aucpr:0.86029\n",
      "[80]\tvalidation_0-aucpr:0.86357\n",
      "[90]\tvalidation_0-aucpr:0.86529\n",
      "[100]\tvalidation_0-aucpr:0.86758\n",
      "[110]\tvalidation_0-aucpr:0.86898\n",
      "[120]\tvalidation_0-aucpr:0.86914\n",
      "[130]\tvalidation_0-aucpr:0.87013\n",
      "[140]\tvalidation_0-aucpr:0.87162\n",
      "[150]\tvalidation_0-aucpr:0.87288\n",
      "[160]\tvalidation_0-aucpr:0.87386\n",
      "[170]\tvalidation_0-aucpr:0.87415\n",
      "[180]\tvalidation_0-aucpr:0.87573\n",
      "[190]\tvalidation_0-aucpr:0.87577\n",
      "[199]\tvalidation_0-aucpr:0.87619\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "173\n",
      "precision 0.6184971098265896\n",
      "recall 0.856\n",
      "f1 0.7181208053691275\n",
      "average_precision 0.5506099965997959\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.63720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.80667\n",
      "[20]\tvalidation_0-aucpr:0.83497\n",
      "[30]\tvalidation_0-aucpr:0.84809\n",
      "[40]\tvalidation_0-aucpr:0.85819\n",
      "[50]\tvalidation_0-aucpr:0.86540\n",
      "[60]\tvalidation_0-aucpr:0.86953\n",
      "[70]\tvalidation_0-aucpr:0.87145\n",
      "[80]\tvalidation_0-aucpr:0.87341\n",
      "[90]\tvalidation_0-aucpr:0.87546\n",
      "[100]\tvalidation_0-aucpr:0.87841\n",
      "[110]\tvalidation_0-aucpr:0.87887\n",
      "[120]\tvalidation_0-aucpr:0.87972\n",
      "[130]\tvalidation_0-aucpr:0.88044\n",
      "[140]\tvalidation_0-aucpr:0.88268\n",
      "[150]\tvalidation_0-aucpr:0.88426\n",
      "[160]\tvalidation_0-aucpr:0.88506\n",
      "[170]\tvalidation_0-aucpr:0.88508\n",
      "[180]\tvalidation_0-aucpr:0.88560\n",
      "[190]\tvalidation_0-aucpr:0.88577\n",
      "[199]\tvalidation_0-aucpr:0.88654\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "161\n",
      "precision 0.6708074534161491\n",
      "recall 0.7941176470588235\n",
      "f1 0.7272727272727273\n",
      "average_precision 0.5656412130069419\n",
      "(7651, 256) (850, 256) (7651,) (850,)\n",
      "7651 7651\n",
      "BalancedBaggingClassifier\n",
      "BalancedRandomForestClassifier\n",
      "XGBClassifier\n",
      "xgboost detected\n",
      "[0]\tvalidation_0-aucpr:0.60647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/xgboost/sklearn.py:861: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-aucpr:0.78731\n",
      "[20]\tvalidation_0-aucpr:0.81640\n",
      "[30]\tvalidation_0-aucpr:0.83882\n",
      "[40]\tvalidation_0-aucpr:0.84757\n",
      "[50]\tvalidation_0-aucpr:0.85480\n",
      "[60]\tvalidation_0-aucpr:0.86040\n",
      "[70]\tvalidation_0-aucpr:0.86710\n",
      "[80]\tvalidation_0-aucpr:0.87010\n",
      "[90]\tvalidation_0-aucpr:0.87189\n",
      "[100]\tvalidation_0-aucpr:0.87473\n",
      "[110]\tvalidation_0-aucpr:0.87683\n",
      "[120]\tvalidation_0-aucpr:0.87863\n",
      "[130]\tvalidation_0-aucpr:0.88026\n",
      "[140]\tvalidation_0-aucpr:0.88101\n",
      "[150]\tvalidation_0-aucpr:0.88149\n",
      "[160]\tvalidation_0-aucpr:0.88254\n",
      "[170]\tvalidation_0-aucpr:0.88261\n",
      "[180]\tvalidation_0-aucpr:0.88329\n",
      "[190]\tvalidation_0-aucpr:0.88390\n",
      "[199]\tvalidation_0-aucpr:0.88454\n",
      "7651 7651\n",
      "7651\n",
      "not use probas\n",
      "134\n",
      "precision 0.7164179104477612\n",
      "recall 0.8347826086956521\n",
      "f1 0.7710843373493976\n",
      "average_precision 0.6204061533763408\n"
     ]
    }
   ],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "cv = em.cross_validate(X_train.values, y_train, scoring=['precision', 'recall', 'f1', 'average_precision'], cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8309721012781959\n",
      "0.6028994401430416\n"
     ]
    }
   ],
   "source": [
    "# print(em.meta_classifier)\n",
    "\n",
    "print(np.array(cv['recall']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(em, open('models/curr_models/em-f2-4.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but BalancedBaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but BalancedRandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but BalancedBaggingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve: 0.86\n",
      "0.8632605879742479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but BalancedRandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, em.predict_proba(X_test)[:,1])\n",
    "area = auc(recall, precision)\n",
    "\n",
    "print('Area Under Curve: %.2f' % area)\n",
    "\n",
    "# pickle.dump(em, open('models/curr_models/custom-ensemble-f2-4.pkl', 'wb'))\n",
    "print(average_precision_score(y_test, em.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9087488240827846\n",
      "0.8607714016933208\n",
      "0.8904045155221072\n",
      "0.867826904985889\n",
      "0.9379115710253998\n",
      "0.6895424836601307\n",
      "0.7973856209150327\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, em.predict(X_test)))\n",
    "print(accuracy_score(y_test, knn.predict(X_test)))\n",
    "print(accuracy_score(y_test, mlp.predict(X_test)))\n",
    "print(accuracy_score(y_test, randforest.predict(X_test)))\n",
    "print(accuracy_score(y_test, xgb1.predict(X_test)))\n",
    "\n",
    "print(recall_score(y_test, xgb1.predict(X_test)))\n",
    "print(recall_score(y_test, em.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "x = cross_validate(em.meta_clf_, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'], verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.0964632987976075\n",
      "score_time 0.008139228820800782\n",
      "test_recall 0.4653217332828983\n",
      "test_f1 0.5366943173652114\n",
      "test_accuracy 0.8994014719716674\n",
      "test_precision 0.6966997540133837\n",
      "test_roc_auc 0.8787708820719597\n",
      "test_neg_brier_score -0.07558212884947939\n",
      "test_average_precision 0.674270494108131\n"
     ]
    }
   ],
   "source": [
    "for k, v in x.items():\n",
    "    print(k, v.mean())\n",
    "    # modelScores[name][k]=v.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting 3 classifiers...\n",
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)Fitting classifier1: balancedbaggingclassifier (1/3)\n",
      "\n",
      "Fitting 3 classifiers...Fitting 3 classifiers...\n",
      "\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedrandomforestclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedrandomforestclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedrandomforestclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedrandomforestclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedrandomforestclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   20.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.2s finished\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "z = cross_val_score(em, X, y, cv=5, scoring='average_precision', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7747447765328916\n"
     ]
    }
   ],
   "source": [
    "print(z.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388523047977423\n",
      "0.7352941176470589\n",
      "0.7758620689655173\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, em.predict(X_test)))\n",
    "print(recall_score(y_test, em.predict(X_test)))\n",
    "print(f1_score(y_test, em.predict(X_test)))\n",
    "# pickle.dump(em, open('models/curr_models/ensemble.pkl', 'wb'))\n",
    "asdf = pickle.load(open('models/curr_models/xgb1-test.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# print(em.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967074317968015\n",
      "0.7973856209150327\n",
      "0.874551971326165\n",
      "0.9285042333019755\n",
      "0.7941176470588235\n",
      "0.7617554858934168\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, asdf.predict(X_test)))\n",
    "print(recall_score(y_test, asdf.predict(X_test)))\n",
    "print(f1_score(y_test, asdf.predict(X_test)))\n",
    "\n",
    "print(accuracy_score(y_test, temp_svm.predict(X_test)))\n",
    "print(recall_score(y_test, temp_svm.predict(X_test)))\n",
    "print(f1_score(y_test, temp_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedbaggingclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedbaggingclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   43.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# print(em.clfs_)\n",
    "x = cross_val_score(em, X, y, cv=2, scoring='recall', verbose=1, n_jobs=-1)\n",
    "# x = cross_validate(em.clfs_, X, y, cv=2, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'], verbose=1, n_jobs=-1)\n",
    "# name = 'ensemble_lengthdiv_4'\n",
    "# if (name not in modelScores):\n",
    "#     modelScores[name] = {}\n",
    "#     for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "#         modelScores[name][k]=v.mean()\n",
    "# else:\n",
    "#     print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77172503 0.71725032]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump em\n",
    "pickle.dump(em, open('models/curr_models/em.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
