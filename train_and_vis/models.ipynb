{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/Documents/coding/scires/project/utils\n",
      "/Users/benjaminli/Documents/coding/scires/project\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations, product\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, balanced_accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score, f1_score, recall_score, precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean,std\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "from os import path\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'project'):\n",
    "    %cd utils\n",
    "elif (os.path.abspath('').split('/')[-1] == 'train_and_vis'):\n",
    "    %cd ../utils\n",
    "\n",
    "import query_utils\n",
    "import model_utils\n",
    "import validation_utils\n",
    "import data_utils\n",
    "\n",
    "if (os.path.abspath('').split('/')[-1] == 'utils'):\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data creation\n",
    "Performed with CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m isZoonotic \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39misZoonotic\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m][:\u001b[39m1200\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m isZoonotic \u001b[39m=\u001b[39m isZoonotic\u001b[39m.\u001b[39mloc[:, isZoonotic\u001b[39m.\u001b[39mcolumns \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39misZoonotic\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(isZoonotic)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "isZoonotic = df.loc[df['isZoonotic']==1][:1200]\n",
    "isZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(isZoonotic)\n",
    "\n",
    "posGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "posGanModel.fit(isZoonotic)\n",
    "\n",
    "# check if current model is better than pickled model\n",
    "posGanModel.save('models/curr_models/posGanModel.pkl')\n",
    "\n",
    "notZoonotic = df.loc[df['isZoonotic']==0][:3000]\n",
    "notZoonotic = isZoonotic.loc[:, isZoonotic.columns != 'isZoonotic']\n",
    "print(notZoonotic)\n",
    "\n",
    "negGanModel = CTGANSynthesizer(batch_size=60, epochs=10, verbose=True)\n",
    "negGanModel.fit(notZoonotic)\n",
    "negGanModel.save('models/curr_models/negGanModel.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset retrieval\n",
    "Workings of the function is packaged into data_utils (for readability). Data is generated within \"process_data.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: /Users/benjaminli/Documents/coding/scires/project\n"
     ]
    }
   ],
   "source": [
    "dataset = data_utils.retrieveMerged(dir='data/')\n",
    "# datasets = data_utils.retrieveAllDatasets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep track of scores of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_f1_4': {'fit_time': 9.182259464263916,\n",
       "  'score_time': 0.38588614463806153,\n",
       "  'test_recall': 0.8072016979783971,\n",
       "  'test_f1': 0.6601338755726636,\n",
       "  'test_accuracy': 0.8749357534170772,\n",
       "  'test_precision': 0.5686347080784393,\n",
       "  'test_roc_auc': 0.9236435213170576,\n",
       "  'test_neg_brier_score': -0.09125115690858958,\n",
       "  'total': 2.299727937959529},\n",
       " 'mlp_f3_3': {'fit_time': 12.69257574081421,\n",
       "  'score_time': 0.34751105308532715,\n",
       "  'test_recall': 0.8383453116462825,\n",
       "  'test_f1': 0.6473697885556842,\n",
       "  'test_accuracy': 0.8494335011897516,\n",
       "  'test_precision': 0.5495825398084325,\n",
       "  'test_roc_auc': 0.9188979100863088,\n",
       "  'test_neg_brier_score': -0.10668787556757205,\n",
       "  'total': 2.2979251347207033},\n",
       " 'mlp_f2_4': {'fit_time': 11.08979058265686,\n",
       "  'score_time': 0.36149845123291013,\n",
       "  'test_recall': 0.7766843189173287,\n",
       "  'test_f1': 0.6699328776782045,\n",
       "  'test_accuracy': 0.8882084223341267,\n",
       "  'test_precision': 0.6028925092633572,\n",
       "  'test_roc_auc': 0.9247547799273411,\n",
       "  'test_neg_brier_score': -0.08142440889216647,\n",
       "  'total': 2.289947567630708},\n",
       " 'mlp_f1_6': {'fit_time': 51.713082265853885,\n",
       "  'score_time': 0.9758026123046875,\n",
       "  'test_recall': 0.8026457361408819,\n",
       "  'test_f1': 0.6361912305791717,\n",
       "  'test_accuracy': 0.8654382823308062,\n",
       "  'test_precision': 0.5374109465354621,\n",
       "  'test_roc_auc': 0.9224098264426661,\n",
       "  'test_neg_brier_score': -0.0945335057420684,\n",
       "  'total': 2.2667132874206515},\n",
       " 'mlp_f1_5': {'fit_time': 22.5436252117157,\n",
       "  'score_time': 0.44889016151428224,\n",
       "  'test_recall': 0.7987601395368386,\n",
       "  'test_f1': 0.6356739615485534,\n",
       "  'test_accuracy': 0.8646825078855626,\n",
       "  'test_precision': 0.5453670183852157,\n",
       "  'test_roc_auc': 0.9216410014637114,\n",
       "  'test_neg_brier_score': -0.09136863897767766,\n",
       "  'total': 2.264706463571426},\n",
       " 'mlp_f2_3': {'fit_time': 12.340601348876953,\n",
       "  'score_time': 0.29123740196228026,\n",
       "  'test_recall': 0.7689047198755936,\n",
       "  'test_f1': 0.6527537339157734,\n",
       "  'test_accuracy': 0.8850068728902662,\n",
       "  'test_precision': 0.5774773243160104,\n",
       "  'test_roc_auc': 0.9211042043255068,\n",
       "  'test_neg_brier_score': -0.08127809550056461,\n",
       "  'total': 2.2614845626163094},\n",
       " 'mlp_f3_5': {'fit_time': 14.193923425674438,\n",
       "  'score_time': 0.4031697750091553,\n",
       "  'test_recall': 0.8221136468709285,\n",
       "  'test_f1': 0.6271251773164528,\n",
       "  'test_accuracy': 0.8414355376016823,\n",
       "  'test_precision': 0.5334135592760462,\n",
       "  'test_roc_auc': 0.9152925071661814,\n",
       "  'test_neg_brier_score': -0.1088314663905234,\n",
       "  'total': 2.2556998649630393},\n",
       " 'mlp_f2_5': {'fit_time': 15.924036073684693,\n",
       "  'score_time': 0.42554874420166017,\n",
       "  'test_recall': 0.7721199512461647,\n",
       "  'test_f1': 0.6441999916940659,\n",
       "  'test_accuracy': 0.8779513253278735,\n",
       "  'test_precision': 0.576175876961647,\n",
       "  'test_roc_auc': 0.9258203558156538,\n",
       "  'test_neg_brier_score': -0.08975626613550972,\n",
       "  'total': 2.252384032620375},\n",
       " 'svm_f2_4': {'fit_time': 6.441674995422363,\n",
       "  'score_time': 3.110650157928467,\n",
       "  'test_recall': 0.7195666792754171,\n",
       "  'test_f1': 0.680627734884343,\n",
       "  'test_accuracy': 0.9109778982900781,\n",
       "  'test_precision': 0.6755043001874332,\n",
       "  'test_roc_auc': 0.9195314656792288,\n",
       "  'test_neg_brier_score': -0.06779188285595661,\n",
       "  'total': 2.2519339969830328},\n",
       " 'mlp_f2_6': {'fit_time': 32.21785717010498,\n",
       "  'score_time': 0.711247444152832,\n",
       "  'test_recall': 0.7974656411549615,\n",
       "  'test_f1': 0.6316306377024214,\n",
       "  'test_accuracy': 0.8657188644789995,\n",
       "  'test_precision': 0.5371231872472746,\n",
       "  'test_roc_auc': 0.9202469133832045,\n",
       "  'test_neg_brier_score': -0.09866557396511037,\n",
       "  'total': 2.2506776182754766},\n",
       " 'rf_f1_3': {'fit_time': 0.673237657546997,\n",
       "  'score_time': 0.06305813789367676,\n",
       "  'test_recall': 0.8033287101248267,\n",
       "  'test_f1': 0.6376446981126623,\n",
       "  'test_accuracy': 0.8496201427701843,\n",
       "  'test_precision': 0.557841501561644,\n",
       "  'test_roc_auc': 0.9113908529679753,\n",
       "  'test_neg_brier_score': -0.1036142534713076,\n",
       "  'total': 2.2487500077341567},\n",
       " 'rf_f1_4': {'fit_time': 0.3828004837036133,\n",
       "  'score_time': 0.04037809371948242,\n",
       "  'test_recall': 0.8247236582188038,\n",
       "  'test_f1': 0.6207048310771551,\n",
       "  'test_accuracy': 0.83861386752255,\n",
       "  'test_precision': 0.5229388200064958,\n",
       "  'test_roc_auc': 0.910494420772485,\n",
       "  'test_neg_brier_score': -0.10967277864423663,\n",
       "  'total': 2.2462501314242074},\n",
       " 'rf_f3_3': {'fit_time': 0.28589487075805664,\n",
       "  'score_time': 0.03607010841369629,\n",
       "  'test_recall': 0.8026772580170638,\n",
       "  'test_f1': 0.635436790839013,\n",
       "  'test_accuracy': 0.8511267777101434,\n",
       "  'test_precision': 0.5558658633147152,\n",
       "  'test_roc_auc': 0.9113416202038491,\n",
       "  'test_neg_brier_score': -0.10388738292291518,\n",
       "  'total': 2.245568286137011},\n",
       " 'mlp_f3_4': {'fit_time': 11.664755201339721,\n",
       "  'score_time': 0.34946379661560056,\n",
       "  'test_recall': 0.7987475307863657,\n",
       "  'test_f1': 0.6308952237003621,\n",
       "  'test_accuracy': 0.8528239499750981,\n",
       "  'test_precision': 0.5438019065901061,\n",
       "  'test_roc_auc': 0.9153417011857522,\n",
       "  'test_neg_brier_score': -0.10303714852755086,\n",
       "  'total': 2.241947307144929},\n",
       " 'svm_f2_3': {'fit_time': 1.0388792037963868,\n",
       "  'score_time': 1.184439754486084,\n",
       "  'test_recall': 0.7682637750598916,\n",
       "  'test_f1': 0.6470785392118301,\n",
       "  'test_accuracy': 0.8794546843008135,\n",
       "  'test_precision': 0.5694617314417644,\n",
       "  'test_roc_auc': 0.9059787336109665,\n",
       "  'test_neg_brier_score': -0.08563907097963931,\n",
       "  'total': 2.2356819769030487},\n",
       " 'rf_f3_4': {'fit_time': 0.36256895065307615,\n",
       "  'score_time': 0.03960065841674805,\n",
       "  'test_recall': 0.8104379439330897,\n",
       "  'test_f1': 0.6122819346017718,\n",
       "  'test_accuracy': 0.8375780421670079,\n",
       "  'test_precision': 0.517284226258682,\n",
       "  'test_roc_auc': 0.9098157387600138,\n",
       "  'test_neg_brier_score': -0.10799163270211942,\n",
       "  'total': 2.224543984592756},\n",
       " 'mlp_f1_3': {'fit_time': 5.641985559463501,\n",
       "  'score_time': 0.3429579257965088,\n",
       "  'test_recall': 0.7909805404951037,\n",
       "  'test_f1': 0.6129231538456255,\n",
       "  'test_accuracy': 0.8570628299485363,\n",
       "  'test_precision': 0.5071047997117664,\n",
       "  'test_roc_auc': 0.915887930020903,\n",
       "  'test_neg_brier_score': -0.10401978874103301,\n",
       "  'total': 2.215771835620599},\n",
       " 'xgb_f1_4': {'fit_time': 3.781730365753174,\n",
       "  'score_time': 0.01956338882446289,\n",
       "  'test_recall': 0.8156201403774219,\n",
       "  'test_f1': 0.6104394394548548,\n",
       "  'test_accuracy': 0.8383293010901444,\n",
       "  'test_precision': 0.5084032815414197,\n",
       "  'test_roc_auc': 0.9124100464192155,\n",
       "  'test_neg_brier_score': -0.12665033904950382,\n",
       "  'total': 2.2118192872019886},\n",
       " 'mlp_f3_6': {'fit_time': 24.688657188415526,\n",
       "  'score_time': 0.6551656723022461,\n",
       "  'test_recall': 0.8007102929433026,\n",
       "  'test_f1': 0.6163852010676341,\n",
       "  'test_accuracy': 0.84877941453157,\n",
       "  'test_precision': 0.5110844203436183,\n",
       "  'test_roc_auc': 0.9071307607457563,\n",
       "  'test_neg_brier_score': -0.11622677904897338,\n",
       "  'total': 2.2079994757077195},\n",
       " 'rf_f2_4': {'fit_time': 0.44559249877929685,\n",
       "  'score_time': 0.038927984237670896,\n",
       "  'test_recall': 0.7935485226747362,\n",
       "  'test_f1': 0.6095630801166361,\n",
       "  'test_accuracy': 0.8536746831940679,\n",
       "  'test_precision': 0.5078574652531154,\n",
       "  'test_roc_auc': 0.9124865212318658,\n",
       "  'test_neg_brier_score': -0.10795246804714738,\n",
       "  'total': 2.207645655976091},\n",
       " 'xgb_f3_3': {'fit_time': 3.7060344219207764,\n",
       "  'score_time': 0.014565849304199218,\n",
       "  'test_recall': 0.8137288278064977,\n",
       "  'test_f1': 0.6115900124135841,\n",
       "  'test_accuracy': 0.834283083393282,\n",
       "  'test_precision': 0.5106685846240002,\n",
       "  'test_roc_auc': 0.9068828343370023,\n",
       "  'test_neg_brier_score': -0.1307657871800653,\n",
       "  'total': 2.201435887377019},\n",
       " 'rf_f1_5': {'fit_time': 0.6000373840332032,\n",
       "  'score_time': 0.04732570648193359,\n",
       "  'test_recall': 0.8156495607951919,\n",
       "  'test_f1': 0.5989438606391093,\n",
       "  'test_accuracy': 0.830617232029218,\n",
       "  'test_precision': 0.49094791592883613,\n",
       "  'test_roc_auc': 0.9037483385236003,\n",
       "  'test_neg_brier_score': -0.11737497661889215,\n",
       "  'total': 2.200966783339009},\n",
       " 'xgb_f3_5': {'fit_time': 7.592995834350586,\n",
       "  'score_time': 0.029067420959472658,\n",
       "  'test_recall': 0.833158912285126,\n",
       "  'test_f1': 0.5929275765570411,\n",
       "  'test_accuracy': 0.8235584527696309,\n",
       "  'test_precision': 0.4726514172596331,\n",
       "  'test_roc_auc': 0.9048827889306967,\n",
       "  'test_neg_brier_score': -0.1328818219277872,\n",
       "  'total': 2.1980874558450765},\n",
       " 'rf_f2_3': {'fit_time': 0.30217394828796384,\n",
       "  'score_time': 0.038896369934082034,\n",
       "  'test_recall': 0.7734417685873997,\n",
       "  'test_f1': 0.6213791860135606,\n",
       "  'test_accuracy': 0.8658125394278124,\n",
       "  'test_precision': 0.5325331554110591,\n",
       "  'test_roc_auc': 0.9063302693213835,\n",
       "  'test_neg_brier_score': -0.1044856117846273,\n",
       "  'total': 2.1966656121377164},\n",
       " 'xgb_f1_5': {'fit_time': 9.465924882888794,\n",
       "  'score_time': 0.034711790084838864,\n",
       "  'test_recall': 0.812377590047493,\n",
       "  'test_f1': 0.5957276641889511,\n",
       "  'test_accuracy': 0.8303351889768136,\n",
       "  'test_precision': 0.48868606627991606,\n",
       "  'test_roc_auc': 0.9061718723272761,\n",
       "  'test_neg_brier_score': -0.1282699816288476,\n",
       "  'total': 2.1860071449348726},\n",
       " 'svm_f3_4': {'fit_time': 4.718837118148803,\n",
       "  'score_time': 2.7102776527404786,\n",
       "  'test_recall': 0.7358361703021898,\n",
       "  'test_f1': 0.6401249173404641,\n",
       "  'test_accuracy': 0.877006253112722,\n",
       "  'test_precision': 0.5891997818295154,\n",
       "  'test_roc_auc': 0.8913670041328989,\n",
       "  'test_neg_brier_score': -0.08740740861294846,\n",
       "  'total': 2.179920683162604},\n",
       " 'rf_f3_5': {'fit_time': 0.5398379325866699,\n",
       "  'score_time': 0.048029422760009766,\n",
       "  'test_recall': 0.8020089942420039,\n",
       "  'test_f1': 0.5919979110851005,\n",
       "  'test_accuracy': 0.8280752587017874,\n",
       "  'test_precision': 0.4869791095986976,\n",
       "  'test_roc_auc': 0.9015821871132556,\n",
       "  'test_neg_brier_score': -0.11647759820707211,\n",
       "  'total': 2.179111494233288},\n",
       " 'xgb_f2_4': {'fit_time': 4.854494190216064,\n",
       "  'score_time': 0.01835479736328125,\n",
       "  'test_recall': 0.7844765267095364,\n",
       "  'test_f1': 0.6006880549724263,\n",
       "  'test_accuracy': 0.8500970173205689,\n",
       "  'test_precision': 0.4947263503937707,\n",
       "  'test_roc_auc': 0.9064532988976353,\n",
       "  'test_neg_brier_score': -0.11687840443501238,\n",
       "  'total': 2.1747394761445857},\n",
       " 'xgb_f2_5': {'fit_time': 8.804008769989014,\n",
       "  'score_time': 0.03093862533569336,\n",
       "  'test_recall': 0.7916025721850964,\n",
       "  'test_f1': 0.5993536834354649,\n",
       "  'test_accuracy': 0.8464271816722926,\n",
       "  'test_precision': 0.49043677764000504,\n",
       "  'test_roc_auc': 0.9004855606444698,\n",
       "  'test_neg_brier_score': -0.1197660981286734,\n",
       "  'total': 2.1716757181363575},\n",
       " 'xgb_f1_3': {'fit_time': 3.2481399536132813,\n",
       "  'score_time': 0.015207624435424805,\n",
       "  'test_recall': 0.8098222166183332,\n",
       "  'test_f1': 0.5993580116185406,\n",
       "  'test_accuracy': 0.8287332411045322,\n",
       "  'test_precision': 0.49247938747250075,\n",
       "  'test_roc_auc': 0.8983555937573016,\n",
       "  'test_neg_brier_score': -0.13648852807028594,\n",
       "  'total': 2.1710472939238894},\n",
       " 'xgb_f3_4': {'fit_time': 3.8369383811950684,\n",
       "  'score_time': 0.018232250213623048,\n",
       "  'test_recall': 0.8091371411759761,\n",
       "  'test_f1': 0.5954835696761532,\n",
       "  'test_accuracy': 0.8257223617951415,\n",
       "  'test_precision': 0.4950999268794776,\n",
       "  'test_roc_auc': 0.9034605873383118,\n",
       "  'test_neg_brier_score': -0.1374745292269814,\n",
       "  'total': 2.17060676896346},\n",
       " 'xgb_f2_3': {'fit_time': 3.682933235168457,\n",
       "  'score_time': 0.01545543670654297,\n",
       "  'test_recall': 0.7974509309460764,\n",
       "  'test_f1': 0.5985745962711088,\n",
       "  'test_accuracy': 0.8438875546455649,\n",
       "  'test_precision': 0.48785963453151826,\n",
       "  'test_roc_auc': 0.8971440087235623,\n",
       "  'test_neg_brier_score': -0.12304992852125171,\n",
       "  'total': 2.1701196074194957},\n",
       " 'rf_f3_6': {'fit_time': 1.489657735824585,\n",
       "  'score_time': 0.07536168098449707,\n",
       "  'test_recall': 0.8033118984575296,\n",
       "  'test_f1': 0.5930306595226671,\n",
       "  'test_accuracy': 0.8356999391289912,\n",
       "  'test_precision': 0.47858867704489666,\n",
       "  'test_roc_auc': 0.8958752523398182,\n",
       "  'test_neg_brier_score': -0.12601429025510485,\n",
       "  'total': 2.16620352006491},\n",
       " 'rf_f2_5': {'fit_time': 0.6895964622497559,\n",
       "  'score_time': 0.04699277877807617,\n",
       "  'test_recall': 0.7864371874080611,\n",
       "  'test_f1': 0.5914793560904524,\n",
       "  'test_accuracy': 0.8407826904985889,\n",
       "  'test_precision': 0.4841031271214792,\n",
       "  'test_roc_auc': 0.9049874547443355,\n",
       "  'test_neg_brier_score': -0.11900806547949752,\n",
       "  'total': 2.163895932763352},\n",
       " 'xgb_f2_6': {'fit_time': 20.36616539955139,\n",
       "  'score_time': 0.10566897392272949,\n",
       "  'test_recall': 0.7786344723237926,\n",
       "  'test_f1': 0.5987444155949405,\n",
       "  'test_accuracy': 0.8515098002324167,\n",
       "  'test_precision': 0.4932435177271969,\n",
       "  'test_roc_auc': 0.8988902599449696,\n",
       "  'test_neg_brier_score': -0.11388828005949392,\n",
       "  'total': 2.1623808678042087},\n",
       " 'xgb_f3_6': {'fit_time': 17.45177388191223,\n",
       "  'score_time': 0.11109700202941894,\n",
       "  'test_recall': 0.7961648383978481,\n",
       "  'test_f1': 0.5917210656796733,\n",
       "  'test_accuracy': 0.8309933484588568,\n",
       "  'test_precision': 0.48462525924606464,\n",
       "  'test_roc_auc': 0.8970751434572094,\n",
       "  'test_neg_brier_score': -0.12559913663123567,\n",
       "  'total': 2.1593619109034954},\n",
       " 'rf_f1_6': {'fit_time': 1.7328995704650878,\n",
       "  'score_time': 0.07697968482971192,\n",
       "  'test_recall': 0.7864497961585339,\n",
       "  'test_f1': 0.5832211992936639,\n",
       "  'test_accuracy': 0.8308071938464945,\n",
       "  'test_precision': 0.47306123355413465,\n",
       "  'test_roc_auc': 0.8918330855185321,\n",
       "  'test_neg_brier_score': -0.12688660539427812,\n",
       "  'total': 2.134617475576452},\n",
       " 'xgb_f1_6': {'fit_time': 17.82449336051941,\n",
       "  'score_time': 0.11508121490478515,\n",
       "  'test_recall': 0.785810952801244,\n",
       "  'test_f1': 0.5774907223882504,\n",
       "  'test_accuracy': 0.8246897238669693,\n",
       "  'test_precision': 0.46652488051625063,\n",
       "  'test_roc_auc': 0.8916577906938631,\n",
       "  'test_neg_brier_score': -0.13109756176952062,\n",
       "  'total': 2.123861904113837},\n",
       " 'rf_f2_6': {'fit_time': 1.8176741123199462,\n",
       "  'score_time': 0.07468795776367188,\n",
       "  'test_recall': 0.7734480729626361,\n",
       "  'test_f1': 0.5789396932651698,\n",
       "  'test_accuracy': 0.8373941895855237,\n",
       "  'test_precision': 0.47011602095673055,\n",
       "  'test_roc_auc': 0.8879940037769811,\n",
       "  'test_neg_brier_score': -0.13097873010237399,\n",
       "  'total': 2.1094030399024133},\n",
       " 'knn_f2_4': {'fit_time': 0.02101101875305176,\n",
       "  'score_time': 0.09459757804870605,\n",
       "  'test_recall': 0.843573740175682,\n",
       "  'test_f1': 0.6001263330822514,\n",
       "  'test_accuracy': 0.8280734436389796,\n",
       "  'test_precision': 0.47083773179337507,\n",
       "  'test_roc_auc': 0.8345001337091948,\n",
       "  'test_neg_brier_score': -0.17192655636102044,\n",
       "  'total': 2.1062736506061075},\n",
       " 'knn_f3_4': {'fit_time': 0.02068023681640625,\n",
       "  'score_time': 0.06336283683776855,\n",
       "  'test_recall': 0.8363930567814062,\n",
       "  'test_f1': 0.6029510913590906,\n",
       "  'test_accuracy': 0.8234594654418682,\n",
       "  'test_precision': 0.48454881636484626,\n",
       "  'test_roc_auc': 0.8288184326284576,\n",
       "  'test_neg_brier_score': -0.17654053455813182,\n",
       "  'total': 2.091622046210823},\n",
       " 'knn_f3_3': {'fit_time': 0.006073999404907227,\n",
       "  'score_time': 0.03609743118286133,\n",
       "  'test_recall': 0.8169524650107174,\n",
       "  'test_f1': 0.6050472649993741,\n",
       "  'test_accuracy': 0.8296698577831887,\n",
       "  'test_precision': 0.4922435812769397,\n",
       "  'test_roc_auc': 0.8243815709753642,\n",
       "  'test_neg_brier_score': -0.17033014221681148,\n",
       "  'total': 2.076051158768644},\n",
       " 'svm_f3_3': {'fit_time': 1.820357084274292,\n",
       "  'score_time': 1.633793306350708,\n",
       "  'test_recall': 0.6223111839616695,\n",
       "  'test_f1': 0.6622677588722691,\n",
       "  'test_accuracy': 0.9047616623319129,\n",
       "  'test_precision': 0.7670728169863373,\n",
       "  'test_roc_auc': 0.8690880648935909,\n",
       "  'test_neg_brier_score': -0.07928686951563617,\n",
       "  'total': 2.0743801382118936},\n",
       " 'knn_f1_3': {'fit_time': 0.006434345245361328,\n",
       "  'score_time': 0.23126916885375975,\n",
       "  'test_recall': 0.8065397385785735,\n",
       "  'test_f1': 0.601296422615953,\n",
       "  'test_accuracy': 0.8332461512921254,\n",
       "  'test_precision': 0.48886637902036434,\n",
       "  'test_roc_auc': 0.8221471395149335,\n",
       "  'test_neg_brier_score': -0.1667538487078745,\n",
       "  'total': 2.0632294520015853},\n",
       " 'knn_f1_5': {'fit_time': 0.10765976905822754,\n",
       "  'score_time': 0.6587644577026367,\n",
       "  'test_recall': 0.8286260664901441,\n",
       "  'test_f1': 0.5803285578110288,\n",
       "  'test_accuracy': 0.8070848541862652,\n",
       "  'test_precision': 0.4582952432916074,\n",
       "  'test_roc_auc': 0.8160191422159031,\n",
       "  'test_neg_brier_score': -0.1929151458137347,\n",
       "  'total': 2.0320586207033413},\n",
       " 'knn_f3_5': {'fit_time': 0.10336565971374512,\n",
       "  'score_time': 0.142830753326416,\n",
       "  'test_recall': 0.8337956541840036,\n",
       "  'test_f1': 0.5741466219933697,\n",
       "  'test_accuracy': 0.803982380609817,\n",
       "  'test_precision': 0.4512758228311407,\n",
       "  'test_roc_auc': 0.8163474693594758,\n",
       "  'test_neg_brier_score': -0.19601761939018317,\n",
       "  'total': 2.028272126146666},\n",
       " 'knn_f1_4': {'fit_time': 0.02127671241760254,\n",
       "  'score_time': 0.34290475845336915,\n",
       "  'test_recall': 0.8065292312865127,\n",
       "  'test_f1': 0.5827334292475597,\n",
       "  'test_accuracy': 0.820355265342261,\n",
       "  'test_precision': 0.4651860242243905,\n",
       "  'test_roc_auc': 0.8146019849332949,\n",
       "  'test_neg_brier_score': -0.17964473465773895,\n",
       "  'total': 2.0242199108096286},\n",
       " 'knn_f3_6': {'fit_time': 0.5713346481323243,\n",
       "  'score_time': 0.5241081714630127,\n",
       "  'test_recall': 0.8902912621359225,\n",
       "  'test_f1': 0.5476721418887871,\n",
       "  'test_accuracy': 0.758053500083006,\n",
       "  'test_precision': 0.40522346011513644,\n",
       "  'test_roc_auc': 0.8129497037151818,\n",
       "  'test_neg_brier_score': -0.2419464999169941,\n",
       "  'total': 2.0089666078228974},\n",
       " 'knn_f2_3': {'fit_time': 0.006704187393188477,\n",
       "  'score_time': 0.07589864730834961,\n",
       "  'test_recall': 0.8065502458706343,\n",
       "  'test_f1': 0.5710774429523003,\n",
       "  'test_accuracy': 0.8175344806596204,\n",
       "  'test_precision': 0.4473588072765174,\n",
       "  'test_roc_auc': 0.8129614190277772,\n",
       "  'test_neg_brier_score': -0.1824655193403796,\n",
       "  'total': 2.008123588510332},\n",
       " 'knn_f1_6': {'fit_time': 0.5757604598999023,\n",
       "  'score_time': 1.9945283889770509,\n",
       "  'test_recall': 0.8682175429748245,\n",
       "  'test_f1': 0.5484528305880176,\n",
       "  'test_accuracy': 0.7672767196059986,\n",
       "  'test_precision': 0.4102172217413065,\n",
       "  'test_roc_auc': 0.809177566203978,\n",
       "  'test_neg_brier_score': -0.23272328039400145,\n",
       "  'total': 1.9931246593728185},\n",
       " 'svm_f3_5': {'fit_time': 25.571607255935668,\n",
       "  'score_time': 10.544783449172973,\n",
       "  'test_recall': 0.7461669398562603,\n",
       "  'test_f1': 0.5291742991048717,\n",
       "  'test_accuracy': 0.8215867190526257,\n",
       "  'test_precision': 0.4163185110362675,\n",
       "  'test_roc_auc': 0.8431971153418008,\n",
       "  'test_neg_brier_score': -0.13201217769586973,\n",
       "  'total': 1.986526176607063},\n",
       " 'knn_f2_5': {'fit_time': 0.10547595024108887,\n",
       "  'score_time': 0.15437617301940917,\n",
       "  'test_recall': 0.793590551842979,\n",
       "  'test_f1': 0.5599588005008878,\n",
       "  'test_accuracy': 0.8161227159537381,\n",
       "  'test_precision': 0.4349396318273655,\n",
       "  'test_roc_auc': 0.8067567508802128,\n",
       "  'test_neg_brier_score': -0.18387728404626197,\n",
       "  'total': 1.9764288191778174},\n",
       " 'svm_f3_6': {'fit_time': 109.11372156143189,\n",
       "  'score_time': 50.53300194740295,\n",
       "  'test_recall': 0.8898226369100156,\n",
       "  'test_f1': 0.3489018698900065,\n",
       "  'test_accuracy': 0.49279548447789273,\n",
       "  'test_precision': 0.21956569655117636,\n",
       "  'test_roc_auc': 0.7556959434635748,\n",
       "  'test_neg_brier_score': -0.2238242948240226,\n",
       "  'total': 1.7705961554395744},\n",
       " 'knn_f2_6': {'fit_time': 0.5608635902404785,\n",
       "  'score_time': 0.49248366355895995,\n",
       "  'test_recall': 0.7313474551338629,\n",
       "  'test_f1': 0.4674971347574801,\n",
       "  'test_accuracy': 0.7533597033921753,\n",
       "  'test_precision': 0.34594140675944357,\n",
       "  'test_roc_auc': 0.7442097759984119,\n",
       "  'test_neg_brier_score': -0.24664029660782472,\n",
       "  'total': 1.6964140692819303},\n",
       " 'svm_f2_5': {'fit_time': 31.866920471191406,\n",
       "  'score_time': 12.23724298477173,\n",
       "  'test_recall': 0.3319232547387887,\n",
       "  'test_f1': 0.44129358607854174,\n",
       "  'test_accuracy': 0.8936664047368712,\n",
       "  'test_precision': 0.8403621359124871,\n",
       "  'test_roc_auc': 0.875871270787408,\n",
       "  'test_neg_brier_score': -0.0972674594534371,\n",
       "  'total': 1.5518206521513014},\n",
       " 'svm_f2_6': {'fit_time': 101.62899775505066,\n",
       "  'score_time': 47.86398730278015,\n",
       "  'test_recall': 0.1095553313999916,\n",
       "  'test_f1': 0.18371642419827017,\n",
       "  'test_accuracy': 0.8666605279176581,\n",
       "  'test_precision': 0.8303641312939307,\n",
       "  'test_roc_auc': 0.8119340753412974,\n",
       "  'test_neg_brier_score': -0.12238631828837598,\n",
       "  'total': 0.9828195126511832},\n",
       " 'svm_f1_3': {'fit_time': 1.9005918025970459,\n",
       "  'score_time': 1.832925271987915,\n",
       "  'test_recall': 0.0012965998402891608,\n",
       "  'test_f1': 0.002584820962522184,\n",
       "  'test_accuracy': 0.8550861380111782,\n",
       "  'test_precision': 0.4,\n",
       "  'test_roc_auc': 0.510706523502875,\n",
       "  'test_neg_brier_score': -0.14527397592299335,\n",
       "  'total': 0.3693139683826931},\n",
       " 'svm_f1_4': {'fit_time': 6.530042266845703,\n",
       "  'score_time': 3.4427698135375975,\n",
       "  'test_recall': 0.0012965998402891608,\n",
       "  'test_f1': 0.002584820962522184,\n",
       "  'test_accuracy': 0.8550861380111782,\n",
       "  'test_precision': 0.4,\n",
       "  'test_roc_auc': 0.5082480131965573,\n",
       "  'test_neg_brier_score': -0.1457355230836727,\n",
       "  'total': 0.366393910915696},\n",
       " 'svm_f1_5': {'fit_time': 31.155922889709473,\n",
       "  'score_time': 12.689632606506347,\n",
       "  'test_recall': 0.0012965998402891608,\n",
       "  'test_f1': 0.002584820962522184,\n",
       "  'test_accuracy': 0.8550861380111782,\n",
       "  'test_precision': 0.4,\n",
       "  'test_roc_auc': 0.5064696334864541,\n",
       "  'test_neg_brier_score': -0.14603576232779042,\n",
       "  'total': 0.3643152919614751},\n",
       " 'svm_f1_6': {'fit_time': 109.18032379150391,\n",
       "  'score_time': 53.78303756713867,\n",
       "  'test_recall': 0.0012965998402891608,\n",
       "  'test_f1': 0.002584820962522184,\n",
       "  'test_accuracy': 0.8550861380111782,\n",
       "  'test_precision': 0.4,\n",
       "  'test_roc_auc': 0.50618518657562,\n",
       "  'test_neg_brier_score': -0.146554394177546,\n",
       "  'total': 0.36351221320088534}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelScores = {}\n",
    "import json\n",
    "modelScores = pickle.load(open('score_df.pkl', 'rb'))\n",
    "modelScores = modelScores.T.to_dict()\n",
    "modelScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate & validate performance of KNN (baseline) on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['f1-3', 'f2-3', 'f3-3', 'f1-4', 'f2-4', 'f3-4', 'f1-5', 'f2-5', 'f3-5', 'f1-6', 'f2-6', 'f3-6'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.006434345245361328\n",
      "score_time 0.23126916885375975\n",
      "test_recall 0.8065397385785735\n",
      "test_f1 0.601296422615953\n",
      "test_accuracy 0.8332461512921254\n",
      "test_precision 0.48886637902036434\n",
      "test_roc_auc 0.8221471395149335\n",
      "test_neg_brier_score -0.1667538487078745\n",
      "fit_time 0.006704187393188477\n",
      "score_time 0.07589864730834961\n",
      "test_recall 0.8065502458706343\n",
      "test_f1 0.5710774429523003\n",
      "test_accuracy 0.8175344806596204\n",
      "test_precision 0.4473588072765174\n",
      "test_roc_auc 0.8129614190277772\n",
      "test_neg_brier_score -0.1824655193403796\n",
      "fit_time 0.006073999404907227\n",
      "score_time 0.03609743118286133\n",
      "test_recall 0.8169524650107174\n",
      "test_f1 0.6050472649993741\n",
      "test_accuracy 0.8296698577831887\n",
      "test_precision 0.4922435812769397\n",
      "test_roc_auc 0.8243815709753642\n",
      "test_neg_brier_score -0.17033014221681148\n",
      "fit_time 0.02127671241760254\n",
      "score_time 0.34290475845336915\n",
      "test_recall 0.8065292312865127\n",
      "test_f1 0.5827334292475597\n",
      "test_accuracy 0.820355265342261\n",
      "test_precision 0.4651860242243905\n",
      "test_roc_auc 0.8146019849332949\n",
      "test_neg_brier_score -0.17964473465773895\n",
      "fit_time 0.02101101875305176\n",
      "score_time 0.09459757804870605\n",
      "test_recall 0.843573740175682\n",
      "test_f1 0.6001263330822514\n",
      "test_accuracy 0.8280734436389796\n",
      "test_precision 0.47083773179337507\n",
      "test_roc_auc 0.8345001337091948\n",
      "test_neg_brier_score -0.17192655636102044\n",
      "fit_time 0.02068023681640625\n",
      "score_time 0.06336283683776855\n",
      "test_recall 0.8363930567814062\n",
      "test_f1 0.6029510913590906\n",
      "test_accuracy 0.8234594654418682\n",
      "test_precision 0.48454881636484626\n",
      "test_roc_auc 0.8288184326284576\n",
      "test_neg_brier_score -0.17654053455813182\n",
      "fit_time 0.10765976905822754\n",
      "score_time 0.6587644577026367\n",
      "test_recall 0.8286260664901441\n",
      "test_f1 0.5803285578110288\n",
      "test_accuracy 0.8070848541862652\n",
      "test_precision 0.4582952432916074\n",
      "test_roc_auc 0.8160191422159031\n",
      "test_neg_brier_score -0.1929151458137347\n",
      "fit_time 0.10547595024108887\n",
      "score_time 0.15437617301940917\n",
      "test_recall 0.793590551842979\n",
      "test_f1 0.5599588005008878\n",
      "test_accuracy 0.8161227159537381\n",
      "test_precision 0.4349396318273655\n",
      "test_roc_auc 0.8067567508802128\n",
      "test_neg_brier_score -0.18387728404626197\n",
      "fit_time 0.10336565971374512\n",
      "score_time 0.142830753326416\n",
      "test_recall 0.8337956541840036\n",
      "test_f1 0.5741466219933697\n",
      "test_accuracy 0.803982380609817\n",
      "test_precision 0.4512758228311407\n",
      "test_roc_auc 0.8163474693594758\n",
      "test_neg_brier_score -0.19601761939018317\n",
      "fit_time 0.5757604598999023\n",
      "score_time 1.9945283889770509\n",
      "test_recall 0.8682175429748245\n",
      "test_f1 0.5484528305880176\n",
      "test_accuracy 0.7672767196059986\n",
      "test_precision 0.4102172217413065\n",
      "test_roc_auc 0.809177566203978\n",
      "test_neg_brier_score -0.23272328039400145\n",
      "fit_time 0.5608635902404785\n",
      "score_time 0.49248366355895995\n",
      "test_recall 0.7313474551338629\n",
      "test_f1 0.4674971347574801\n",
      "test_accuracy 0.7533597033921753\n",
      "test_precision 0.34594140675944357\n",
      "test_roc_auc 0.7442097759984119\n",
      "test_neg_brier_score -0.24664029660782472\n",
      "fit_time 0.5713346481323243\n",
      "score_time 0.5241081714630127\n",
      "test_recall 0.8902912621359225\n",
      "test_f1 0.5476721418887871\n",
      "test_accuracy 0.758053500083006\n",
      "test_precision 0.40522346011513644\n",
      "test_roc_auc 0.8129497037151818\n",
      "test_neg_brier_score -0.2419464999169941\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        knntest = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors = 1, n_jobs = -1), n_estimators = 1, n_jobs = -1)\n",
    "\n",
    "        # knntest = KNeighborsClassifier(n_neighbors = 1, n_jobs = -1)\n",
    "        knntest.fit(X_train, y_train)\n",
    "        # print(knntest.score(X_test, y_test))\n",
    "        x = cross_validate(knntest, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        \n",
    "        name = f'knn_{feature}_{kmer}'\n",
    "        \n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn_f1_4': {'fit_time': 0.556103515625, 'score_time': 2.1676071643829347, 'test_recall': 0.8967847686294288, 'test_f1': 0.5506206040204477, 'test_accuracy': 0.7598422223451939, 'test_precision': 0.4068609142945686, 'test_roc_auc': 0.8166917789212086, 'test_neg_brier_score': -0.24015777765480606}, 'knn_f2_4': {'fit_time': 0.5469307899475098, 'score_time': 0.5283036708831788, 'test_recall': 0.7209095112007733, 'test_f1': 0.49014203521664257, 'test_accuracy': 0.7846974710862709, 'test_precision': 0.37431163097253817, 'test_roc_auc': 0.7581982888970294, 'test_neg_brier_score': -0.2153025289137292}, 'knn_f3_4': {'fit_time': 0.5275906562805176, 'score_time': 0.5401241779327393, 'test_recall': 0.8695246501071743, 'test_f1': 0.5344595291629525, 'test_accuracy': 0.7597513806651541, 'test_precision': 0.39288153362735134, 'test_roc_auc': 0.8053181863634385, 'test_neg_brier_score': -0.24024861933484587}}\n"
     ]
    }
   ],
   "source": [
    "print(modelScores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate & validate performance of random forest (baseline) on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 0.673237657546997\n",
      "score_time 0.06305813789367676\n",
      "test_recall 0.8033287101248267\n",
      "test_f1 0.6376446981126623\n",
      "test_accuracy 0.8496201427701843\n",
      "test_precision 0.557841501561644\n",
      "test_roc_auc 0.9113908529679753\n",
      "test_neg_brier_score -0.1036142534713076\n",
      "fit_time 0.30217394828796384\n",
      "score_time 0.038896369934082034\n",
      "test_recall 0.7734417685873997\n",
      "test_f1 0.6213791860135606\n",
      "test_accuracy 0.8658125394278124\n",
      "test_precision 0.5325331554110591\n",
      "test_roc_auc 0.9063302693213835\n",
      "test_neg_brier_score -0.1044856117846273\n",
      "fit_time 0.28589487075805664\n",
      "score_time 0.03607010841369629\n",
      "test_recall 0.8026772580170638\n",
      "test_f1 0.635436790839013\n",
      "test_accuracy 0.8511267777101434\n",
      "test_precision 0.5558658633147152\n",
      "test_roc_auc 0.9113416202038491\n",
      "test_neg_brier_score -0.10388738292291518\n",
      "fit_time 0.3828004837036133\n",
      "score_time 0.04037809371948242\n",
      "test_recall 0.8247236582188038\n",
      "test_f1 0.6207048310771551\n",
      "test_accuracy 0.83861386752255\n",
      "test_precision 0.5229388200064958\n",
      "test_roc_auc 0.910494420772485\n",
      "test_neg_brier_score -0.10967277864423663\n",
      "fit_time 0.44559249877929685\n",
      "score_time 0.038927984237670896\n",
      "test_recall 0.7935485226747362\n",
      "test_f1 0.6095630801166361\n",
      "test_accuracy 0.8536746831940679\n",
      "test_precision 0.5078574652531154\n",
      "test_roc_auc 0.9124865212318658\n",
      "test_neg_brier_score -0.10795246804714738\n",
      "fit_time 0.36256895065307615\n",
      "score_time 0.03960065841674805\n",
      "test_recall 0.8104379439330897\n",
      "test_f1 0.6122819346017718\n",
      "test_accuracy 0.8375780421670079\n",
      "test_precision 0.517284226258682\n",
      "test_roc_auc 0.9098157387600138\n",
      "test_neg_brier_score -0.10799163270211942\n",
      "fit_time 0.6000373840332032\n",
      "score_time 0.04732570648193359\n",
      "test_recall 0.8156495607951919\n",
      "test_f1 0.5989438606391093\n",
      "test_accuracy 0.830617232029218\n",
      "test_precision 0.49094791592883613\n",
      "test_roc_auc 0.9037483385236003\n",
      "test_neg_brier_score -0.11737497661889215\n",
      "fit_time 0.6895964622497559\n",
      "score_time 0.04699277877807617\n",
      "test_recall 0.7864371874080611\n",
      "test_f1 0.5914793560904524\n",
      "test_accuracy 0.8407826904985889\n",
      "test_precision 0.4841031271214792\n",
      "test_roc_auc 0.9049874547443355\n",
      "test_neg_brier_score -0.11900806547949752\n",
      "fit_time 0.5398379325866699\n",
      "score_time 0.048029422760009766\n",
      "test_recall 0.8020089942420039\n",
      "test_f1 0.5919979110851005\n",
      "test_accuracy 0.8280752587017874\n",
      "test_precision 0.4869791095986976\n",
      "test_roc_auc 0.9015821871132556\n",
      "test_neg_brier_score -0.11647759820707211\n",
      "fit_time 1.7328995704650878\n",
      "score_time 0.07697968482971192\n",
      "test_recall 0.7864497961585339\n",
      "test_f1 0.5832211992936639\n",
      "test_accuracy 0.8308071938464945\n",
      "test_precision 0.47306123355413465\n",
      "test_roc_auc 0.8918330855185321\n",
      "test_neg_brier_score -0.12688660539427812\n",
      "fit_time 1.8176741123199462\n",
      "score_time 0.07468795776367188\n",
      "test_recall 0.7734480729626361\n",
      "test_f1 0.5789396932651698\n",
      "test_accuracy 0.8373941895855237\n",
      "test_precision 0.47011602095673055\n",
      "test_roc_auc 0.8879940037769811\n",
      "test_neg_brier_score -0.13097873010237399\n",
      "fit_time 1.489657735824585\n",
      "score_time 0.07536168098449707\n",
      "test_recall 0.8033118984575296\n",
      "test_f1 0.5930306595226671\n",
      "test_accuracy 0.8356999391289912\n",
      "test_precision 0.47858867704489666\n",
      "test_roc_auc 0.8958752523398182\n",
      "test_neg_brier_score -0.12601429025510485\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        randforest = BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(randforest, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        name = f'rf_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 3.2481399536132813\n",
      "score_time 0.015207624435424805\n",
      "test_recall 0.8098222166183332\n",
      "test_f1 0.5993580116185406\n",
      "test_accuracy 0.8287332411045322\n",
      "test_precision 0.49247938747250075\n",
      "test_roc_auc 0.8983555937573016\n",
      "test_neg_brier_score -0.13648852807028594\n",
      "fit_time 3.682933235168457\n",
      "score_time 0.01545543670654297\n",
      "test_recall 0.7974509309460764\n",
      "test_f1 0.5985745962711088\n",
      "test_accuracy 0.8438875546455649\n",
      "test_precision 0.48785963453151826\n",
      "test_roc_auc 0.8971440087235623\n",
      "test_neg_brier_score -0.12304992852125171\n",
      "fit_time 3.7060344219207764\n",
      "score_time 0.014565849304199218\n",
      "test_recall 0.8137288278064977\n",
      "test_f1 0.6115900124135841\n",
      "test_accuracy 0.834283083393282\n",
      "test_precision 0.5106685846240002\n",
      "test_roc_auc 0.9068828343370023\n",
      "test_neg_brier_score -0.1307657871800653\n",
      "fit_time 3.781730365753174\n",
      "score_time 0.01956338882446289\n",
      "test_recall 0.8156201403774219\n",
      "test_f1 0.6104394394548548\n",
      "test_accuracy 0.8383293010901444\n",
      "test_precision 0.5084032815414197\n",
      "test_roc_auc 0.9124100464192155\n",
      "test_neg_brier_score -0.12665033904950382\n",
      "fit_time 4.854494190216064\n",
      "score_time 0.01835479736328125\n",
      "test_recall 0.7844765267095364\n",
      "test_f1 0.6006880549724263\n",
      "test_accuracy 0.8500970173205689\n",
      "test_precision 0.4947263503937707\n",
      "test_roc_auc 0.9064532988976353\n",
      "test_neg_brier_score -0.11687840443501238\n",
      "fit_time 3.8369383811950684\n",
      "score_time 0.018232250213623048\n",
      "test_recall 0.8091371411759761\n",
      "test_f1 0.5954835696761532\n",
      "test_accuracy 0.8257223617951415\n",
      "test_precision 0.4950999268794776\n",
      "test_roc_auc 0.9034605873383118\n",
      "test_neg_brier_score -0.1374745292269814\n",
      "fit_time 9.465924882888794\n",
      "score_time 0.034711790084838864\n",
      "test_recall 0.812377590047493\n",
      "test_f1 0.5957276641889511\n",
      "test_accuracy 0.8303351889768136\n",
      "test_precision 0.48868606627991606\n",
      "test_roc_auc 0.9061718723272761\n",
      "test_neg_brier_score -0.1282699816288476\n",
      "fit_time 8.804008769989014\n",
      "score_time 0.03093862533569336\n",
      "test_recall 0.7916025721850964\n",
      "test_f1 0.5993536834354649\n",
      "test_accuracy 0.8464271816722926\n",
      "test_precision 0.49043677764000504\n",
      "test_roc_auc 0.9004855606444698\n",
      "test_neg_brier_score -0.1197660981286734\n",
      "fit_time 7.592995834350586\n",
      "score_time 0.029067420959472658\n",
      "test_recall 0.833158912285126\n",
      "test_f1 0.5929275765570411\n",
      "test_accuracy 0.8235584527696309\n",
      "test_precision 0.4726514172596331\n",
      "test_roc_auc 0.9048827889306967\n",
      "test_neg_brier_score -0.1328818219277872\n",
      "fit_time 17.82449336051941\n",
      "score_time 0.11508121490478515\n",
      "test_recall 0.785810952801244\n",
      "test_f1 0.5774907223882504\n",
      "test_accuracy 0.8246897238669693\n",
      "test_precision 0.46652488051625063\n",
      "test_roc_auc 0.8916577906938631\n",
      "test_neg_brier_score -0.13109756176952062\n",
      "fit_time 20.36616539955139\n",
      "score_time 0.10566897392272949\n",
      "test_recall 0.7786344723237926\n",
      "test_f1 0.5987444155949405\n",
      "test_accuracy 0.8515098002324167\n",
      "test_precision 0.4932435177271969\n",
      "test_roc_auc 0.8988902599449696\n",
      "test_neg_brier_score -0.11388828005949392\n",
      "fit_time 17.45177388191223\n",
      "score_time 0.11109700202941894\n",
      "test_recall 0.7961648383978481\n",
      "test_f1 0.5917210656796733\n",
      "test_accuracy 0.8309933484588568\n",
      "test_precision 0.48462525924606464\n",
      "test_roc_auc 0.8970751434572094\n",
      "test_neg_brier_score -0.12559913663123567\n"
     ]
    }
   ],
   "source": [
    "kmer = 4\n",
    "\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        xgb1 = BalancedBaggingClassifier(base_estimator=XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    "        ), n_estimators=1, n_jobs=-1)\n",
    "        xgb1.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(xgb1, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        name = f'xgb_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rf_f1_3', 'rf_f2_3', 'rf_f3_3', 'rf_f1_4', 'rf_f2_4', 'rf_f3_4', 'rf_f1_5', 'rf_f2_5', 'rf_f3_5', 'rf_f1_6', 'rf_f2_6', 'rf_f3_6', 'xgb_f1_3', 'xgb_f2_3', 'xgb_f3_3', 'xgb_f1_4', 'xgb_f2_4', 'xgb_f3_4', 'xgb_f1_5', 'xgb_f2_5', 'xgb_f3_5', 'xgb_f1_6', 'xgb_f2_6', 'xgb_f3_6'])\n"
     ]
    }
   ],
   "source": [
    "print(modelScores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 5.641985559463501\n",
      "score_time 0.3429579257965088\n",
      "test_recall 0.7909805404951037\n",
      "test_f1 0.6129231538456255\n",
      "test_accuracy 0.8570628299485363\n",
      "test_precision 0.5071047997117664\n",
      "test_roc_auc 0.915887930020903\n",
      "test_neg_brier_score -0.10401978874103301\n",
      "fit_time 12.340601348876953\n",
      "score_time 0.29123740196228026\n",
      "test_recall 0.7689047198755936\n",
      "test_f1 0.6527537339157734\n",
      "test_accuracy 0.8850068728902662\n",
      "test_precision 0.5774773243160104\n",
      "test_roc_auc 0.9211042043255068\n",
      "test_neg_brier_score -0.08127809550056461\n",
      "fit_time 12.69257574081421\n",
      "score_time 0.34751105308532715\n",
      "test_recall 0.8383453116462825\n",
      "test_f1 0.6473697885556842\n",
      "test_accuracy 0.8494335011897516\n",
      "test_precision 0.5495825398084325\n",
      "test_roc_auc 0.9188979100863088\n",
      "test_neg_brier_score -0.10668787556757205\n",
      "fit_time 9.182259464263916\n",
      "score_time 0.38588614463806153\n",
      "test_recall 0.8072016979783971\n",
      "test_f1 0.6601338755726636\n",
      "test_accuracy 0.8749357534170772\n",
      "test_precision 0.5686347080784393\n",
      "test_roc_auc 0.9236435213170576\n",
      "test_neg_brier_score -0.09125115690858958\n",
      "fit_time 11.08979058265686\n",
      "score_time 0.36149845123291013\n",
      "test_recall 0.7766843189173287\n",
      "test_f1 0.6699328776782045\n",
      "test_accuracy 0.8882084223341267\n",
      "test_precision 0.6028925092633572\n",
      "test_roc_auc 0.9247547799273411\n",
      "test_neg_brier_score -0.08142440889216647\n",
      "fit_time 11.664755201339721\n",
      "score_time 0.34946379661560056\n",
      "test_recall 0.7987475307863657\n",
      "test_f1 0.6308952237003621\n",
      "test_accuracy 0.8528239499750981\n",
      "test_precision 0.5438019065901061\n",
      "test_roc_auc 0.9153417011857522\n",
      "test_neg_brier_score -0.10303714852755086\n",
      "fit_time 22.5436252117157\n",
      "score_time 0.44889016151428224\n",
      "test_recall 0.7987601395368386\n",
      "test_f1 0.6356739615485534\n",
      "test_accuracy 0.8646825078855626\n",
      "test_precision 0.5453670183852157\n",
      "test_roc_auc 0.9216410014637114\n",
      "test_neg_brier_score -0.09136863897767766\n",
      "fit_time 15.924036073684693\n",
      "score_time 0.42554874420166017\n",
      "test_recall 0.7721199512461647\n",
      "test_f1 0.6441999916940659\n",
      "test_accuracy 0.8779513253278735\n",
      "test_precision 0.576175876961647\n",
      "test_roc_auc 0.9258203558156538\n",
      "test_neg_brier_score -0.08975626613550972\n",
      "fit_time 14.193923425674438\n",
      "score_time 0.4031697750091553\n",
      "test_recall 0.8221136468709285\n",
      "test_f1 0.6271251773164528\n",
      "test_accuracy 0.8414355376016823\n",
      "test_precision 0.5334135592760462\n",
      "test_roc_auc 0.9152925071661814\n",
      "test_neg_brier_score -0.1088314663905234\n",
      "fit_time 51.713082265853885\n",
      "score_time 0.9758026123046875\n",
      "test_recall 0.8026457361408819\n",
      "test_f1 0.6361912305791717\n",
      "test_accuracy 0.8654382823308062\n",
      "test_precision 0.5374109465354621\n",
      "test_roc_auc 0.9224098264426661\n",
      "test_neg_brier_score -0.0945335057420684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 32.21785717010498\n",
      "score_time 0.711247444152832\n",
      "test_recall 0.7974656411549615\n",
      "test_f1 0.6316306377024214\n",
      "test_accuracy 0.8657188644789995\n",
      "test_precision 0.5371231872472746\n",
      "test_roc_auc 0.9202469133832045\n",
      "test_neg_brier_score -0.09866557396511037\n",
      "fit_time 24.688657188415526\n",
      "score_time 0.6551656723022461\n",
      "test_recall 0.8007102929433026\n",
      "test_f1 0.6163852010676341\n",
      "test_accuracy 0.84877941453157\n",
      "test_precision 0.5110844203436183\n",
      "test_roc_auc 0.9071307607457563\n",
      "test_neg_brier_score -0.11622677904897338\n"
     ]
    }
   ],
   "source": [
    "# ds = datasets['merged']['lengthdivdataset-4']\n",
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        mlp = BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "        mlp.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(mlp, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        name = f'mlp_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_time 71.89677076339721\n",
    "score_time 0.10850300788879394\n",
    "test_recall 0.8584950773558369\n",
    "test_f1 0.6911281484361098\n",
    "test_accuracy 0.8864734363076601\n",
    "test_precision 0.5796959595204415\n",
    "test_roc_auc 0.9540192015137766\n",
    "test_neg_brier_score -0.07964541647825815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(modelScores.keys()))\n",
    "# print(modelScores.keys())\n",
    "# print(modelScores['mlp_balanced_normalized_4'])\n",
    "# print(modelScores['mlp_balanced_normalized_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 1.9005918025970459\n",
      "score_time 1.832925271987915\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.510706523502875\n",
      "test_neg_brier_score -0.14527397592299335\n",
      "fit_time 1.0388792037963868\n",
      "score_time 1.184439754486084\n",
      "test_recall 0.7682637750598916\n",
      "test_f1 0.6470785392118301\n",
      "test_accuracy 0.8794546843008135\n",
      "test_precision 0.5694617314417644\n",
      "test_roc_auc 0.9059787336109665\n",
      "test_neg_brier_score -0.08563907097963931\n",
      "fit_time 1.820357084274292\n",
      "score_time 1.633793306350708\n",
      "test_recall 0.6223111839616695\n",
      "test_f1 0.6622677588722691\n",
      "test_accuracy 0.9047616623319129\n",
      "test_precision 0.7670728169863373\n",
      "test_roc_auc 0.8690880648935909\n",
      "test_neg_brier_score -0.07928686951563617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 6.530042266845703\n",
      "score_time 3.4427698135375975\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.5082480131965573\n",
      "test_neg_brier_score -0.1457355230836727\n",
      "fit_time 6.441674995422363\n",
      "score_time 3.110650157928467\n",
      "test_recall 0.7195666792754171\n",
      "test_f1 0.680627734884343\n",
      "test_accuracy 0.9109778982900781\n",
      "test_precision 0.6755043001874332\n",
      "test_roc_auc 0.9195314656792288\n",
      "test_neg_brier_score -0.06779188285595661\n",
      "fit_time 4.718837118148803\n",
      "score_time 2.7102776527404786\n",
      "test_recall 0.7358361703021898\n",
      "test_f1 0.6401249173404641\n",
      "test_accuracy 0.877006253112722\n",
      "test_precision 0.5891997818295154\n",
      "test_roc_auc 0.8913670041328989\n",
      "test_neg_brier_score -0.08740740861294846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 31.155922889709473\n",
      "score_time 12.689632606506347\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.5064696334864541\n",
      "test_neg_brier_score -0.14603576232779042\n",
      "fit_time 31.866920471191406\n",
      "score_time 12.23724298477173\n",
      "test_recall 0.3319232547387887\n",
      "test_f1 0.44129358607854174\n",
      "test_accuracy 0.8936664047368712\n",
      "test_precision 0.8403621359124871\n",
      "test_roc_auc 0.875871270787408\n",
      "test_neg_brier_score -0.0972674594534371\n",
      "fit_time 25.571607255935668\n",
      "score_time 10.544783449172973\n",
      "test_recall 0.7461669398562603\n",
      "test_f1 0.5291742991048717\n",
      "test_accuracy 0.8215867190526257\n",
      "test_precision 0.4163185110362675\n",
      "test_roc_auc 0.8431971153418008\n",
      "test_neg_brier_score -0.13201217769586973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 109.18032379150391\n",
      "score_time 53.78303756713867\n",
      "test_recall 0.0012965998402891608\n",
      "test_f1 0.002584820962522184\n",
      "test_accuracy 0.8550861380111782\n",
      "test_precision 0.4\n",
      "test_roc_auc 0.50618518657562\n",
      "test_neg_brier_score -0.146554394177546\n",
      "fit_time 101.62899775505066\n",
      "score_time 47.86398730278015\n",
      "test_recall 0.1095553313999916\n",
      "test_f1 0.18371642419827017\n",
      "test_accuracy 0.8666605279176581\n",
      "test_precision 0.8303641312939307\n",
      "test_roc_auc 0.8119340753412974\n",
      "test_neg_brier_score -0.12238631828837598\n",
      "fit_time 109.11372156143189\n",
      "score_time 50.53300194740295\n",
      "test_recall 0.8898226369100156\n",
      "test_f1 0.3489018698900065\n",
      "test_accuracy 0.49279548447789273\n",
      "test_precision 0.21956569655117636\n",
      "test_roc_auc 0.7556959434635748\n",
      "test_neg_brier_score -0.2238242948240226\n"
     ]
    }
   ],
   "source": [
    "features = ['f1', 'f2', 'f3']\n",
    "for kmer in range(3, 7):\n",
    "    for feature in features:\n",
    "        ds = dataset[f'{feature}-{kmer}']\n",
    "\n",
    "        X, y = ds['X'], ds['y']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "        temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42), n_estimators=10, n_jobs=-1)\n",
    "        temp_svm.fit(X_train, y_train)\n",
    "\n",
    "        # randforest.fit(X_train, y_train)\n",
    "        x = cross_validate(temp_svm, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "        name = f'svm_{feature}_{kmer}'\n",
    "        if (name not in modelScores):\n",
    "            modelScores[name] = {}\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "        else:\n",
    "            for k, v in x.items():\n",
    "                print(k, v.mean())\n",
    "                modelScores[name][k]=v.mean()\n",
    "            print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.60215\n",
      "[10]\tvalidation_0-aucpr:0.79226\n",
      "[20]\tvalidation_0-aucpr:0.82126\n",
      "[30]\tvalidation_0-aucpr:0.83316\n",
      "[40]\tvalidation_0-aucpr:0.84168\n",
      "[50]\tvalidation_0-aucpr:0.84784\n",
      "[60]\tvalidation_0-aucpr:0.85343\n",
      "[70]\tvalidation_0-aucpr:0.85694\n",
      "[80]\tvalidation_0-aucpr:0.85838\n",
      "[90]\tvalidation_0-aucpr:0.86029\n",
      "[100]\tvalidation_0-aucpr:0.86255\n",
      "[110]\tvalidation_0-aucpr:0.86355\n",
      "[120]\tvalidation_0-aucpr:0.86534\n",
      "[130]\tvalidation_0-aucpr:0.86587\n",
      "[140]\tvalidation_0-aucpr:0.86640\n",
      "[150]\tvalidation_0-aucpr:0.86598\n",
      "[160]\tvalidation_0-aucpr:0.86754\n",
      "[170]\tvalidation_0-aucpr:0.86833\n",
      "[180]\tvalidation_0-aucpr:0.86805\n",
      "[190]\tvalidation_0-aucpr:0.86813\n",
      "[199]\tvalidation_0-aucpr:0.86812\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.09, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.09, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.09, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=9, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=-1,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=42, ...)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.09,\n",
    "        n_estimators=200,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    "        )\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "xgb1.fit(X_train, y_train, eval_metric='aucpr', eval_set=[(X_validation, y_validation)], early_stopping_rounds=15, verbose=10)\n",
    "\n",
    "# xgb1.fit(X_train, y_train)\n",
    "\n",
    "# x = cross_validate(xgb1, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'])\n",
    "\n",
    "# for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "        # modelScores[name][k]=v.mean()\n",
    "\n",
    "# X_test = X_test[xgb1.get_booster().feature_names]\n",
    "\n",
    "# print(accuracy_score(xgb1.predict(X_test), y_test))\n",
    "# print(recall_score(xgb1.predict(X_test), y_test))\n",
    "# print(f1_score(xgb1.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ds \u001b[39m=\u001b[39m dataset[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf2-4\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m ds[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m], ds[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "ds = dataset[f'f2-4']\n",
    "\n",
    "X, y = ds['X'], ds['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# randforest = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=\"sqrt\"), n_estimators=1, n_jobs=-1)\n",
    "knn = BalancedBaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors = 1, n_jobs = -1), n_estimators = 1, n_jobs = -1)\n",
    "\n",
    "# randforest.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, knn.predict_proba(X_test)[:,1])\n",
    "area = auc(recall, precision)\n",
    "\n",
    "\n",
    "print('Area Under Curve: %.2f' % area)\n",
    "\n",
    "x = cross_validate(knn, X, y, cv=10, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "\n",
    "for k, v in x.items():\n",
    "    print(k, v.mean())\n",
    "        # modelScores[name][k]=v.mean()\n",
    "\n",
    "x = cross_validate(xgb1, X, y, cv=10, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score', 'average_precision'])\n",
    "\n",
    "for k, v in x.items():\n",
    "    print(k, v.mean())\n",
    "# print(accuracy_score(knn.predict(X_test), y_test))\n",
    "# print(recall_score(knn.predict(X_test), y_test))\n",
    "\n",
    "\n",
    "# print(accuracy_score(xgb1.predict(X_test), y_test))\n",
    "# print(recall_score(xgb1.predict(X_test), y_test))\n",
    "# print(f1_score(xgb1.predict(X_test), y_test))\n",
    "# pickle.dump(xgb1, open('models/curr_models/xgBoost.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order models by performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(modelScores).T\n",
    "\n",
    "# select model with best overall scores, precision doesn't really matter, excluding accuracy just because\n",
    "score_df['total'] = score_df.apply(lambda x: x[['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score']].sum(), axis=1)\n",
    "score_df['name'] = score_df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "score_df['feature'] = score_df.apply(lambda x: x.name.split(\"_\")[1], axis=1)\n",
    "score_df['kmer'] = score_df.apply(lambda x: x.name.split(\"_\")[2], axis=1)\n",
    "# sort based on total column\n",
    "score_df = score_df.sort_values(by='test_f1', ascending=False)\n",
    "# print(len(score_df))\n",
    "\n",
    "# for each k-mer value, create a plot with the AUC score of each model and each feature and put it into one graph\n",
    "\n",
    "\n",
    "# for kmer in modelKmers:\n",
    "#     for name in modelNames:\n",
    "#         for feature in modelFeatures:\n",
    "#             df = score_df[score_df.index.str.contains(f'{name}_{feature}_{kmer}')]\n",
    "#             df.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "#             plt.title(f'{name} {feature} {kmer}')\n",
    "#     plt.show()\n",
    "\n",
    "# retrieve all model names\n",
    "modelNames = score_df['name'].unique()\n",
    "\n",
    "for kmer in range(3, 7):\n",
    "    # for feature in features:\n",
    "\n",
    "    for modelName in modelNames:\n",
    "        # retrieve models that match the current name and k-mer\n",
    "        df = score_df[score_df['name'] == modelName]\n",
    "        df = df[df['kmer'] == str(kmer)]\n",
    "        # rename all indices to the name of the model\n",
    "        print(df)\n",
    "        df.index = df.apply(lambda x: x.name.split(\"_\")[0], axis=1)\n",
    "        \n",
    "        # plot the auc for \n",
    "        df.plot.bar(y=['test_roc_auc', 'test_accuracy'], figsize=(20, 10), rot=0, )\n",
    "        plt.title(f'kmer = {kmer}, feature = {feature}')\n",
    "    plt.show()\n",
    "\n",
    "# xg_boost = score_df[score_df.index.str.contains(f'{name}_{feature}_{kmer}')]\n",
    "# # mlp = score_df[score_df.index.str.contains('mlp')]\n",
    "# # svm = score_df[score_df.index.str.contains('svm')]\n",
    "# xg_boost.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "\n",
    "# xg_boost.plot.bar(y=['test_f1', 'test_recall', 'test_roc_auc', 'test_neg_brier_score', 'test_accuracy'], figsize=(20, 10))\n",
    "# pickle.dump(score_df, open('score_df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'test_f1'\n",
    "\n",
    "# Create a figure and subplots for each feature\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "# Loop through each k-mer length\n",
    "for length in range(3, 7):\n",
    "    # Loop through each feature\n",
    "    for i, feature in enumerate(['knn_f1', 'knn_f2', 'knn_f3']):\n",
    "        # Extract the data for the current length and feature\n",
    "        data = [modelScores[model][metric] for model in modelScores]\n",
    "        # print(data)\n",
    "        # Plot the data on the corresponding subplot\n",
    "        axs[i].plot(length, 'o-')\n",
    "        axs[i].set_xlabel('k-mer length')\n",
    "        axs[i].set_ylabel(metric)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump models into pickle - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Searched version of the Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "\"\"\"\n",
    "{'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 0, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3}\n",
    "\"\"\"\n",
    "\n",
    "parameters={\n",
    "   'n_estimators': 120, 'max_features': 2, 'max_depth': 6, 'random_state': 42, 'min_sample_split': 50, 'subsample': 0.8, 'learning_rate': 0.3\n",
    "}\n",
    "\n",
    "param_test1 = {'n_estimators':range(100,140,10), 'learning_rate':[0.1,0.15,0.2], 'subsample':[0.8,0.85,0.9], 'max_depth':range(6,9,1), 'min_samples_split':range(10,40,10), 'max_features':range(2, 5)}\n",
    "\n",
    "gradBoost = GridSearchCV(estimator = GradientBoostingClassifier(\n",
    "    n_estimators=parameters['n_estimators'], max_features=parameters['max_features'], random_state=parameters['random_state']), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=-1, cv=5, verbose=10)\n",
    "\n",
    "# parameters['learning_rate']=learning_rate\n",
    "gradBoost.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "def hidden_layers_generator(hidden_layers, max_neurons):\n",
    "  hd_sizes = []\n",
    "  comb = combinations_with_replacement(np.arange(100,max_neurons+10,20), hidden_layers)\n",
    "  hd_sizes.append(list(comb))\n",
    "  return hd_sizes\n",
    "\n",
    "\n",
    "# ds = datasets['merged'][f'normalized-{kmer}']\n",
    "\n",
    "# X_train, y_train, X_test, y_test = ds['X_train'], ds['y_train'], ds['X_test'], ds['y_test']\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = np.concatenate([ds['y_train'], ds['y_test']], axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(l)\n",
    "hlg = hidden_layers_generator(hidden_layers=5, max_neurons=200)\n",
    "print(hlg)\n",
    "\n",
    "mlp_gs = MLPClassifier(max_iter=350, random_state=42, solver='adam')\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': hlg[0],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.05, 0.1, 0.2],\n",
    "}\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5, verbose=10, scoring='recall')\n",
    "clf.fit(X_train, y_train) # X is train samples and y is the corresponding labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the ensemble model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_neg_brier_score</th>\n",
       "      <th>total</th>\n",
       "      <th>name</th>\n",
       "      <th>feature</th>\n",
       "      <th>kmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp_f2_5</th>\n",
       "      <td>15.924036</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>0.772120</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.877951</td>\n",
       "      <td>0.576176</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>-0.089756</td>\n",
       "      <td>2.252384</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_4</th>\n",
       "      <td>11.089791</td>\n",
       "      <td>0.361498</td>\n",
       "      <td>0.776684</td>\n",
       "      <td>0.669933</td>\n",
       "      <td>0.888208</td>\n",
       "      <td>0.602893</td>\n",
       "      <td>0.924755</td>\n",
       "      <td>-0.081424</td>\n",
       "      <td>2.289948</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_4</th>\n",
       "      <td>9.182259</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>0.807202</td>\n",
       "      <td>0.660134</td>\n",
       "      <td>0.874936</td>\n",
       "      <td>0.568635</td>\n",
       "      <td>0.923644</td>\n",
       "      <td>-0.091251</td>\n",
       "      <td>2.299728</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_6</th>\n",
       "      <td>51.713082</td>\n",
       "      <td>0.975803</td>\n",
       "      <td>0.802646</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.865438</td>\n",
       "      <td>0.537411</td>\n",
       "      <td>0.922410</td>\n",
       "      <td>-0.094534</td>\n",
       "      <td>2.266713</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_5</th>\n",
       "      <td>22.543625</td>\n",
       "      <td>0.448890</td>\n",
       "      <td>0.798760</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>0.864683</td>\n",
       "      <td>0.545367</td>\n",
       "      <td>0.921641</td>\n",
       "      <td>-0.091369</td>\n",
       "      <td>2.264706</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_3</th>\n",
       "      <td>12.340601</td>\n",
       "      <td>0.291237</td>\n",
       "      <td>0.768905</td>\n",
       "      <td>0.652754</td>\n",
       "      <td>0.885007</td>\n",
       "      <td>0.577477</td>\n",
       "      <td>0.921104</td>\n",
       "      <td>-0.081278</td>\n",
       "      <td>2.261485</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f2_6</th>\n",
       "      <td>32.217857</td>\n",
       "      <td>0.711247</td>\n",
       "      <td>0.797466</td>\n",
       "      <td>0.631631</td>\n",
       "      <td>0.865719</td>\n",
       "      <td>0.537123</td>\n",
       "      <td>0.920247</td>\n",
       "      <td>-0.098666</td>\n",
       "      <td>2.250678</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_4</th>\n",
       "      <td>6.441675</td>\n",
       "      <td>3.110650</td>\n",
       "      <td>0.719567</td>\n",
       "      <td>0.680628</td>\n",
       "      <td>0.910978</td>\n",
       "      <td>0.675504</td>\n",
       "      <td>0.919531</td>\n",
       "      <td>-0.067792</td>\n",
       "      <td>2.251934</td>\n",
       "      <td>svm</td>\n",
       "      <td>f2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_3</th>\n",
       "      <td>12.692576</td>\n",
       "      <td>0.347511</td>\n",
       "      <td>0.838345</td>\n",
       "      <td>0.647370</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>0.549583</td>\n",
       "      <td>0.918898</td>\n",
       "      <td>-0.106688</td>\n",
       "      <td>2.297925</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f1_3</th>\n",
       "      <td>5.641986</td>\n",
       "      <td>0.342958</td>\n",
       "      <td>0.790981</td>\n",
       "      <td>0.612923</td>\n",
       "      <td>0.857063</td>\n",
       "      <td>0.507105</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>-0.104020</td>\n",
       "      <td>2.215772</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_4</th>\n",
       "      <td>11.664755</td>\n",
       "      <td>0.349464</td>\n",
       "      <td>0.798748</td>\n",
       "      <td>0.630895</td>\n",
       "      <td>0.852824</td>\n",
       "      <td>0.543802</td>\n",
       "      <td>0.915342</td>\n",
       "      <td>-0.103037</td>\n",
       "      <td>2.241947</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_5</th>\n",
       "      <td>14.193923</td>\n",
       "      <td>0.403170</td>\n",
       "      <td>0.822114</td>\n",
       "      <td>0.627125</td>\n",
       "      <td>0.841436</td>\n",
       "      <td>0.533414</td>\n",
       "      <td>0.915293</td>\n",
       "      <td>-0.108831</td>\n",
       "      <td>2.255700</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_4</th>\n",
       "      <td>0.445592</td>\n",
       "      <td>0.038928</td>\n",
       "      <td>0.793549</td>\n",
       "      <td>0.609563</td>\n",
       "      <td>0.853675</td>\n",
       "      <td>0.507857</td>\n",
       "      <td>0.912487</td>\n",
       "      <td>-0.107952</td>\n",
       "      <td>2.207646</td>\n",
       "      <td>rf</td>\n",
       "      <td>f2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_4</th>\n",
       "      <td>3.781730</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.610439</td>\n",
       "      <td>0.838329</td>\n",
       "      <td>0.508403</td>\n",
       "      <td>0.912410</td>\n",
       "      <td>-0.126650</td>\n",
       "      <td>2.211819</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_3</th>\n",
       "      <td>0.673238</td>\n",
       "      <td>0.063058</td>\n",
       "      <td>0.803329</td>\n",
       "      <td>0.637645</td>\n",
       "      <td>0.849620</td>\n",
       "      <td>0.557842</td>\n",
       "      <td>0.911391</td>\n",
       "      <td>-0.103614</td>\n",
       "      <td>2.248750</td>\n",
       "      <td>rf</td>\n",
       "      <td>f1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_3</th>\n",
       "      <td>0.285895</td>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.802677</td>\n",
       "      <td>0.635437</td>\n",
       "      <td>0.851127</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.911342</td>\n",
       "      <td>-0.103887</td>\n",
       "      <td>2.245568</td>\n",
       "      <td>rf</td>\n",
       "      <td>f3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_4</th>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.040378</td>\n",
       "      <td>0.824724</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.838614</td>\n",
       "      <td>0.522939</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>-0.109673</td>\n",
       "      <td>2.246250</td>\n",
       "      <td>rf</td>\n",
       "      <td>f1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_4</th>\n",
       "      <td>0.362569</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>0.810438</td>\n",
       "      <td>0.612282</td>\n",
       "      <td>0.837578</td>\n",
       "      <td>0.517284</td>\n",
       "      <td>0.909816</td>\n",
       "      <td>-0.107992</td>\n",
       "      <td>2.224544</td>\n",
       "      <td>rf</td>\n",
       "      <td>f3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_f3_6</th>\n",
       "      <td>24.688657</td>\n",
       "      <td>0.655166</td>\n",
       "      <td>0.800710</td>\n",
       "      <td>0.616385</td>\n",
       "      <td>0.848779</td>\n",
       "      <td>0.511084</td>\n",
       "      <td>0.907131</td>\n",
       "      <td>-0.116227</td>\n",
       "      <td>2.207999</td>\n",
       "      <td>mlp</td>\n",
       "      <td>f3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_3</th>\n",
       "      <td>3.706034</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.813729</td>\n",
       "      <td>0.611590</td>\n",
       "      <td>0.834283</td>\n",
       "      <td>0.510669</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>-0.130766</td>\n",
       "      <td>2.201436</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_4</th>\n",
       "      <td>4.854494</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.784477</td>\n",
       "      <td>0.600688</td>\n",
       "      <td>0.850097</td>\n",
       "      <td>0.494726</td>\n",
       "      <td>0.906453</td>\n",
       "      <td>-0.116878</td>\n",
       "      <td>2.174739</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_3</th>\n",
       "      <td>0.302174</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.773442</td>\n",
       "      <td>0.621379</td>\n",
       "      <td>0.865813</td>\n",
       "      <td>0.532533</td>\n",
       "      <td>0.906330</td>\n",
       "      <td>-0.104486</td>\n",
       "      <td>2.196666</td>\n",
       "      <td>rf</td>\n",
       "      <td>f2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_5</th>\n",
       "      <td>9.465925</td>\n",
       "      <td>0.034712</td>\n",
       "      <td>0.812378</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>0.830335</td>\n",
       "      <td>0.488686</td>\n",
       "      <td>0.906172</td>\n",
       "      <td>-0.128270</td>\n",
       "      <td>2.186007</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_3</th>\n",
       "      <td>1.038879</td>\n",
       "      <td>1.184440</td>\n",
       "      <td>0.768264</td>\n",
       "      <td>0.647079</td>\n",
       "      <td>0.879455</td>\n",
       "      <td>0.569462</td>\n",
       "      <td>0.905979</td>\n",
       "      <td>-0.085639</td>\n",
       "      <td>2.235682</td>\n",
       "      <td>svm</td>\n",
       "      <td>f2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_5</th>\n",
       "      <td>0.689596</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.591479</td>\n",
       "      <td>0.840783</td>\n",
       "      <td>0.484103</td>\n",
       "      <td>0.904987</td>\n",
       "      <td>-0.119008</td>\n",
       "      <td>2.163896</td>\n",
       "      <td>rf</td>\n",
       "      <td>f2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_5</th>\n",
       "      <td>7.592996</td>\n",
       "      <td>0.029067</td>\n",
       "      <td>0.833159</td>\n",
       "      <td>0.592928</td>\n",
       "      <td>0.823558</td>\n",
       "      <td>0.472651</td>\n",
       "      <td>0.904883</td>\n",
       "      <td>-0.132882</td>\n",
       "      <td>2.198087</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_5</th>\n",
       "      <td>0.600037</td>\n",
       "      <td>0.047326</td>\n",
       "      <td>0.815650</td>\n",
       "      <td>0.598944</td>\n",
       "      <td>0.830617</td>\n",
       "      <td>0.490948</td>\n",
       "      <td>0.903748</td>\n",
       "      <td>-0.117375</td>\n",
       "      <td>2.200967</td>\n",
       "      <td>rf</td>\n",
       "      <td>f1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_4</th>\n",
       "      <td>3.836938</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.809137</td>\n",
       "      <td>0.595484</td>\n",
       "      <td>0.825722</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.903461</td>\n",
       "      <td>-0.137475</td>\n",
       "      <td>2.170607</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_5</th>\n",
       "      <td>0.539838</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.591998</td>\n",
       "      <td>0.828075</td>\n",
       "      <td>0.486979</td>\n",
       "      <td>0.901582</td>\n",
       "      <td>-0.116478</td>\n",
       "      <td>2.179111</td>\n",
       "      <td>rf</td>\n",
       "      <td>f3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_5</th>\n",
       "      <td>8.804009</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>0.791603</td>\n",
       "      <td>0.599354</td>\n",
       "      <td>0.846427</td>\n",
       "      <td>0.490437</td>\n",
       "      <td>0.900486</td>\n",
       "      <td>-0.119766</td>\n",
       "      <td>2.171676</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_6</th>\n",
       "      <td>20.366165</td>\n",
       "      <td>0.105669</td>\n",
       "      <td>0.778634</td>\n",
       "      <td>0.598744</td>\n",
       "      <td>0.851510</td>\n",
       "      <td>0.493244</td>\n",
       "      <td>0.898890</td>\n",
       "      <td>-0.113888</td>\n",
       "      <td>2.162381</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_3</th>\n",
       "      <td>3.248140</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>0.809822</td>\n",
       "      <td>0.599358</td>\n",
       "      <td>0.828733</td>\n",
       "      <td>0.492479</td>\n",
       "      <td>0.898356</td>\n",
       "      <td>-0.136489</td>\n",
       "      <td>2.171047</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f2_3</th>\n",
       "      <td>3.682933</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.598575</td>\n",
       "      <td>0.843888</td>\n",
       "      <td>0.487860</td>\n",
       "      <td>0.897144</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>2.170120</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f3_6</th>\n",
       "      <td>17.451774</td>\n",
       "      <td>0.111097</td>\n",
       "      <td>0.796165</td>\n",
       "      <td>0.591721</td>\n",
       "      <td>0.830993</td>\n",
       "      <td>0.484625</td>\n",
       "      <td>0.897075</td>\n",
       "      <td>-0.125599</td>\n",
       "      <td>2.159362</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f3_6</th>\n",
       "      <td>1.489658</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.803312</td>\n",
       "      <td>0.593031</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.478589</td>\n",
       "      <td>0.895875</td>\n",
       "      <td>-0.126014</td>\n",
       "      <td>2.166204</td>\n",
       "      <td>rf</td>\n",
       "      <td>f3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f1_6</th>\n",
       "      <td>1.732900</td>\n",
       "      <td>0.076980</td>\n",
       "      <td>0.786450</td>\n",
       "      <td>0.583221</td>\n",
       "      <td>0.830807</td>\n",
       "      <td>0.473061</td>\n",
       "      <td>0.891833</td>\n",
       "      <td>-0.126887</td>\n",
       "      <td>2.134617</td>\n",
       "      <td>rf</td>\n",
       "      <td>f1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_f1_6</th>\n",
       "      <td>17.824493</td>\n",
       "      <td>0.115081</td>\n",
       "      <td>0.785811</td>\n",
       "      <td>0.577491</td>\n",
       "      <td>0.824690</td>\n",
       "      <td>0.466525</td>\n",
       "      <td>0.891658</td>\n",
       "      <td>-0.131098</td>\n",
       "      <td>2.123862</td>\n",
       "      <td>xgb</td>\n",
       "      <td>f1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_4</th>\n",
       "      <td>4.718837</td>\n",
       "      <td>2.710278</td>\n",
       "      <td>0.735836</td>\n",
       "      <td>0.640125</td>\n",
       "      <td>0.877006</td>\n",
       "      <td>0.589200</td>\n",
       "      <td>0.891367</td>\n",
       "      <td>-0.087407</td>\n",
       "      <td>2.179921</td>\n",
       "      <td>svm</td>\n",
       "      <td>f3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_f2_6</th>\n",
       "      <td>1.817674</td>\n",
       "      <td>0.074688</td>\n",
       "      <td>0.773448</td>\n",
       "      <td>0.578940</td>\n",
       "      <td>0.837394</td>\n",
       "      <td>0.470116</td>\n",
       "      <td>0.887994</td>\n",
       "      <td>-0.130979</td>\n",
       "      <td>2.109403</td>\n",
       "      <td>rf</td>\n",
       "      <td>f2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_5</th>\n",
       "      <td>31.866920</td>\n",
       "      <td>12.237243</td>\n",
       "      <td>0.331923</td>\n",
       "      <td>0.441294</td>\n",
       "      <td>0.893666</td>\n",
       "      <td>0.840362</td>\n",
       "      <td>0.875871</td>\n",
       "      <td>-0.097267</td>\n",
       "      <td>1.551821</td>\n",
       "      <td>svm</td>\n",
       "      <td>f2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_3</th>\n",
       "      <td>1.820357</td>\n",
       "      <td>1.633793</td>\n",
       "      <td>0.622311</td>\n",
       "      <td>0.662268</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.767073</td>\n",
       "      <td>0.869088</td>\n",
       "      <td>-0.079287</td>\n",
       "      <td>2.074380</td>\n",
       "      <td>svm</td>\n",
       "      <td>f3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_5</th>\n",
       "      <td>25.571607</td>\n",
       "      <td>10.544783</td>\n",
       "      <td>0.746167</td>\n",
       "      <td>0.529174</td>\n",
       "      <td>0.821587</td>\n",
       "      <td>0.416319</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>-0.132012</td>\n",
       "      <td>1.986526</td>\n",
       "      <td>svm</td>\n",
       "      <td>f3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_4</th>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.094598</td>\n",
       "      <td>0.843574</td>\n",
       "      <td>0.600126</td>\n",
       "      <td>0.828073</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.834500</td>\n",
       "      <td>-0.171927</td>\n",
       "      <td>2.106274</td>\n",
       "      <td>knn</td>\n",
       "      <td>f2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_4</th>\n",
       "      <td>0.020680</td>\n",
       "      <td>0.063363</td>\n",
       "      <td>0.836393</td>\n",
       "      <td>0.602951</td>\n",
       "      <td>0.823459</td>\n",
       "      <td>0.484549</td>\n",
       "      <td>0.828818</td>\n",
       "      <td>-0.176541</td>\n",
       "      <td>2.091622</td>\n",
       "      <td>knn</td>\n",
       "      <td>f3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_3</th>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>0.816952</td>\n",
       "      <td>0.605047</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.492244</td>\n",
       "      <td>0.824382</td>\n",
       "      <td>-0.170330</td>\n",
       "      <td>2.076051</td>\n",
       "      <td>knn</td>\n",
       "      <td>f3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_3</th>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.231269</td>\n",
       "      <td>0.806540</td>\n",
       "      <td>0.601296</td>\n",
       "      <td>0.833246</td>\n",
       "      <td>0.488866</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>-0.166754</td>\n",
       "      <td>2.063229</td>\n",
       "      <td>knn</td>\n",
       "      <td>f1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_5</th>\n",
       "      <td>0.103366</td>\n",
       "      <td>0.142831</td>\n",
       "      <td>0.833796</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>0.803982</td>\n",
       "      <td>0.451276</td>\n",
       "      <td>0.816347</td>\n",
       "      <td>-0.196018</td>\n",
       "      <td>2.028272</td>\n",
       "      <td>knn</td>\n",
       "      <td>f3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_5</th>\n",
       "      <td>0.107660</td>\n",
       "      <td>0.658764</td>\n",
       "      <td>0.828626</td>\n",
       "      <td>0.580329</td>\n",
       "      <td>0.807085</td>\n",
       "      <td>0.458295</td>\n",
       "      <td>0.816019</td>\n",
       "      <td>-0.192915</td>\n",
       "      <td>2.032059</td>\n",
       "      <td>knn</td>\n",
       "      <td>f1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_4</th>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.342905</td>\n",
       "      <td>0.806529</td>\n",
       "      <td>0.582733</td>\n",
       "      <td>0.820355</td>\n",
       "      <td>0.465186</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>-0.179645</td>\n",
       "      <td>2.024220</td>\n",
       "      <td>knn</td>\n",
       "      <td>f1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_3</th>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.075899</td>\n",
       "      <td>0.806550</td>\n",
       "      <td>0.571077</td>\n",
       "      <td>0.817534</td>\n",
       "      <td>0.447359</td>\n",
       "      <td>0.812961</td>\n",
       "      <td>-0.182466</td>\n",
       "      <td>2.008124</td>\n",
       "      <td>knn</td>\n",
       "      <td>f2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f3_6</th>\n",
       "      <td>0.571335</td>\n",
       "      <td>0.524108</td>\n",
       "      <td>0.890291</td>\n",
       "      <td>0.547672</td>\n",
       "      <td>0.758054</td>\n",
       "      <td>0.405223</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>-0.241946</td>\n",
       "      <td>2.008967</td>\n",
       "      <td>knn</td>\n",
       "      <td>f3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f2_6</th>\n",
       "      <td>101.628998</td>\n",
       "      <td>47.863987</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.183716</td>\n",
       "      <td>0.866661</td>\n",
       "      <td>0.830364</td>\n",
       "      <td>0.811934</td>\n",
       "      <td>-0.122386</td>\n",
       "      <td>0.982820</td>\n",
       "      <td>svm</td>\n",
       "      <td>f2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f1_6</th>\n",
       "      <td>0.575760</td>\n",
       "      <td>1.994528</td>\n",
       "      <td>0.868218</td>\n",
       "      <td>0.548453</td>\n",
       "      <td>0.767277</td>\n",
       "      <td>0.410217</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>-0.232723</td>\n",
       "      <td>1.993125</td>\n",
       "      <td>knn</td>\n",
       "      <td>f1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_5</th>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.154376</td>\n",
       "      <td>0.793591</td>\n",
       "      <td>0.559959</td>\n",
       "      <td>0.816123</td>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.806757</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>1.976429</td>\n",
       "      <td>knn</td>\n",
       "      <td>f2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f3_6</th>\n",
       "      <td>109.113722</td>\n",
       "      <td>50.533002</td>\n",
       "      <td>0.889823</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>0.492795</td>\n",
       "      <td>0.219566</td>\n",
       "      <td>0.755696</td>\n",
       "      <td>-0.223824</td>\n",
       "      <td>1.770596</td>\n",
       "      <td>svm</td>\n",
       "      <td>f3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_f2_6</th>\n",
       "      <td>0.560864</td>\n",
       "      <td>0.492484</td>\n",
       "      <td>0.731347</td>\n",
       "      <td>0.467497</td>\n",
       "      <td>0.753360</td>\n",
       "      <td>0.345941</td>\n",
       "      <td>0.744210</td>\n",
       "      <td>-0.246640</td>\n",
       "      <td>1.696414</td>\n",
       "      <td>knn</td>\n",
       "      <td>f2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_3</th>\n",
       "      <td>1.900592</td>\n",
       "      <td>1.832925</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.510707</td>\n",
       "      <td>-0.145274</td>\n",
       "      <td>0.369314</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_4</th>\n",
       "      <td>6.530042</td>\n",
       "      <td>3.442770</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>-0.145736</td>\n",
       "      <td>0.366394</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_5</th>\n",
       "      <td>31.155923</td>\n",
       "      <td>12.689633</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506470</td>\n",
       "      <td>-0.146036</td>\n",
       "      <td>0.364315</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_f1_6</th>\n",
       "      <td>109.180324</td>\n",
       "      <td>53.783038</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.855086</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.506185</td>\n",
       "      <td>-0.146554</td>\n",
       "      <td>0.363512</td>\n",
       "      <td>svm</td>\n",
       "      <td>f1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fit_time  score_time  test_recall   test_f1  test_accuracy  \\\n",
       "mlp_f2_5   15.924036    0.425549     0.772120  0.644200       0.877951   \n",
       "mlp_f2_4   11.089791    0.361498     0.776684  0.669933       0.888208   \n",
       "mlp_f1_4    9.182259    0.385886     0.807202  0.660134       0.874936   \n",
       "mlp_f1_6   51.713082    0.975803     0.802646  0.636191       0.865438   \n",
       "mlp_f1_5   22.543625    0.448890     0.798760  0.635674       0.864683   \n",
       "mlp_f2_3   12.340601    0.291237     0.768905  0.652754       0.885007   \n",
       "mlp_f2_6   32.217857    0.711247     0.797466  0.631631       0.865719   \n",
       "svm_f2_4    6.441675    3.110650     0.719567  0.680628       0.910978   \n",
       "mlp_f3_3   12.692576    0.347511     0.838345  0.647370       0.849434   \n",
       "mlp_f1_3    5.641986    0.342958     0.790981  0.612923       0.857063   \n",
       "mlp_f3_4   11.664755    0.349464     0.798748  0.630895       0.852824   \n",
       "mlp_f3_5   14.193923    0.403170     0.822114  0.627125       0.841436   \n",
       "rf_f2_4     0.445592    0.038928     0.793549  0.609563       0.853675   \n",
       "xgb_f1_4    3.781730    0.019563     0.815620  0.610439       0.838329   \n",
       "rf_f1_3     0.673238    0.063058     0.803329  0.637645       0.849620   \n",
       "rf_f3_3     0.285895    0.036070     0.802677  0.635437       0.851127   \n",
       "rf_f1_4     0.382800    0.040378     0.824724  0.620705       0.838614   \n",
       "rf_f3_4     0.362569    0.039601     0.810438  0.612282       0.837578   \n",
       "mlp_f3_6   24.688657    0.655166     0.800710  0.616385       0.848779   \n",
       "xgb_f3_3    3.706034    0.014566     0.813729  0.611590       0.834283   \n",
       "xgb_f2_4    4.854494    0.018355     0.784477  0.600688       0.850097   \n",
       "rf_f2_3     0.302174    0.038896     0.773442  0.621379       0.865813   \n",
       "xgb_f1_5    9.465925    0.034712     0.812378  0.595728       0.830335   \n",
       "svm_f2_3    1.038879    1.184440     0.768264  0.647079       0.879455   \n",
       "rf_f2_5     0.689596    0.046993     0.786437  0.591479       0.840783   \n",
       "xgb_f3_5    7.592996    0.029067     0.833159  0.592928       0.823558   \n",
       "rf_f1_5     0.600037    0.047326     0.815650  0.598944       0.830617   \n",
       "xgb_f3_4    3.836938    0.018232     0.809137  0.595484       0.825722   \n",
       "rf_f3_5     0.539838    0.048029     0.802009  0.591998       0.828075   \n",
       "xgb_f2_5    8.804009    0.030939     0.791603  0.599354       0.846427   \n",
       "xgb_f2_6   20.366165    0.105669     0.778634  0.598744       0.851510   \n",
       "xgb_f1_3    3.248140    0.015208     0.809822  0.599358       0.828733   \n",
       "xgb_f2_3    3.682933    0.015455     0.797451  0.598575       0.843888   \n",
       "xgb_f3_6   17.451774    0.111097     0.796165  0.591721       0.830993   \n",
       "rf_f3_6     1.489658    0.075362     0.803312  0.593031       0.835700   \n",
       "rf_f1_6     1.732900    0.076980     0.786450  0.583221       0.830807   \n",
       "xgb_f1_6   17.824493    0.115081     0.785811  0.577491       0.824690   \n",
       "svm_f3_4    4.718837    2.710278     0.735836  0.640125       0.877006   \n",
       "rf_f2_6     1.817674    0.074688     0.773448  0.578940       0.837394   \n",
       "svm_f2_5   31.866920   12.237243     0.331923  0.441294       0.893666   \n",
       "svm_f3_3    1.820357    1.633793     0.622311  0.662268       0.904762   \n",
       "svm_f3_5   25.571607   10.544783     0.746167  0.529174       0.821587   \n",
       "knn_f2_4    0.021011    0.094598     0.843574  0.600126       0.828073   \n",
       "knn_f3_4    0.020680    0.063363     0.836393  0.602951       0.823459   \n",
       "knn_f3_3    0.006074    0.036097     0.816952  0.605047       0.829670   \n",
       "knn_f1_3    0.006434    0.231269     0.806540  0.601296       0.833246   \n",
       "knn_f3_5    0.103366    0.142831     0.833796  0.574147       0.803982   \n",
       "knn_f1_5    0.107660    0.658764     0.828626  0.580329       0.807085   \n",
       "knn_f1_4    0.021277    0.342905     0.806529  0.582733       0.820355   \n",
       "knn_f2_3    0.006704    0.075899     0.806550  0.571077       0.817534   \n",
       "knn_f3_6    0.571335    0.524108     0.890291  0.547672       0.758054   \n",
       "svm_f2_6  101.628998   47.863987     0.109555  0.183716       0.866661   \n",
       "knn_f1_6    0.575760    1.994528     0.868218  0.548453       0.767277   \n",
       "knn_f2_5    0.105476    0.154376     0.793591  0.559959       0.816123   \n",
       "svm_f3_6  109.113722   50.533002     0.889823  0.348902       0.492795   \n",
       "knn_f2_6    0.560864    0.492484     0.731347  0.467497       0.753360   \n",
       "svm_f1_3    1.900592    1.832925     0.001297  0.002585       0.855086   \n",
       "svm_f1_4    6.530042    3.442770     0.001297  0.002585       0.855086   \n",
       "svm_f1_5   31.155923   12.689633     0.001297  0.002585       0.855086   \n",
       "svm_f1_6  109.180324   53.783038     0.001297  0.002585       0.855086   \n",
       "\n",
       "          test_precision  test_roc_auc  test_neg_brier_score     total name  \\\n",
       "mlp_f2_5        0.576176      0.925820             -0.089756  2.252384  mlp   \n",
       "mlp_f2_4        0.602893      0.924755             -0.081424  2.289948  mlp   \n",
       "mlp_f1_4        0.568635      0.923644             -0.091251  2.299728  mlp   \n",
       "mlp_f1_6        0.537411      0.922410             -0.094534  2.266713  mlp   \n",
       "mlp_f1_5        0.545367      0.921641             -0.091369  2.264706  mlp   \n",
       "mlp_f2_3        0.577477      0.921104             -0.081278  2.261485  mlp   \n",
       "mlp_f2_6        0.537123      0.920247             -0.098666  2.250678  mlp   \n",
       "svm_f2_4        0.675504      0.919531             -0.067792  2.251934  svm   \n",
       "mlp_f3_3        0.549583      0.918898             -0.106688  2.297925  mlp   \n",
       "mlp_f1_3        0.507105      0.915888             -0.104020  2.215772  mlp   \n",
       "mlp_f3_4        0.543802      0.915342             -0.103037  2.241947  mlp   \n",
       "mlp_f3_5        0.533414      0.915293             -0.108831  2.255700  mlp   \n",
       "rf_f2_4         0.507857      0.912487             -0.107952  2.207646   rf   \n",
       "xgb_f1_4        0.508403      0.912410             -0.126650  2.211819  xgb   \n",
       "rf_f1_3         0.557842      0.911391             -0.103614  2.248750   rf   \n",
       "rf_f3_3         0.555866      0.911342             -0.103887  2.245568   rf   \n",
       "rf_f1_4         0.522939      0.910494             -0.109673  2.246250   rf   \n",
       "rf_f3_4         0.517284      0.909816             -0.107992  2.224544   rf   \n",
       "mlp_f3_6        0.511084      0.907131             -0.116227  2.207999  mlp   \n",
       "xgb_f3_3        0.510669      0.906883             -0.130766  2.201436  xgb   \n",
       "xgb_f2_4        0.494726      0.906453             -0.116878  2.174739  xgb   \n",
       "rf_f2_3         0.532533      0.906330             -0.104486  2.196666   rf   \n",
       "xgb_f1_5        0.488686      0.906172             -0.128270  2.186007  xgb   \n",
       "svm_f2_3        0.569462      0.905979             -0.085639  2.235682  svm   \n",
       "rf_f2_5         0.484103      0.904987             -0.119008  2.163896   rf   \n",
       "xgb_f3_5        0.472651      0.904883             -0.132882  2.198087  xgb   \n",
       "rf_f1_5         0.490948      0.903748             -0.117375  2.200967   rf   \n",
       "xgb_f3_4        0.495100      0.903461             -0.137475  2.170607  xgb   \n",
       "rf_f3_5         0.486979      0.901582             -0.116478  2.179111   rf   \n",
       "xgb_f2_5        0.490437      0.900486             -0.119766  2.171676  xgb   \n",
       "xgb_f2_6        0.493244      0.898890             -0.113888  2.162381  xgb   \n",
       "xgb_f1_3        0.492479      0.898356             -0.136489  2.171047  xgb   \n",
       "xgb_f2_3        0.487860      0.897144             -0.123050  2.170120  xgb   \n",
       "xgb_f3_6        0.484625      0.897075             -0.125599  2.159362  xgb   \n",
       "rf_f3_6         0.478589      0.895875             -0.126014  2.166204   rf   \n",
       "rf_f1_6         0.473061      0.891833             -0.126887  2.134617   rf   \n",
       "xgb_f1_6        0.466525      0.891658             -0.131098  2.123862  xgb   \n",
       "svm_f3_4        0.589200      0.891367             -0.087407  2.179921  svm   \n",
       "rf_f2_6         0.470116      0.887994             -0.130979  2.109403   rf   \n",
       "svm_f2_5        0.840362      0.875871             -0.097267  1.551821  svm   \n",
       "svm_f3_3        0.767073      0.869088             -0.079287  2.074380  svm   \n",
       "svm_f3_5        0.416319      0.843197             -0.132012  1.986526  svm   \n",
       "knn_f2_4        0.470838      0.834500             -0.171927  2.106274  knn   \n",
       "knn_f3_4        0.484549      0.828818             -0.176541  2.091622  knn   \n",
       "knn_f3_3        0.492244      0.824382             -0.170330  2.076051  knn   \n",
       "knn_f1_3        0.488866      0.822147             -0.166754  2.063229  knn   \n",
       "knn_f3_5        0.451276      0.816347             -0.196018  2.028272  knn   \n",
       "knn_f1_5        0.458295      0.816019             -0.192915  2.032059  knn   \n",
       "knn_f1_4        0.465186      0.814602             -0.179645  2.024220  knn   \n",
       "knn_f2_3        0.447359      0.812961             -0.182466  2.008124  knn   \n",
       "knn_f3_6        0.405223      0.812950             -0.241946  2.008967  knn   \n",
       "svm_f2_6        0.830364      0.811934             -0.122386  0.982820  svm   \n",
       "knn_f1_6        0.410217      0.809178             -0.232723  1.993125  knn   \n",
       "knn_f2_5        0.434940      0.806757             -0.183877  1.976429  knn   \n",
       "svm_f3_6        0.219566      0.755696             -0.223824  1.770596  svm   \n",
       "knn_f2_6        0.345941      0.744210             -0.246640  1.696414  knn   \n",
       "svm_f1_3        0.400000      0.510707             -0.145274  0.369314  svm   \n",
       "svm_f1_4        0.400000      0.508248             -0.145736  0.366394  svm   \n",
       "svm_f1_5        0.400000      0.506470             -0.146036  0.364315  svm   \n",
       "svm_f1_6        0.400000      0.506185             -0.146554  0.363512  svm   \n",
       "\n",
       "         feature kmer  \n",
       "mlp_f2_5      f2    5  \n",
       "mlp_f2_4      f2    4  \n",
       "mlp_f1_4      f1    4  \n",
       "mlp_f1_6      f1    6  \n",
       "mlp_f1_5      f1    5  \n",
       "mlp_f2_3      f2    3  \n",
       "mlp_f2_6      f2    6  \n",
       "svm_f2_4      f2    4  \n",
       "mlp_f3_3      f3    3  \n",
       "mlp_f1_3      f1    3  \n",
       "mlp_f3_4      f3    4  \n",
       "mlp_f3_5      f3    5  \n",
       "rf_f2_4       f2    4  \n",
       "xgb_f1_4      f1    4  \n",
       "rf_f1_3       f1    3  \n",
       "rf_f3_3       f3    3  \n",
       "rf_f1_4       f1    4  \n",
       "rf_f3_4       f3    4  \n",
       "mlp_f3_6      f3    6  \n",
       "xgb_f3_3      f3    3  \n",
       "xgb_f2_4      f2    4  \n",
       "rf_f2_3       f2    3  \n",
       "xgb_f1_5      f1    5  \n",
       "svm_f2_3      f2    3  \n",
       "rf_f2_5       f2    5  \n",
       "xgb_f3_5      f3    5  \n",
       "rf_f1_5       f1    5  \n",
       "xgb_f3_4      f3    4  \n",
       "rf_f3_5       f3    5  \n",
       "xgb_f2_5      f2    5  \n",
       "xgb_f2_6      f2    6  \n",
       "xgb_f1_3      f1    3  \n",
       "xgb_f2_3      f2    3  \n",
       "xgb_f3_6      f3    6  \n",
       "rf_f3_6       f3    6  \n",
       "rf_f1_6       f1    6  \n",
       "xgb_f1_6      f1    6  \n",
       "svm_f3_4      f3    4  \n",
       "rf_f2_6       f2    6  \n",
       "svm_f2_5      f2    5  \n",
       "svm_f3_3      f3    3  \n",
       "svm_f3_5      f3    5  \n",
       "knn_f2_4      f2    4  \n",
       "knn_f3_4      f3    4  \n",
       "knn_f3_3      f3    3  \n",
       "knn_f1_3      f1    3  \n",
       "knn_f3_5      f3    5  \n",
       "knn_f1_5      f1    5  \n",
       "knn_f1_4      f1    4  \n",
       "knn_f2_3      f2    3  \n",
       "knn_f3_6      f3    6  \n",
       "svm_f2_6      f2    6  \n",
       "knn_f1_6      f1    6  \n",
       "knn_f2_5      f2    5  \n",
       "svm_f3_6      f3    6  \n",
       "knn_f2_6      f2    6  \n",
       "svm_f1_3      f1    3  \n",
       "svm_f1_4      f1    4  \n",
       "svm_f1_5      f1    5  \n",
       "svm_f1_6      f1    6  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "score_df = score_df.sort_values(by=['test_roc_auc'], ascending=False)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# SVM: f2_4\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42), n_estimators=10, n_jobs=-1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# temp_svm.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# RF: f2_4\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m randforest \u001b[39m=\u001b[39m BalancedRandomForestClassifier(max_features\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqrt\u001b[39m\u001b[39m\"\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m randforest\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# XGBoost: f2_4\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m xgb1 \u001b[39m=\u001b[39m BalancedBaggingClassifier(base_estimator\u001b[39m=\u001b[39mXGBClassifier(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         learning_rate \u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         n_estimators\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         scale_pos_weight\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/train_and_vis/models.ipynb#X50sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         ), n_estimators\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/imblearn/ensemble/_forest.py:547\u001b[0m, in \u001b[0;36mBalancedRandomForestClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    539\u001b[0m     samplers\u001b[39m.\u001b[39mappend(sampler)\n\u001b[1;32m    541\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[39m# that case. However, we respect any parallel_backend contexts set\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m# at a higher level, since correctness does not rely on using\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# threads.\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m samplers_trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    548\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    549\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    550\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    551\u001b[0m )(\n\u001b[1;32m    552\u001b[0m     delayed(_local_parallel_build_trees)(\n\u001b[1;32m    553\u001b[0m         s,\n\u001b[1;32m    554\u001b[0m         t,\n\u001b[1;32m    555\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    556\u001b[0m         X,\n\u001b[1;32m    557\u001b[0m         y_encoded,\n\u001b[1;32m    558\u001b[0m         sample_weight,\n\u001b[1;32m    559\u001b[0m         i,\n\u001b[1;32m    560\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    561\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    562\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    563\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    564\u001b[0m     )\n\u001b[1;32m    565\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, (s, t) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\u001b[39mzip\u001b[39;49m(samplers, trees))\n\u001b[1;32m    566\u001b[0m )\n\u001b[1;32m    567\u001b[0m samplers, trees \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39msamplers_trees)\n\u001b[1;32m    569\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/seq/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pretrained models\n",
    "ds = dataset['f2-4']\n",
    "X, y = ds['X'], ds['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MLP: f2_4\n",
    "mlp = BalancedBaggingClassifier(base_estimator=MLPClassifier(alpha=0.6, hidden_layer_sizes=(100, 180, 180, 200, 200),\n",
    "              max_iter=550, random_state=42, solver='adam', activation='relu'), n_estimators=5, n_jobs=-1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# SVM: f2_4\n",
    "# temp_svm = BalancedBaggingClassifier(base_estimator=SVC(kernel='rbf', C=2, gamma=0.6, probability=True, random_state=42), n_estimators=10, n_jobs=-1)\n",
    "\n",
    "# temp_svm.fit(X_train, y_train)\n",
    "\n",
    "# RF: f2_4\n",
    "randforest = BalancedRandomForestClassifier(max_features=\"sqrt\", n_jobs=-1)\n",
    "\n",
    "randforest.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost: f2_4\n",
    "xgb1 = BalancedBaggingClassifier(base_estimator=XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=200,\n",
    "        max_depth=9,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        #  scale_pos_weight=1,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=6,\n",
    "        ), n_estimators=1, n_jobs=-1)\n",
    "xgb1.fit(X_train, y_train)\n",
    "# xgb1 = pickle.load(open('models/curr_models/xgb1-test.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# xgb1.fit(X_train, y_train)\n",
    "\n",
    "em = StackingCVClassifier(classifiers = [mlp, randforest, xgb1],\n",
    "                            # shuffle = True,\n",
    "                            use_probas = True,\n",
    "                            cv = 5,\n",
    "                            use_features_in_secondary=True,\n",
    "                            meta_classifier = LogisticRegression(C = 5, random_state=42), n_jobs=-1, random_state=42, verbose=1, store_train_meta_features=True)\n",
    "em.fit(X_train, y_train)\n",
    "# x = cross_validate(em, X, y, cv=5, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'], verbose=1, n_jobs=-1)\n",
    "# name = 'ensemble_lengthdiv_4'\n",
    "# if (name not in modelScores):\n",
    "#     modelScores[name] = {}\n",
    "#     for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "#         modelScores[name][k]=v.mean()\n",
    "# else:\n",
    "#     print('already in modelScores')\n",
    "# em.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388523047977423\n",
      "0.7352941176470589\n",
      "0.7758620689655173\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, em.predict(X_test)))\n",
    "print(recall_score(y_test, em.predict(X_test)))\n",
    "print(f1_score(y_test, em.predict(X_test)))\n",
    "# pickle.dump(em, open('models/curr_models/ensemble.pkl', 'wb'))\n",
    "asdf = pickle.load(open('models/curr_models/xgb1-test.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# print(em.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967074317968015\n",
      "0.7973856209150327\n",
      "0.874551971326165\n",
      "0.9285042333019755\n",
      "0.7941176470588235\n",
      "0.7617554858934168\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, asdf.predict(X_test)))\n",
    "print(recall_score(y_test, asdf.predict(X_test)))\n",
    "print(f1_score(y_test, asdf.predict(X_test)))\n",
    "\n",
    "print(accuracy_score(y_test, temp_svm.predict(X_test)))\n",
    "print(recall_score(y_test, temp_svm.predict(X_test)))\n",
    "print(f1_score(y_test, temp_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 classifiers...\n",
      "Fitting 3 classifiers...\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n",
      "Fitting classifier1: balancedbaggingclassifier (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedbaggingclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: balancedbaggingclassifier (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: balancedbaggingclassifier (3/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   43.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# print(em.clfs_)\n",
    "x = cross_val_score(em, X, y, cv=2, scoring='recall', verbose=1, n_jobs=-1)\n",
    "# x = cross_validate(em.clfs_, X, y, cv=2, scoring=['recall', 'f1', 'accuracy', 'precision', 'roc_auc', 'neg_brier_score'], verbose=1, n_jobs=-1)\n",
    "# name = 'ensemble_lengthdiv_4'\n",
    "# if (name not in modelScores):\n",
    "#     modelScores[name] = {}\n",
    "#     for k, v in x.items():\n",
    "#         print(k, v.mean())\n",
    "#         modelScores[name][k]=v.mean()\n",
    "# else:\n",
    "#     print('already in modelScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77172503 0.71725032]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump em\n",
    "pickle.dump(em, open('models/curr_models/em.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
