{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, Entrez\n",
    "import os\n",
    "from urllib.error import HTTPError\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import permutations, product\n",
    "import functools\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "import tqdm\n",
    "from numba import njit,jit\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pickle\n",
    "from os import path\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "import threading\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "Entrez.tool = \"Zoonosis predictor\"\n",
    "\n",
    "Entrez.email = input(\"Enter an email address to use NCBI e-utils: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetkmerdict(permset)->OrderedDict:\n",
    "        kmerdict = OrderedDict()\n",
    "        for i in permset:\n",
    "            kmerdict[i]=0\n",
    "        return kmerdict\n",
    "\n",
    "def assign_kmers_to_dict(st, permset, kmer):\n",
    "    kmerdict=resetkmerdict(permset)\n",
    "    # st = row[2] # tune for which column the sequence is in\n",
    "    for j in range(len(st)-kmer+1):\n",
    "        if not st[j:j+kmer] in permset: continue\n",
    "        kmerdict[st[j:j+kmer]]+=1\n",
    "    return kmerdict\n",
    "\n",
    "def getTrainParams(mergedDf):\n",
    "    kmer = 4\n",
    "    print(mergedDf)\n",
    "    s = product('acgt',repeat = kmer)\n",
    "    permset = set([\"\".join(x) for x in list(s)])\n",
    "    # print(permset)\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for row in tqdm.tqdm(mergedDf.itertuples()):\n",
    "        # print(row)\n",
    "        l.append(assign_kmers_to_dict(row[2], permset, kmer))\n",
    "        \n",
    "\n",
    "    finalkmerdict=pd.DataFrame(l)\n",
    "    # print(finalkmerdict)\n",
    "\n",
    "    # print(\"finished\")\n",
    "    mergedDf.fillna(0, inplace=True)\n",
    "\n",
    "    X = finalkmerdict\n",
    "    Y = mergedDf['isZoonotic']\n",
    "\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    return train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequences(mergedDf):\n",
    "    accession_list = [] # maintain order\n",
    "    isZoonotic_list = [] # maintain order\n",
    "    accession_set = set()\n",
    "    isZoonotic_set = set()\n",
    "\n",
    "\n",
    "    for row in tqdm.tqdm(mergedDf.itertuples()):\n",
    "        # row[13] = accession, row[15] = infects humans\n",
    "        for single_acc in row[14].split(\"; \"):\n",
    "            if single_acc not in accession_set:\n",
    "                accession_list.append(single_acc)\n",
    "                isZoonotic_list.append(row[15])\n",
    "                accession_set.add(single_acc)\n",
    "                isZoonotic_set.add(row[15])\n",
    "\n",
    "    ls = []\n",
    "\n",
    "    # TODO: RUN MULTIPLE THREADS TO SPEED UP\n",
    "\n",
    "    for index, ID in enumerate(tqdm.tqdm(accession_list[:100])): #only read the first 100 lol\n",
    "        # multithread for speed up\n",
    "        \n",
    "        try:\n",
    "            QueryHandle = Entrez.efetch(db=\"nucleotide\", id=ID, \n",
    "                                        rettype=\"gb\", retmode=\"text\")\n",
    "        except HTTPError as Error:\n",
    "            if Error.code == 400:  # Bad request\n",
    "                raise ValueError(f\"Accession number not found: {ID}\")\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        SeqRec = SeqIO.read(QueryHandle, \"genbank\")\n",
    "        # print(str(SeqRec.seq))\n",
    "        ls.append({'accession': ID, 'sequence': str(SeqRec.seq).lower(), 'isZoonotic': isZoonotic_list[index]})\n",
    "\n",
    "    df = pd.DataFrame(ls)\n",
    "\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [00:00, 554985.44it/s]\n",
      "100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accession                                           sequence  isZoonotic\n",
      "0   NC_025403.1  accagagggaaaatataacaatgtcgttttatagcgatgtaaataa...           1\n",
      "1   NC_025404.1  accagagggaaaattaagaaaggtcgttccaagacgacttaaaaga...           1\n",
      "2   NC_028246.1  acggagaaaaacaaaaaaactatagtgattagataaataaggaaaa...           1\n",
      "3   NC_002077.1  ttgcccactccctctctgcgcgctcgctcgctcggtggggcctgcg...           1\n",
      "4   NC_006152.1  ctctcccccctgtcgcgttcgctcgctcgctggctcgtttgggggg...           1\n",
      "..          ...                                                ...         ...\n",
      "95  NC_004218.1  gtattaaatttttgtaagtcgttatggaattatttagtgacagtgg...           1\n",
      "96  NC_004219.1  gtatttaaaattcatgtttttgcatcatggcgtgggttacgcaagc...           1\n",
      "97  NC_004220.1  gtattaaaaattacaagaacctaacattgcaatggagatcttgaga...           1\n",
      "98  NC_004221.1  gtatttaaaattatagaaagttctgaacctaggggtctttctgtct...           1\n",
      "99  NC_004204.1  gtattaaaattcagcaattgtccaatttaggaaacattctgtttaa...           1\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 317.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    acca  atgt  catc  cctc  gcgg  tagg  acgt  aaaa  cgta  gacc  ...  gtac  \\\n",
      "0     77    80    95    38    12    28     5   148     5    33  ...    26   \n",
      "1     90    73    93    39    11    34    11   131    12    52  ...    25   \n",
      "2     57    79    54    22     7    35     4   296     9    20  ...    25   \n",
      "3     34     6    27    35    25     5    20    26     6    31  ...     8   \n",
      "4     31    15    20    32    21     2    11    30     5    28  ...    15   \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "95     5    14     8     0     2     8     8    16    10     3  ...    10   \n",
      "96     7     9     5     1     1     7     6    15     4     4  ...     2   \n",
      "97     2    10     4     2     2     3    12    20     8     1  ...     9   \n",
      "98     2     9     7     0     1     3    12    15     6     2  ...     4   \n",
      "99     3     9     3     0     1     1     2     6     1     5  ...     2   \n",
      "\n",
      "    ctgg  gtgc  cagt  gact  tccg  cgga  ggaa  ttat  cagc  \n",
      "0     48    46    67    53    15    22    68   108    57  \n",
      "1     57    47    58    65    25    17    80    78    79  \n",
      "2     38    19    50    41    13    24   112   148    21  \n",
      "3     42    18    12    25    20    24    18     8    38  \n",
      "4     42    15    20    21     9    23    28     4    41  \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "95     6     3     8     9     4     2    13    22     8  \n",
      "96     9     4    15    10     1     2    10    10     9  \n",
      "97     6     3     8     5     2     3     9     8     6  \n",
      "98     3     7     6     4     2     4    11     8     2  \n",
      "99     2     1     3     4     1     2     6     5     2  \n",
      "\n",
      "[100 rows x 256 columns]\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "     ..\n",
      "95    1\n",
      "96    1\n",
      "97    1\n",
      "98    1\n",
      "99    1\n",
      "Name: isZoonotic, Length: 100, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mergedDf = pd.read_csv(\"FinalData_Cleaned.csv\")\n",
    "sequences = getSequences(mergedDf)\n",
    "X_train, X_test, y_train, y_test = getTrainParams(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accession                                           sequence  isZoonotic\n",
      "0   NC_025403.1  accagagggaaaatataacaatgtcgttttatagcgatgtaaataa...           1\n",
      "1   NC_025404.1  accagagggaaaattaagaaaggtcgttccaagacgacttaaaaga...           1\n",
      "2   NC_028246.1  acggagaaaaacaaaaaaactatagtgattagataaataaggaaaa...           1\n",
      "3   NC_002077.1  ttgcccactccctctctgcgcgctcgctcgctcggtggggcctgcg...           1\n",
      "4   NC_006152.1  ctctcccccctgtcgcgttcgctcgctcgctggctcgtttgggggg...           1\n",
      "..          ...                                                ...         ...\n",
      "95  NC_004218.1  gtattaaatttttgtaagtcgttatggaattatttagtgacagtgg...           1\n",
      "96  NC_004219.1  gtatttaaaattcatgtttttgcatcatggcgtgggttacgcaagc...           1\n",
      "97  NC_004220.1  gtattaaaaattacaagaacctaacattgcaatggagatcttgaga...           1\n",
      "98  NC_004221.1  gtatttaaaattatagaaagttctgaacctaggggtctttctgtct...           1\n",
      "99  NC_004204.1  gtattaaaattcagcaattgtccaatttaggaaacattctgtttaa...           1\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "149\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "best_gradBoost = pickle.load(open('curr_models/gradBoost.pkl', 'rb'))\n",
    "\n",
    "\n",
    "kmer = 4\n",
    "print(sequences)\n",
    "\n",
    "s = product('acgt',repeat = kmer)\n",
    "permset = set([\"\".join(x) for x in list(s)])\n",
    "\n",
    "pred_arr = []\n",
    "for ind, file in enumerate(os.listdir(\"./virome_contigs\")):\n",
    "    fasta_sequences = SeqIO.parse(open(f\"./virome_contigs/{file}\"),'fasta')\n",
    "\n",
    "    fasta = [x for x in fasta_sequences][0]\n",
    "    # print(fasta)\n",
    "    \n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    X_info = sequence.lower()\n",
    "\n",
    "    oDict = assign_kmers_to_dict(X_info, permset, kmer) # convert ordereddict to pandas dataframe\n",
    "\n",
    "    kmer_df = pd.DataFrame()\n",
    "\n",
    "    for i in oDict:\n",
    "        kmer_df.at[0, i]=oDict[i]\n",
    "    cols_when_model_builds = best_gradBoost.feature_names_in_\n",
    "    kmer_df=kmer_df[cols_when_model_builds]\n",
    "    \n",
    "    pred_arr.append(best_gradBoost.predict(kmer_df))\n",
    "    \n",
    "pred_arr = np.asarray(pred_arr)\n",
    "    # print(best_gradBoost.predict(kmer_df), sequences.loc[ind]['isZoonotic'])\n",
    "    # print(best_gradBoost.predict(kmer_df), sequences['isZoonotic'])\n",
    "        # print(accuracy_score())\n",
    "\n",
    "print(pred_arr[pred_arr ==1])\n",
    "print(len(pred_arr))\n",
    "\n",
    "print(sequences['isZoonotic'][sequences['isZoonotic'] == 1].to_numpy())\n",
    "print(len(sequences['isZoonotic'][sequences['isZoonotic'] == 1].to_numpy()))\n",
    "\n",
    "    # with open(output_file) as out_file:\n",
    "    #     for fasta in fasta_sequences:\n",
    "    #         name, sequence = fasta.id, str(fasta.seq)\n",
    "    #         new_sequence = some_function(sequence)\n",
    "    #         write_fasta(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(sequences['isZoonotic'], pred_arr[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: PA544053.1\n",
      "Name: PA544053\n",
      "Description: WO 2022071435-A/1: SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING THE SAME\n",
      "Number of features: 1\n",
      "/molecule_type=DNA\n",
      "/topology=linear\n",
      "/data_file_division=PAT\n",
      "/date=29-JUL-2022\n",
      "/accessions=['PA544053']\n",
      "/sequence_version=1\n",
      "/keywords=['WO 2022071435-A/1']\n",
      "/source=Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\n",
      "/organism=Severe acute respiratory syndrome coronavirus 2\n",
      "/taxonomy=['Viruses', 'Riboviria', 'Orthornavirae', 'Pisuviricota', 'Pisoniviricetes', 'Nidovirales', 'Cornidovirineae', 'Coronaviridae', 'Orthocoronavirinae', 'Betacoronavirus', 'Sarbecovirus']\n",
      "/references=[Reference(title='SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING THE SAME', ...)]\n",
      "/comment=OS   Severe acute respiratory syndrome coronavirus 2 PN   WO\n",
      "2022071435-A/1\n",
      "PD   07-APR-2022\n",
      "PF   29-SEP-2021 WO 2021JP035967\n",
      "PR   30-SEP-2020 JP 2020-164630         ,30-APR-2021 JP\n",
      "PR   JP2021/017159       ,\n",
      "PR   25-AUG-2021 US 63/236927\n",
      "PA   ONCOTHERAPY SCIENCE INC,CANCER PRECISION MEDICINE INC,Kazuma\n",
      "PA   KIYOTANI,\n",
      "PA   Yusuke NAKAMURA\n",
      "PI   tetsuro hikichi,yusuke nakamura,kazuma kiyotani\n",
      "PT   'SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING\n",
      "PT   THE SAME'\n",
      "PS   N16\n",
      "CC\n",
      "FH   Key             Location/Qualifiers.\n",
      "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA')\n",
      "[0.05, 0.95]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def getSingleSequence(accessionID):\n",
    "    try:\n",
    "        QueryHandle = Entrez.efetch(db=\"nucleotide\", id=accessionID, \n",
    "                                    rettype=\"gb\", retmode=\"text\")\n",
    "    except HTTPError as Error:\n",
    "        if Error.code == 400:  # Bad request\n",
    "            raise ValueError(f\"Accession number not found: {accessionID}\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    SeqRec = SeqIO.read(QueryHandle, \"genbank\")\n",
    "    print(str(SeqRec))\n",
    "\n",
    "    oDict = assign_kmers_to_dict(X_info, permset, kmer) # convert ordereddict to pandas dataframe\n",
    "\n",
    "    kmer_df = pd.DataFrame()\n",
    "\n",
    "    for i in oDict:\n",
    "        kmer_df.at[0, i]=oDict[i]\n",
    "    # print(best_gradBoost.predict_proba(kmer_df))\n",
    "\n",
    "    cols_when_model_builds = best_gradBoost.feature_names_in_\n",
    "    kmer_df=kmer_df[cols_when_model_builds]\n",
    "    \n",
    "    print([round(x, 2) for x in best_gradBoost.predict_proba(kmer_df).tolist()[0]])\n",
    "    print(best_gradBoost.predict(kmer_df).tolist()[0])\n",
    "\n",
    "    # ls = []\n",
    "    # ls.append({'accession': accessionID, 'sequence': str(SeqRec.seq).lower()})\n",
    "    # df = pd.DataFrame(ls)\n",
    "    # print(df)\n",
    "\n",
    "getSingleSequence(\"PA544053\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
