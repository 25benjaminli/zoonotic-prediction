{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, Entrez\n",
    "import os\n",
    "from urllib.error import HTTPError\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import permutations, product\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_val_score\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pickle\n",
    "from os import path\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from warnings import simplefilter\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, balanced_accuracy_score, precision_recall_curve, auc, roc_curve, roc_auc_score\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "Entrez.tool = \"Zoonosis predictor\"\n",
    "\n",
    "Entrez.email = input(\"Enter an email address to use NCBI e-utils: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, name, X_test, y_test, params=None, dir='models/curr_models', gradBoost=False, xgBoost=False):\n",
    "    if not path.exists(f\"{dir}/{name}.pkl\"):\n",
    "        print(\"does not exist\")\n",
    "\n",
    "        pickle.dump(model, open(f'{dir}/{name}.pkl', 'wb'))\n",
    "    else:\n",
    "        predictions = model.predict(X_test)\n",
    "        currAcc = accuracy_score(y_test, predictions)\n",
    "\n",
    "        pickled_model = pickle.load(open(f'{dir}/{name}.pkl', 'rb'))\n",
    "        \n",
    "        if gradBoost:\n",
    "            # get features here \n",
    "            cols_when_model_builds = pickled_model.feature_names_in_\n",
    "            X_test=X_test[cols_when_model_builds]\n",
    "        elif xgBoost:\n",
    "            # put features into the same order that the model was trained in\n",
    "            cols_when_model_builds = pickled_model.get_booster().feature_names\n",
    "            X_test=X_test[cols_when_model_builds]\n",
    "        \n",
    "        # .values?\n",
    "        \n",
    "        picklePredictions=pickled_model.predict(X_test)\n",
    "        pickleAcc=accuracy_score(y_test, picklePredictions)\n",
    "        \n",
    "        if currAcc > pickleAcc:\n",
    "            print(\"update!\")\n",
    "\n",
    "            # TP, FP, FN, TN\n",
    "            print(confusion_matrix(y_test, picklePredictions).ravel())\n",
    "\n",
    "            print(\"curr\", currAcc, \"pickle\", pickleAcc)\n",
    "            pickle.dump(model, open(f'{dir}/{name}.pkl', 'wb'))\n",
    "\n",
    "            if params != None:\n",
    "                pickle.dump(params, open(f'{dir}/{name}-params.pkl', 'wb'))\n",
    "        else:\n",
    "            print(\"no update\")\n",
    "            print(\"curr\", currAcc, \"pickle\", pickleAcc)\n",
    "            \n",
    "            # TP, FP, FN, TN\n",
    "            print(confusion_matrix(y_test, picklePredictions).ravel())\n",
    "\n",
    "            model=pickled_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetkmerdict(permset)->OrderedDict:\n",
    "        kmerdict = OrderedDict()\n",
    "        for i in permset:\n",
    "            kmerdict[i]=0\n",
    "        return kmerdict\n",
    "\n",
    "def assign_kmers_to_dict(st, permset, kmer):\n",
    "    kmerdict=resetkmerdict(permset)\n",
    "    # st = row[2] # tune for which column the sequence is in\n",
    "    for j in range(len(st)-kmer+1):\n",
    "        if not st[j:j+kmer] in permset: continue\n",
    "        kmerdict[st[j:j+kmer]]+=1\n",
    "    return kmerdict\n",
    "\n",
    "def getTrainParams(mergedDf, kmer):\n",
    "\n",
    "    s = product('acgt',repeat = kmer)\n",
    "    permset = set([\"\".join(x) for x in list(s)])\n",
    "    # print(permset)\n",
    "\n",
    "    l = []\n",
    "    \n",
    "    for row in tqdm.tqdm(mergedDf.itertuples()):\n",
    "        # print(row)\n",
    "        l.append(assign_kmers_to_dict(row[2], permset, kmer))\n",
    "\n",
    "    finalkmerdict=pd.DataFrame(l)\n",
    "    # print(finalkmerdict)\n",
    "\n",
    "    # print(\"finished\")\n",
    "    # mergedDf.fillna(0, inplace=True)\n",
    "\n",
    "    X = finalkmerdict\n",
    "    X = X.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=1)\n",
    "    Y = mergedDf['isZoonotic']\n",
    "\n",
    "    \n",
    "\n",
    "    # print(X)\n",
    "    # print(Y)\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryKmer(ID, isZoonotic_list, index, everything):\n",
    "    FileName = \"{}.gb\".format(ID)\n",
    "    try:\n",
    "        QueryHandle = Entrez.efetch(db=\"nucleotide\", id=ID, \n",
    "                                    rettype=\"gb\", retmode=\"text\")\n",
    "    except HTTPError as Error:\n",
    "        if Error.code == 400:  # Bad request\n",
    "            raise ValueError(f\"Accession number not found: {ID}\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    SeqRec = SeqIO.read(QueryHandle, \"genbank\")\n",
    "    info = {'accession': ID, 'sequence': str(SeqRec.seq).lower(), 'isZoonotic': isZoonotic_list[index]}\n",
    "    everything.append(info)\n",
    "\n",
    "    pickle.dump(info, open(f\"data/sequences/{ID}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequences(mergedDf):\n",
    "    accession_list = [] # maintain order\n",
    "    isZoonotic_list = [] # maintain order\n",
    "    accession_set = set()\n",
    "    isZoonotic_set = set()\n",
    "\n",
    "\n",
    "    for row in tqdm.tqdm(mergedDf.itertuples()):\n",
    "        # row[13] = accession, row[15] = infects humans\n",
    "        for single_acc in row[14].split(\"; \"):\n",
    "            # print(single_acc)\n",
    "            if single_acc not in accession_set:\n",
    "                accession_list.append(single_acc)\n",
    "                isZoonotic_list.append(0 if not row[16] else 1)\n",
    "                # accession_set.add(single_acc)\n",
    "                # isZoonotic_set.add(row[15])\n",
    "                # print(0 if not row[16] else 1)\n",
    "\n",
    "    print(\"passed local retrieval\")\n",
    "    # TODO: RUN MULTIPLE THREADS TO SPEED UP\n",
    "    threads = []\n",
    "    vals = []\n",
    "\n",
    "    print(len(accession_list))\n",
    "    for index, ID in enumerate(tqdm.tqdm(accession_list[1000:1848])): #only read the first 100 lol\n",
    "        # multithread for speed up\n",
    "        queryKmer(ID, isZoonotic_list, index, vals)\n",
    "        # x = threading.Thread(target=queryKmer, args=(ID, isZoonotic_list, index, vals))\n",
    "        # threads.append(x)\n",
    "        # x.start()\n",
    "\n",
    "    # for index, thread in enumerate(tqdm.tqdm(threads)):\n",
    "    #     thread.join()\n",
    "    df = pd.DataFrame(vals)\n",
    "    df.to_csv(\"data/nardus_sequences.csv\")\n",
    "\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "913it [00:00, 581092.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed local retrieval\n",
      "1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 25/848 [00:10<05:26,  2.52it/s]/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/Bio/GenBank/Scanner.py:1794: BiopythonParserWarning: Structured comment not parsed for NC_034212. Is it malformed?\n",
      "  warnings.warn(\n",
      "  3%|▎         | 26/848 [00:11<05:20,  2.56it/s]/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/Bio/GenBank/Scanner.py:1794: BiopythonParserWarning: Structured comment not parsed for NC_034213. Is it malformed?\n",
      "  warnings.warn(\n",
      "  3%|▎         | 27/848 [00:11<05:21,  2.55it/s]/Users/benjaminli/opt/miniconda3/envs/seq/lib/python3.8/site-packages/Bio/GenBank/Scanner.py:1794: BiopythonParserWarning: Structured comment not parsed for NC_034211. Is it malformed?\n",
      "  warnings.warn(\n",
      "100%|██████████| 848/848 [05:47<00:00,  2.44it/s]\n",
      "848it [00:01, 769.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# SLOW METHOD\n",
    "mergedDf = pd.read_csv(\"data/FinalData_Cleaned.csv\") # read mollentze data\n",
    "print(len(mergedDf))\n",
    "sequences = getSequences(mergedDf)\n",
    "(X_test, y_test) = getTrainParams(sequences, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "843    1\n",
      "844    1\n",
      "845    1\n",
      "846    1\n",
      "847    1\n",
      "Name: isZoonotic, Length: 848, dtype: int64\n",
      "848\n",
      "848\n"
     ]
    }
   ],
   "source": [
    "print(sequences['isZoonotic'])\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        accession                                           sequence  \\\n",
      "0     NC_018629.1  acgcttaacagctaaaaaccagaagacagagaaggaatcgaagggg...   \n",
      "1     NC_038446.1  tagtagtagactccttgaaaagctactactacaaagactgggatga...   \n",
      "2     NC_002324.1  acacaaagtcctgggcaaaagaaaagcaaaataaccaactatagat...   \n",
      "3     NC_006507.1  agcaaaaacaggcagtcaaaatggctacagaccagatggacatctc...   \n",
      "4     NC_004119.1  agttggttttgccggctacaacgatcctccgtaggaagcgttggtg...   \n",
      "...           ...                                                ...   \n",
      "1843  NC_030117.1  ggctcaagcctctcgcggctgtgcaagtggaaaaaaaattttttta...   \n",
      "1844  NC_018481.1  cgcactggggatccgagttaaagtatcaatcttccgtgtataatct...   \n",
      "1845   KP792660.1  taaagcaatggcgcatcaacttggagagatagtgaggcagtttgct...   \n",
      "1846   KU925448.1  atgtctgtcttagactttaccgacatccgtggtctgaatgattggt...   \n",
      "1847  NC_023819.1  gttcttttgccactatgaagcttggctatgtgccaccagtgtatga...   \n",
      "\n",
      "      isZoonotic  \n",
      "0              1  \n",
      "1              0  \n",
      "2              0  \n",
      "3              1  \n",
      "4              0  \n",
      "...          ...  \n",
      "1843           0  \n",
      "1844           0  \n",
      "1845           1  \n",
      "1846           0  \n",
      "1847           0  \n",
      "\n",
      "[1848 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getTrainParams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# print(df)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m (X_test_temp, y_test_temp) \u001b[39m=\u001b[39m getTrainParams(df, \u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getTrainParams' is not defined"
     ]
    }
   ],
   "source": [
    "# FAST METHOD - LOAD DATA FROM FOLDER\n",
    "li = []\n",
    "for f in os.listdir('data/sequences'):\n",
    "    seqdf = pickle.load(open(f'data/sequences/{f}', 'rb'))\n",
    "    li.append(seqdf)\n",
    "df = pd.DataFrame(li)\n",
    "print(df)\n",
    "\n",
    "# print(df)\n",
    "(X_test_temp, y_test_temp) = getTrainParams(df, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradBoost = pickle.load(open('models/curr_models/gradBoost.pkl', 'rb'))\n",
    "best_xgBoost = pickle.load(open('models/curr_models/xgBoost.pkl', 'rb'))\n",
    "\n",
    "kmer = 4\n",
    "s = product('acgt',repeat = kmer)\n",
    "permset = set([\"\".join(x) for x in list(s)])\n",
    "\n",
    "pred_arr = []\n",
    "xg_pred = []\n",
    "\n",
    "# blood validation\n",
    "for ind, file in enumerate(os.listdir(\"data/virome_contigs\")):\n",
    "    fasta_sequences = SeqIO.parse(open(f\"data/virome_contigs/{file}\"),'fasta')\n",
    "\n",
    "    fasta = [x for x in fasta_sequences][0]\n",
    "    # print(fasta)\n",
    "    \n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    X_info = sequence.lower()\n",
    "\n",
    "    oDict = assign_kmers_to_dict(X_info, permset, kmer) # convert ordereddict to pandas dataframe\n",
    "\n",
    "    kmer_df = pd.DataFrame()\n",
    "\n",
    "    for i in oDict:\n",
    "        kmer_df.at[0, i]=oDict[i]\n",
    "\n",
    "    kmer_df = kmer_df.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=1)\n",
    "    \n",
    "    cols_when_model_builds = best_gradBoost.feature_names_in_\n",
    "    kmer_df=kmer_df[cols_when_model_builds]\n",
    "    \n",
    "    # print(kmer_df.to_string())\n",
    "    \n",
    "    pred_arr.append(best_gradBoost.predict(kmer_df))\n",
    "    \n",
    "    cols_when_model_builds = best_xgBoost.get_booster().feature_names\n",
    "    kmer_df=kmer_df[cols_when_model_builds]\n",
    "    # print(kmer_df.to_string())\n",
    "\n",
    "    xg_pred.append(best_xgBoost.predict(kmer_df))\n",
    "    \n",
    "pred_arr = np.asarray(pred_arr)\n",
    "xg_pred = np.asarray(xg_pred)\n",
    "\n",
    "\n",
    "    # print(best_gradBoost.predict(kmer_df), sequences.loc[ind]['isZoonotic'])\n",
    "    # print(best_gradBoost.predict(kmer_df), sequences['isZoonotic'])\n",
    "        # print(accuracy_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848 1848\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test_temp), len(y_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848\n",
      "0.79004329004329\n",
      "[1326   28  360  134]\n",
      "0.7922077922077922\n",
      "[1326   28  360  134]\n"
     ]
    }
   ],
   "source": [
    "cols_when_model_builds = best_gradBoost.feature_names_in_\n",
    "X_test_temp=X_test_temp[cols_when_model_builds]\n",
    "print(len(X_test_temp))\n",
    "print(accuracy_score(y_test_temp, best_gradBoost.predict(X_test_temp)))\n",
    "print(confusion_matrix(y_test_temp, best_gradBoost.predict(X_test_temp)).ravel())\n",
    "\n",
    "# print(y_test.to_string())\n",
    "\n",
    "cols_when_model_builds = best_xgBoost.get_booster().feature_names\n",
    "X_test_temp=X_test_temp[cols_when_model_builds]\n",
    "print(accuracy_score(y_test_temp, best_xgBoost.predict(X_test_temp)))\n",
    "print(confusion_matrix(y_test_temp, best_gradBoost.predict(X_test_temp)).ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tggc      ttcc      tatg      gtat      aatg      acag      atgg  \\\n",
      "0     0.129032  0.296774  0.341935  0.193548  0.406452  0.393548  0.412903   \n",
      "1     0.291667  0.291667  0.541667  0.458333  0.541667  0.333333  0.625000   \n",
      "2     0.138462  0.276923  0.353846  0.307692  0.400000  0.123077  0.246154   \n",
      "3     0.315789  0.263158  0.105263  0.105263  0.473684  0.473684  0.526316   \n",
      "4     0.540146  0.218978  0.240876  0.094891  0.693431  0.335766  0.715328   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1843  0.063178  0.157752  0.276744  0.219767  0.310078  0.110078  0.229070   \n",
      "1844  0.280000  0.240000  0.160000  0.160000  0.340000  0.220000  0.260000   \n",
      "1845  0.226804  0.144330  0.453608  0.247423  0.587629  0.340206  0.422680   \n",
      "1846  0.550000  0.250000  0.300000  0.150000  0.800000  0.800000  0.500000   \n",
      "1847  0.309524  0.452381  0.547619  0.428571  0.666667  0.166667  0.547619   \n",
      "\n",
      "          tact      tcaa      aggc  ...      ggca      gacc      agct  \\\n",
      "0     0.335484  0.587097  0.200000  ...  0.219355  0.219355  0.296774   \n",
      "1     0.583333  0.625000  0.375000  ...  0.500000  0.208333  0.458333   \n",
      "2     0.246154  0.384615  0.061538  ...  0.076923  0.061538  0.123077   \n",
      "3     0.157895  0.684211  0.368421  ...  0.578947  0.684211  0.210526   \n",
      "4     0.204380  0.430657  0.182482  ...  0.262774  0.175182  0.240876   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1843  0.196512  0.298837  0.036822  ...  0.030233  0.044186  0.138760   \n",
      "1844  0.140000  0.580000  0.180000  ...  0.120000  0.140000  0.160000   \n",
      "1845  0.309278  0.556701  0.175258  ...  0.257732  0.195876  0.216495   \n",
      "1846  0.050000  0.500000  0.500000  ...  0.500000  0.200000  0.550000   \n",
      "1847  0.428571  0.500000  0.261905  ...  0.190476  0.095238  0.238095   \n",
      "\n",
      "          agta      tatc      acgt      cact      cttg      ctat      tctt  \n",
      "0     0.187097  0.361290  0.058065  0.245161  0.335484  0.322581  0.625806  \n",
      "1     0.208333  0.375000  0.083333  0.291667  0.416667  0.333333  0.375000  \n",
      "2     0.353846  0.353846  0.030769  0.415385  0.292308  0.292308  0.461538  \n",
      "3     0.157895  0.157895  0.052632  0.368421  0.263158  0.105263  0.157895  \n",
      "4     0.116788  0.153285  0.065693  0.335766  0.467153  0.197080  0.321168  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1843  0.178295  0.238372  0.080233  0.087597  0.116279  0.274419  0.260078  \n",
      "1844  0.120000  0.180000  0.020000  0.320000  0.300000  0.140000  0.740000  \n",
      "1845  0.247423  0.329897  0.041237  0.185567  0.195876  0.360825  0.340206  \n",
      "1846  0.250000  0.050000  0.000000  0.250000  0.650000  0.250000  0.250000  \n",
      "1847  0.309524  0.404762  0.309524  0.190476  0.333333  0.404762  0.333333  \n",
      "\n",
      "[1848 rows x 256 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv('data/info.csv')\n",
    "X_vals = pd.concat([orig_df.loc[:, orig_df.columns != 'isZoonotic'], X_test_temp], axis=0, ignore_index=True)\n",
    "\n",
    "# # print(X_vals)\n",
    "y_vals = pd.concat([orig_df['isZoonotic'], y_test_temp], axis=0, ignore_index=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vals, y_vals, test_size=0.2, random_state=1)\n",
    "\n",
    "# print(len(X_train)+len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11278\n",
      "Learning rate:  0.05\n",
      "Accuracy score (validation): 0.938\n",
      "update!\n",
      "[1866   26  115  249]\n",
      "curr 0.9379432624113475 pickle 0.9375\n",
      "Learning rate:  0.075\n",
      "Accuracy score (validation): 0.932\n",
      "no update\n",
      "curr 0.9317375886524822 pickle 0.9379432624113475\n",
      "[1874   18  122  242]\n",
      "Learning rate:  0.1\n",
      "Accuracy score (validation): 0.935\n",
      "no update\n",
      "curr 0.9348404255319149 pickle 0.9379432624113475\n",
      "[1874   18  122  242]\n",
      "Learning rate:  0.15\n",
      "Accuracy score (validation): 0.931\n",
      "no update\n",
      "curr 0.9312943262411347 pickle 0.9379432624113475\n",
      "[1874   18  122  242]\n",
      "Learning rate:  0.2\n",
      "Accuracy score (validation): 0.941\n",
      "update!\n",
      "[1874   18  122  242]\n",
      "curr 0.9406028368794326 pickle 0.9379432624113475\n",
      "Learning rate:  0.25\n",
      "Accuracy score (validation): 0.933\n",
      "no update\n",
      "curr 0.9330673758865248 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.3\n",
      "Accuracy score (validation): 0.935\n",
      "no update\n",
      "curr 0.9352836879432624 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.35\n",
      "Accuracy score (validation): 0.929\n",
      "no update\n",
      "curr 0.9286347517730497 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.4\n",
      "Accuracy score (validation): 0.936\n",
      "no update\n",
      "curr 0.93572695035461 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.45\n",
      "Accuracy score (validation): 0.933\n",
      "no update\n",
      "curr 0.9326241134751773 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.5\n",
      "Accuracy score (validation): 0.932\n",
      "no update\n",
      "curr 0.9317375886524822 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.55\n",
      "Accuracy score (validation): 0.813\n",
      "no update\n",
      "curr 0.813386524822695 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.6\n",
      "Accuracy score (validation): 0.779\n",
      "no update\n",
      "curr 0.7788120567375887 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.65\n",
      "Accuracy score (validation): 0.793\n",
      "no update\n",
      "curr 0.7925531914893617 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.7\n",
      "Accuracy score (validation): 0.727\n",
      "no update\n",
      "curr 0.7265070921985816 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.75\n",
      "Accuracy score (validation): 0.742\n",
      "no update\n",
      "curr 0.7415780141843972 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.8\n",
      "Accuracy score (validation): 0.739\n",
      "no update\n",
      "curr 0.7389184397163121 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  0.85\n",
      "Accuracy score (validation): 0.751\n",
      "no update\n",
      "curr 0.750886524822695 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n",
      "Learning rate:  1\n",
      "Accuracy score (validation): 0.724\n",
      "no update\n",
      "curr 0.724290780141844 pickle 0.9406028368794326\n",
      "[1863   29  105  259]\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65,0.7, 0.75, 0.8, 0.85, 1]\n",
    "\n",
    "parameters={\n",
    "   \"n_estimators\":130, # 200 kind of overfits I think\n",
    "    \"max_features\":2,\n",
    "    \"max_depth\":9,\n",
    "    \"random_state\":0,\n",
    "    \"min_sample_split\":25,\n",
    "    \"subsample\":0.85\n",
    "    # \"warm_start\":True\n",
    "}\n",
    "\n",
    "\n",
    "# careful with WARM START - only works after a lot of iterations\n",
    "# integrating both datasets works better!\n",
    "\n",
    "print(len(X_train)+len(X_test))\n",
    "for learning_rate in lr_list:\n",
    "    gradBoost = GradientBoostingClassifier(n_estimators=parameters['n_estimators'], \n",
    "    learning_rate=learning_rate, max_features=parameters['max_features'], \n",
    "    max_depth=parameters['max_depth'], random_state=parameters['random_state'], \n",
    "    min_samples_split=parameters['min_sample_split'], subsample=parameters['subsample']\n",
    "    )\n",
    "\n",
    "    parameters['learning_rate']=learning_rate\n",
    "    gradBoost.fit(X_train, y_train)\n",
    "\n",
    "    cols_when_model_builds = gradBoost.feature_names_in_\n",
    "    X_test=X_test[cols_when_model_builds]\n",
    "    \n",
    "    testingAcc = accuracy_score(y_test, gradBoost.predict(X_test))\n",
    "    trainingAcc = accuracy_score(y_train, gradBoost.predict(X_train))\n",
    "    \n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    # print(\"Accuracy score (training): {0:.3f}\".format(trainingAcc))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(testingAcc))\n",
    "    # print(f\"Feature importance {gradBoost.feature_importances_}\")\n",
    "\n",
    "    # pickle.dump(gradBoost, open('gradBoost.pkl', 'wb'))\n",
    "    saveModel(gradBoost, \"gradBoost\", X_test, y_test, parameters, gradBoost=True, dir=\"models/nardus_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                  max_depth=8, max_features=2,\n",
       "                                                  min_samples_split=50,\n",
       "                                                  n_estimators=120,\n",
       "                                                  random_state=0,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         &#x27;max_depth&#x27;: range(6, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(15, 55, 10),\n",
       "                         &#x27;n_estimators&#x27;: range(100, 140, 10),\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.85, 0.9]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                  max_depth=8, max_features=2,\n",
       "                                                  min_samples_split=50,\n",
       "                                                  n_estimators=120,\n",
       "                                                  random_state=0,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         &#x27;max_depth&#x27;: range(6, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(15, 55, 10),\n",
       "                         &#x27;n_estimators&#x27;: range(100, 140, 10),\n",
       "                         &#x27;subsample&#x27;: [0.8, 0.85, 0.9]},\n",
       "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, max_depth=8, max_features=2,\n",
       "                           min_samples_split=50, n_estimators=120,\n",
       "                           random_state=0, subsample=0.8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.05, max_depth=8, max_features=2,\n",
       "                           min_samples_split=50, n_estimators=120,\n",
       "                           random_state=0, subsample=0.8)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=GradientBoostingClassifier(learning_rate=0.05,\n",
       "                                                  max_depth=8, max_features=2,\n",
       "                                                  min_samples_split=50,\n",
       "                                                  n_estimators=120,\n",
       "                                                  random_state=0,\n",
       "                                                  subsample=0.8),\n",
       "             n_jobs=4,\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'max_depth': range(6, 10),\n",
       "                         'min_samples_split': range(15, 55, 10),\n",
       "                         'n_estimators': range(100, 140, 10),\n",
       "                         'subsample': [0.8, 0.85, 0.9]},\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "param_test1 = {'n_estimators':range(100,140,10), 'learning_rate':[0.1,0.2,0.3,0.4,0.5], 'subsample':[0.8,0.85,0.9], 'max_depth':range(6,10,1), 'min_samples_split':range(15,55,10)}\n",
    "\n",
    "gradBoost = GridSearchCV(estimator = GradientBoostingClassifier(\n",
    "    n_estimators=parameters['n_estimators'], \n",
    "learning_rate=learning_rate, max_features=parameters['max_features'], \n",
    "max_depth=parameters['max_depth'], random_state=parameters['random_state'], \n",
    "min_samples_split=parameters['min_sample_split'], subsample=parameters['subsample']\n",
    "), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5, verbose=1)\n",
    "\n",
    "\n",
    "parameters['learning_rate']=learning_rate\n",
    "gradBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848\n",
      "0.9550865800865801\n",
      "[1344   10   73  421]\n"
     ]
    }
   ],
   "source": [
    "gradBoost = pickle.load(open('models/nardus_testing/gradBoost.pkl', 'rb'))\n",
    "print(len(X_test_temp))\n",
    "cols_when_model_builds = gradBoost.feature_names_in_\n",
    "X_test_temp=X_test_temp[cols_when_model_builds]\n",
    "\n",
    "print(accuracy_score(y_test_temp, gradBoost.predict(X_test_temp)))\n",
    "print(confusion_matrix(y_test_temp, gradBoost.predict(X_test_temp)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848\n",
      "0.79004329004329\n",
      "[1326   28  360  134]\n"
     ]
    }
   ],
   "source": [
    "gradBoost = pickle.load(open('models/curr_models/gradBoost.pkl', 'rb'))\n",
    "print(len(X_test_temp))\n",
    "cols_when_model_builds = gradBoost.feature_names_in_\n",
    "X_test_temp=X_test_temp[cols_when_model_builds]\n",
    "\n",
    "print(accuracy_score(y_test_temp, gradBoost.predict(X_test_temp)))\n",
    "print(confusion_matrix(y_test_temp, gradBoost.predict(X_test_temp)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gradBoost \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodels/nardus_testing/gradBoost.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cols_when_model_builds \u001b[39m=\u001b[39m gradBoost\u001b[39m.\u001b[39mfeature_names_in_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminli/Documents/coding/scires/project/nardus.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_temp\u001b[39m=\u001b[39mX_test_temp[cols_when_model_builds]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "gradBoost = pickle.load(open('models/nardus_testing/gradBoost.pkl', 'rb'))\n",
    "cols_when_model_builds = gradBoost.feature_names_in_\n",
    "X_test_temp=X_test_temp[cols_when_model_builds]\n",
    "\n",
    "print(accuracy_score(y_test_temp, gradBoost.predict(X_test_temp)).ravel())\n",
    "\n",
    "print(confusion_matrix(y_test_temp, gradBoost.predict(X_test_temp)).ravel())\n",
    "\n",
    "# ALWAYS reset X columns to the right order\n",
    "y_thing = y_test_temp.to_numpy()\n",
    "precision, recall, thresholds = precision_recall_curve(y_thing, gradBoost.predict_proba(X_test_temp)[::,1])\n",
    "aaa = auc(recall, precision)\n",
    "\n",
    "print(\"precision recall: \" + str(aaa))\n",
    "\n",
    "y_pred_proba = gradBoost.predict_proba(X_test_temp)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test_temp, y_pred_proba)\n",
    "auc_thing = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "\n",
    "print(y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc_thing))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (validation): 0.630\n",
      "Learning rate:  0.075\n",
      "Accuracy score (validation): 0.650\n",
      "Learning rate:  0.1\n",
      "Accuracy score (validation): 0.630\n",
      "Learning rate:  0.15\n",
      "Accuracy score (validation): 0.660\n",
      "Learning rate:  0.2\n",
      "Accuracy score (validation): 0.640\n",
      "Learning rate:  0.25\n",
      "Accuracy score (validation): 0.640\n",
      "Learning rate:  0.3\n",
      "Accuracy score (validation): 0.630\n",
      "Learning rate:  0.35\n",
      "Accuracy score (validation): 0.640\n",
      "Learning rate:  0.4\n",
      "Accuracy score (validation): 0.630\n",
      "Learning rate:  0.45\n",
      "Accuracy score (validation): 0.645\n",
      "Learning rate:  0.5\n",
      "Accuracy score (validation): 0.635\n",
      "Learning rate:  0.55\n",
      "Accuracy score (validation): 0.625\n",
      "Learning rate:  0.6\n",
      "Accuracy score (validation): 0.635\n",
      "Learning rate:  0.65\n",
      "Accuracy score (validation): 0.595\n",
      "Learning rate:  0.7\n",
      "Accuracy score (validation): 0.630\n",
      "Learning rate:  0.75\n",
      "Accuracy score (validation): 0.635\n",
      "Learning rate:  0.8\n",
      "Accuracy score (validation): 0.610\n",
      "Learning rate:  0.85\n",
      "Accuracy score (validation): 0.625\n",
      "Learning rate:  1\n",
      "Accuracy score (validation): 0.580\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65,0.7, 0.75, 0.8, 0.85, 1]\n",
    "\n",
    "parameters={\n",
    "   \"n_estimators\":100, # 200 kind of overfits I think\n",
    "    \"max_features\":2,\n",
    "    \"max_depth\":8,\n",
    "    \"random_state\":0,\n",
    "    \"subsample\":0.8,\n",
    "    'lambda': 0.5, # regularization?\n",
    "    'alpha': 0.5\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    xgBoost = XGBClassifier(n_estimators=parameters['n_estimators'], \n",
    "    learning_rate=learning_rate, \n",
    "    max_depth=parameters['max_depth'], random_state=parameters['random_state'], \n",
    "    subsample=parameters['subsample'], \n",
    "    )\n",
    "\n",
    "    parameters['learning_rate']=learning_rate\n",
    "    xgBoost.fit(X_train, y_train)\n",
    "\n",
    "    # ALWAYS reset feature names\n",
    "    cols_when_model_builds = xgBoost.get_booster().feature_names\n",
    "    X_test=X_test[cols_when_model_builds]\n",
    "\n",
    "    testingAcc = accuracy_score(y_test, xgBoost.predict(X_test))\n",
    "    trainingAcc = accuracy_score(y_train, xgBoost.predict(X_train))\n",
    "    \n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    # print(\"Accuracy score (training): {0:.3f}\".format(trainingAcc))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(testingAcc))\n",
    "    # print(f\"Feature importance {gradBoost.feature_importances_}\")\n",
    "\n",
    "    # pickle.dump(gradBoost, open('gradBoost.pkl', 'wb'))\n",
    "    # saveModel(xgBoost, \"xgBoost\", X_test, y_test, parameters, xgBoost=True, dir=\"synthetic_data_testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62375\n"
     ]
    }
   ],
   "source": [
    "randforest = pickle.load(open('curr_models/randforest.pkl', 'rb'))\n",
    "print(accuracy_score(y_train, randforest.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "knn = pickle.load(open('curr_models/knn.pkl', 'rb'))\n",
    "\n",
    "print(accuracy_score(y_test, knn.predict(X_test)))\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: PA544053.1\n",
      "Name: PA544053\n",
      "Description: WO 2022071435-A/1: SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING THE SAME\n",
      "Number of features: 1\n",
      "/molecule_type=DNA\n",
      "/topology=linear\n",
      "/data_file_division=PAT\n",
      "/date=29-JUL-2022\n",
      "/accessions=['PA544053']\n",
      "/sequence_version=1\n",
      "/keywords=['WO 2022071435-A/1']\n",
      "/source=Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\n",
      "/organism=Severe acute respiratory syndrome coronavirus 2\n",
      "/taxonomy=['Viruses', 'Riboviria', 'Orthornavirae', 'Pisuviricota', 'Pisoniviricetes', 'Nidovirales', 'Cornidovirineae', 'Coronaviridae', 'Orthocoronavirinae', 'Betacoronavirus', 'Sarbecovirus']\n",
      "/references=[Reference(title='SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING THE SAME', ...)]\n",
      "/comment=OS   Severe acute respiratory syndrome coronavirus 2 PN   WO\n",
      "2022071435-A/1\n",
      "PD   07-APR-2022\n",
      "PF   29-SEP-2021 WO 2021JP035967\n",
      "PR   30-SEP-2020 JP 2020-164630         ,30-APR-2021 JP\n",
      "PR   JP2021/017159       ,\n",
      "PR   25-AUG-2021 US 63/236927\n",
      "PA   ONCOTHERAPY SCIENCE INC,CANCER PRECISION MEDICINE INC,Kazuma\n",
      "PA   KIYOTANI,\n",
      "PA   Yusuke NAKAMURA\n",
      "PI   tetsuro hikichi,yusuke nakamura,kazuma kiyotani\n",
      "PT   'SARS-CoV-2 PROTEIN-DERIVED PEPTIDES AND VACCINES INCLUDING\n",
      "PT   THE SAME'\n",
      "PS   N16\n",
      "CC\n",
      "FH   Key             Location/Qualifiers.\n",
      "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA')\n",
      "[0.33, 0.67]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def getSingleSequence(accessionID):\n",
    "    try:\n",
    "        QueryHandle = Entrez.efetch(db=\"nucleotide\", id=accessionID, \n",
    "                                    rettype=\"gb\", retmode=\"text\")\n",
    "    except HTTPError as Error:\n",
    "        if Error.code == 400:  # Bad request\n",
    "            raise ValueError(f\"Accession number not found: {accessionID}\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    SeqRec = SeqIO.read(QueryHandle, \"genbank\")\n",
    "    print(str(SeqRec))\n",
    "\n",
    "    oDict = assign_kmers_to_dict(X_info, permset, kmer) # convert ordereddict to pandas dataframe\n",
    "\n",
    "    kmer_df = pd.DataFrame()\n",
    "\n",
    "    for i in oDict:\n",
    "        kmer_df.at[0, i]=oDict[i]\n",
    "    # print(best_gradBoost.predict_proba(kmer_df))\n",
    "\n",
    "    cols_when_model_builds = best_gradBoost.feature_names_in_\n",
    "    kmer_df=kmer_df[cols_when_model_builds]\n",
    "    \n",
    "    print([round(x, 2) for x in best_gradBoost.predict_proba(kmer_df).tolist()[0]])\n",
    "    print(best_gradBoost.predict(kmer_df).tolist()[0])\n",
    "\n",
    "    # ls = []\n",
    "    # ls.append({'accession': accessionID, 'sequence': str(SeqRec.seq).lower()})\n",
    "    # df = pd.DataFrame(ls)\n",
    "    # print(df)\n",
    "\n",
    "getSingleSequence(\"PA544053\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1360c63304de9435a2a3572d38e6c9496b6fb5d1617f35fbc8638664d664ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
